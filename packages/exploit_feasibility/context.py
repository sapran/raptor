#!/usr/bin/env python3
"""
Binary Context - Shared reconnaissance data for mitigation analysis and exploit development.

This module provides a unified data collection layer that can be used by:
- FeasibilityAnalyzer: To check what blocks exploitation
- Exploit generators: To get offsets, gadgets, and targets for payload construction

Usage:
    # Standalone reconnaissance (no mitigation verdicts)
    ctx = BinaryContext("/path/to/binary")
    ctx.collect_all()
    print(ctx.libc_info.system_offset)
    ctx.save("recon.json")  # Cache for later

    # Load cached context
    ctx = BinaryContext.load("recon.json")

    # Used by FeasibilityAnalyzer internally
    analyzer = FeasibilityAnalyzer("/path/to/binary")
    report = analyzer.full_analysis(extended=True)
    ctx = report.context  # Access the underlying context
"""

import json
import subprocess
import re
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Optional, List, Dict, Any

# Import logging from parent package
try:
    from ..logging import get_logger
    logger = get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


# =============================================================================
# Data Classes - Shared between mitigation analysis and exploit generation
# =============================================================================

@dataclass
class OneGadget:
    """
    A one_gadget entry with its constraints.

    One-gadgets are single-address code execution gadgets in libc that,
    when called, execute execve("/bin/sh", ...) if certain constraints are met.
    """
    offset: int
    constraints: List[str] = field(default_factory=list)
    description: str = ""  # e.g., "execve('/bin/sh', rsp+0x40, environ)"

    # Feasibility analysis
    partial_overwrite_viable: bool = False  # Can reach via 2-byte overwrite?
    bytes_from_base: int = 0  # How many bytes to write from libc base

    def summary(self) -> str:
        status = "✓ partial-overwrite OK" if self.partial_overwrite_viable else "✗ needs full write"
        constraint_str = ', '.join(self.constraints) if self.constraints else 'none'
        return f"0x{self.offset:x} [{status}] constraints: {constraint_str}"


@dataclass
class LibcInfo:
    """Libc information for exploit development."""
    path: str = ""
    version: str = ""

    # Critical offsets (from libc base)
    system_offset: Optional[int] = None
    execve_offset: Optional[int] = None
    bin_sh_offset: Optional[int] = None
    environ_offset: Optional[int] = None

    # Hooks (removed in glibc 2.34, but useful for older targets)
    malloc_hook_offset: Optional[int] = None
    free_hook_offset: Optional[int] = None

    # One-gadgets (if one_gadget tool available)
    one_gadgets: List[int] = field(default_factory=list)  # Offsets only
    one_gadgets_detailed: List['OneGadget'] = field(default_factory=list)  # With constraints

    # Analysis results
    has_partial_overwrite_gadget: bool = False  # Any one_gadget in low offset range?
    best_partial_gadget: Optional['OneGadget'] = None  # Lowest offset one_gadget

    def __post_init__(self):
        """Validate offset values are non-negative when set."""
        offset_fields = [
            'system_offset', 'execve_offset', 'bin_sh_offset', 'environ_offset',
            'malloc_hook_offset', 'free_hook_offset'
        ]
        for field_name in offset_fields:
            val = getattr(self, field_name)
            if val is not None and val < 0:
                raise ValueError(f"LibcInfo.{field_name} must be non-negative, got {val}")
        for i, og in enumerate(self.one_gadgets):
            if og < 0:
                raise ValueError(f"LibcInfo.one_gadgets[{i}] must be non-negative, got {og}")

    def __repr__(self) -> str:
        ver = self.version.split()[0] if self.version else "unknown"
        og_count = len(self.one_gadgets)
        sys_off = f"0x{self.system_offset:x}" if self.system_offset else "None"
        return f"LibcInfo(version={ver!r}, system={sys_off}, one_gadgets={og_count})"

    def summary(self) -> str:
        lines = ["LIBC INFO:"]
        if self.path:
            lines.append(f"  Path: {self.path}")
        if self.version:
            lines.append(f"  Version: {self.version}")
        if self.system_offset:
            lines.append(f"  system(): 0x{self.system_offset:x}")
        if self.bin_sh_offset:
            lines.append(f'  "/bin/sh": 0x{self.bin_sh_offset:x}')
        if self.malloc_hook_offset:
            lines.append(f"  __malloc_hook: 0x{self.malloc_hook_offset:x}")
        if self.free_hook_offset:
            lines.append(f"  __free_hook: 0x{self.free_hook_offset:x}")
        # Show detailed one_gadgets if available, else fall back to basic list
        if self.one_gadgets_detailed:
            lines.append(f"  One-gadgets: {len(self.one_gadgets_detailed)} found")
            for og in self.one_gadgets_detailed[:5]:
                lines.append(f"    {og.summary()}")
            if self.best_partial_gadget:
                lines.append(f"  Best partial overwrite: 0x{self.best_partial_gadget.offset:x}")
        elif self.one_gadgets:
            lines.append(f"  One-gadgets: {len(self.one_gadgets)} found")
            for og in self.one_gadgets[:3]:
                lines.append(f"    0x{og:x}")
        return "\n".join(lines)


@dataclass
class ROPGadgetInfo:
    """ROP gadget analysis results."""
    total_gadgets: int = 0
    usable_gadgets: int = 0  # After filtering bad bytes

    # Essential gadgets (offsets from binary base)
    pop_rdi_ret: Optional[int] = None
    pop_rsi_ret: Optional[int] = None
    pop_rdx_ret: Optional[int] = None
    pop_rax_ret: Optional[int] = None
    pop_rbx_ret: Optional[int] = None
    pop_rcx_ret: Optional[int] = None
    pop_rbp_ret: Optional[int] = None
    pop_rsp_ret: Optional[int] = None

    # Useful gadgets
    ret: Optional[int] = None  # For stack alignment
    leave_ret: Optional[int] = None  # Stack pivot
    syscall_ret: Optional[int] = None
    call_rax: Optional[int] = None

    # All gadgets (for custom chains)
    all_gadgets: List[Dict[str, Any]] = field(default_factory=list)

    # Filtering stats
    filtered_by_bad_bytes: int = 0
    filtered_by_charset: int = 0  # Filtered due to non-printable/non-alphanumeric

    # Charset-filtered gadget counts (for constrained input)
    printable_gadgets: int = 0     # Gadgets with printable addresses (0x20-0x7e)
    alphanumeric_gadgets: int = 0  # Gadgets with alphanumeric addresses

    def __post_init__(self):
        """Validate gadget counts and addresses are non-negative."""
        if self.total_gadgets < 0:
            raise ValueError(f"ROPGadgetInfo.total_gadgets must be non-negative, got {self.total_gadgets}")
        if self.usable_gadgets < 0:
            raise ValueError(f"ROPGadgetInfo.usable_gadgets must be non-negative, got {self.usable_gadgets}")
        if self.usable_gadgets > self.total_gadgets:
            raise ValueError(f"ROPGadgetInfo.usable_gadgets ({self.usable_gadgets}) cannot exceed total_gadgets ({self.total_gadgets})")

    def __repr__(self) -> str:
        key_gadgets = sum(1 for g in [self.pop_rdi_ret, self.pop_rsi_ret, self.pop_rdx_ret, self.ret] if g)
        return f"ROPGadgetInfo(total={self.total_gadgets}, usable={self.usable_gadgets}, key={key_gadgets}/4)"

    def summary(self) -> str:
        lines = ["ROP GADGETS:"]
        lines.append(f"  Total: {self.total_gadgets}, Usable: {self.usable_gadgets}")
        if self.filtered_by_bad_bytes:
            lines.append(f"  Filtered (bad bytes): {self.filtered_by_bad_bytes}")

        essentials = []
        if self.pop_rdi_ret:
            essentials.append(f"pop rdi; ret @ 0x{self.pop_rdi_ret:x}")
        if self.pop_rsi_ret:
            essentials.append(f"pop rsi; ret @ 0x{self.pop_rsi_ret:x}")
        if self.pop_rdx_ret:
            essentials.append(f"pop rdx; ret @ 0x{self.pop_rdx_ret:x}")
        if self.pop_rax_ret:
            essentials.append(f"pop rax; ret @ 0x{self.pop_rax_ret:x}")
        if self.ret:
            essentials.append(f"ret @ 0x{self.ret:x}")

        extras = []
        if self.pop_rbx_ret:
            extras.append(f"pop rbx; ret @ 0x{self.pop_rbx_ret:x}")
        if self.pop_rcx_ret:
            extras.append(f"pop rcx; ret @ 0x{self.pop_rcx_ret:x}")
        if self.pop_rbp_ret:
            extras.append(f"pop rbp; ret @ 0x{self.pop_rbp_ret:x}")
        if self.pop_rsp_ret:
            extras.append(f"pop rsp; ret @ 0x{self.pop_rsp_ret:x} (stack pivot)")
        if self.leave_ret:
            extras.append(f"leave; ret @ 0x{self.leave_ret:x} (stack pivot)")
        if self.syscall_ret:
            extras.append(f"syscall @ 0x{self.syscall_ret:x}")
        if self.call_rax:
            extras.append(f"call rax @ 0x{self.call_rax:x}")

        if essentials:
            lines.append("  Key gadgets:")
            for g in essentials:
                lines.append(f"    {g}")
        if extras:
            lines.append("  Additional gadgets:")
            for g in extras:
                lines.append(f"    {g}")
        return "\n".join(lines)


@dataclass
class ELFStructure:
    """ELF structure information for write targets."""
    # Section addresses (offsets from binary base for PIE)
    got_plt_addr: Optional[int] = None
    got_plt_size: int = 0
    fini_array_addr: Optional[int] = None
    fini_array_size: int = 0
    init_array_addr: Optional[int] = None
    init_array_size: int = 0
    bss_addr: Optional[int] = None
    bss_size: int = 0

    # GOT entries: function name -> offset
    got_entries: Dict[str, int] = field(default_factory=dict)

    # PLT entries: function name -> offset
    plt_entries: Dict[str, int] = field(default_factory=dict)

    # Useful for ret2plt
    plt_stub_size: int = 16  # Usually 16 bytes per PLT entry

    def __repr__(self) -> str:
        got = f"0x{self.got_plt_addr:x}" if self.got_plt_addr else "None"
        return f"ELFStructure(got={got}, got_entries={len(self.got_entries)}, plt_entries={len(self.plt_entries)})"

    def summary(self) -> str:
        lines = ["ELF STRUCTURE:"]
        if self.got_plt_addr:
            lines.append(f"  .got.plt: 0x{self.got_plt_addr:x} ({self.got_plt_size} bytes)")
        if self.fini_array_addr:
            lines.append(f"  .fini_array: 0x{self.fini_array_addr:x} ({self.fini_array_size} bytes)")
        if self.init_array_addr:
            lines.append(f"  .init_array: 0x{self.init_array_addr:x} ({self.init_array_size} bytes)")
        if self.bss_addr:
            lines.append(f"  .bss: 0x{self.bss_addr:x} ({self.bss_size} bytes)")
        if self.got_entries:
            lines.append(f"  GOT entries: {len(self.got_entries)}")
        if self.plt_entries:
            lines.append(f"  PLT entries: {len(self.plt_entries)}")
        return "\n".join(lines)


@dataclass
class AddressSpaceInfo:
    """Address space layout information from runtime sampling."""
    # Observed address ranges (from /proc/pid/maps)
    binary_base_sample: Optional[int] = None
    libc_base_sample: Optional[int] = None
    stack_sample: Optional[int] = None
    heap_sample: Optional[int] = None
    ld_base_sample: Optional[int] = None  # Linker base

    # Entropy estimates (bits of randomization)
    binary_entropy_bits: int = 0
    libc_entropy_bits: int = 0
    stack_entropy_bits: int = 0

    # Bad byte analysis in addresses
    binary_has_nulls: bool = False
    libc_has_nulls: bool = False
    stack_has_nulls: bool = False

    # Null byte position (which byte position has first null, 0-7)
    # On x86_64 userland, this is typically byte 6 (addresses are 0x00007fff...)
    null_byte_position: int = 6

    # Maximum contiguous non-null bytes that can be written via strcpy
    # On x86_64: addresses like 0x7ffff7c5c4c0 have 6 non-null bytes (c0 c4 c5 f7 ff 7f)
    max_strcpy_bytes: int = 6

    def __post_init__(self):
        """Validate entropy and position values are reasonable."""
        for field_name in ['binary_entropy_bits', 'libc_entropy_bits', 'stack_entropy_bits']:
            val = getattr(self, field_name)
            if val < 0 or val > 64:
                raise ValueError(f"AddressSpaceInfo.{field_name} must be 0-64, got {val}")
        if not (0 <= self.null_byte_position <= 8):
            raise ValueError(f"AddressSpaceInfo.null_byte_position must be 0-8, got {self.null_byte_position}")
        if not (0 <= self.max_strcpy_bytes <= 8):
            raise ValueError(f"AddressSpaceInfo.max_strcpy_bytes must be 0-8, got {self.max_strcpy_bytes}")

    def __repr__(self) -> str:
        binary = f"0x{self.binary_base_sample:x}" if self.binary_base_sample else "None"
        libc = f"0x{self.libc_base_sample:x}" if self.libc_base_sample else "None"
        return f"AddressSpaceInfo(binary={binary}, libc={libc}, entropy={self.binary_entropy_bits}b)"

    def summary(self) -> str:
        lines = ["ADDRESS SPACE:"]
        if self.binary_base_sample:
            null_note = " [NUL@byte6]" if self.binary_has_nulls else ""
            lines.append(f"  Binary: 0x{self.binary_base_sample:x} (~{self.binary_entropy_bits} bits){null_note}")
        if self.libc_base_sample:
            null_note = " [NUL@byte6]" if self.libc_has_nulls else ""
            lines.append(f"  Libc: 0x{self.libc_base_sample:x} (~{self.libc_entropy_bits} bits){null_note}")
        if self.stack_sample:
            null_note = " [NUL@byte6]" if self.stack_has_nulls else ""
            lines.append(f"  Stack: 0x{self.stack_sample:x} (~{self.stack_entropy_bits} bits){null_note}")
        if self.heap_sample:
            lines.append(f"  Heap: 0x{self.heap_sample:x}")
        if self.binary_has_nulls or self.libc_has_nulls or self.stack_has_nulls:
            lines.append(f"  Max strcpy write: {self.max_strcpy_bytes} bytes (null at position {self.null_byte_position})")
        return "\n".join(lines)


@dataclass
class SeccompInfo:
    """Seccomp/sandbox detection results."""
    seccomp_mode: int = 0  # 0=disabled, 1=strict, 2=filter
    seccomp_enabled: bool = False

    # Critical syscalls for exploitation
    execve_allowed: bool = True
    mprotect_allowed: bool = True
    mmap_allowed: bool = True
    open_allowed: bool = True
    read_allowed: bool = True
    write_allowed: bool = True

    # Raw filter info (if available from seccomp-tools)
    filter_rules: List[str] = field(default_factory=list)

    def __repr__(self) -> str:
        mode = {0: "disabled", 1: "strict", 2: "filter"}.get(self.seccomp_mode, "unknown")
        return f"SeccompInfo(mode={mode}, execve={self.execve_allowed}, mprotect={self.mprotect_allowed})"

    def summary(self) -> str:
        if not self.seccomp_enabled:
            return "SECCOMP: Disabled"

        lines = ["SECCOMP: ENABLED"]
        mode_names = {0: "disabled", 1: "strict", 2: "filter"}
        lines.append(f"  Mode: {mode_names.get(self.seccomp_mode, 'unknown')}")

        blocked = []
        if not self.execve_allowed:
            blocked.append("execve")
        if not self.mprotect_allowed:
            blocked.append("mprotect")
        if not self.mmap_allowed:
            blocked.append("mmap")

        if blocked:
            lines.append(f"  Blocked: {', '.join(blocked)}")
        return "\n".join(lines)


@dataclass
class PayloadConstraints:
    """Constraints on payload bytes based on input handling."""
    # Bytes that cannot appear in payload
    bad_bytes: List[int] = field(default_factory=list)

    # Reasons why each bad byte is problematic (maps byte value to reason string)
    bad_byte_reasons: Dict[int, str] = field(default_factory=dict)

    # How input is read (affects constraints)
    input_handler: str = ""  # strcpy, fgets, scanf, read, etc.

    # Additional constraints
    max_length: Optional[int] = None
    must_be_printable: bool = False
    must_be_alphanumeric: bool = False
    newline_terminates: bool = False

    # How many 64-bit addresses can be embedded in payload
    # strcpy: 1 (null at byte 6 terminates), fgets/read: -1 (unlimited)
    max_embeddable_addresses: int = 0

    # Allowed character set (if restricted, e.g., "A-Za-z0-9")
    allowed_charset: str = ""

    # Encoding suggestions based on constraints
    encoding_notes: List[str] = field(default_factory=list)

    # Encoding suggestions for exploit payloads
    encoding_suggestions: List[str] = field(default_factory=list)

    def __post_init__(self):
        """Validate bad_bytes are in valid byte range."""
        for i, b in enumerate(self.bad_bytes):
            if not isinstance(b, int) or b < 0 or b > 255:
                raise ValueError(f"PayloadConstraints.bad_bytes[{i}] must be 0-255, got {b}")
        if self.max_length is not None and self.max_length < 0:
            raise ValueError(f"PayloadConstraints.max_length must be non-negative, got {self.max_length}")

    def __repr__(self) -> str:
        handler = self.input_handler or "unknown"
        return f"PayloadConstraints(handler={handler!r}, bad_bytes={len(self.bad_bytes)}, max_len={self.max_length})"

    def summary(self) -> str:
        lines = ["PAYLOAD CONSTRAINTS:"]
        if self.input_handler:
            lines.append(f"  Input handler: {self.input_handler}")
        if self.bad_bytes:
            hex_bytes = ", ".join(f"0x{b:02x}" for b in sorted(self.bad_bytes)[:10])
            if len(self.bad_bytes) > 10:
                hex_bytes += f" ... ({len(self.bad_bytes)} total)"
            lines.append(f"  Bad bytes: {hex_bytes}")
        if self.max_length:
            lines.append(f"  Max length: {self.max_length}")
        if self.must_be_printable:
            lines.append("  Must be printable ASCII")
        if self.encoding_notes:
            lines.append("  Notes:")
            for note in self.encoding_notes:
                lines.append(f"    - {note}")
        return "\n".join(lines)


@dataclass
class WriteTarget:
    """A potential write target for exploitation."""
    name: str
    address: int  # Offset from base (PIE) or absolute
    is_absolute: bool = False  # True if address is absolute

    # Feasibility
    needs_leak: bool = True
    has_bad_bytes: bool = False
    writable: bool = True

    # Reliability rating
    reliability: str = "medium"  # low/medium/high

    # Usage notes
    notes: str = ""

    def __post_init__(self):
        """Validate target properties."""
        if not self.name:
            raise ValueError("WriteTarget.name cannot be empty")
        if self.address < 0:
            raise ValueError(f"WriteTarget.address must be non-negative, got {self.address}")
        if self.reliability not in ('low', 'medium', 'high'):
            raise ValueError(f"WriteTarget.reliability must be 'low', 'medium', or 'high', got {self.reliability!r}")

    def __repr__(self) -> str:
        addr = f"0x{self.address:x}" if self.address else "dynamic"
        flags = []
        if self.has_bad_bytes:
            flags.append("bad")
        if self.needs_leak:
            flags.append("leak")
        flag_str = f" [{','.join(flags)}]" if flags else ""
        return f"WriteTarget({self.name!r}, {addr}{flag_str})"

    def summary(self) -> str:
        if self.address:
            addr_str = f"0x{self.address:x}"
            if not self.is_absolute:
                addr_str += " (offset)"
        else:
            addr_str = "dynamic"
        flags = []
        if self.needs_leak:
            flags.append("needs leak")
        if self.has_bad_bytes:
            flags.append("bad bytes")
        if not self.writable:
            flags.append("read-only")
        flag_str = f" [{', '.join(flags)}]" if flags else ""
        return f"{self.name} @ {addr_str}{flag_str}"


@dataclass
class ExploitPrimitive:
    """What exploit primitives a vulnerability provides."""
    name: str  # Vulnerability type

    # Capabilities - arbitrary (anywhere in memory)
    arbitrary_read: bool = False
    arbitrary_write: bool = False

    # Capabilities - relative (offset from base, e.g., OOB access)
    relative_read: bool = False   # Out-of-bounds read from buffer
    relative_write: bool = False  # Out-of-bounds write from buffer

    # Capabilities - limited (sequential, not arbitrary target)
    limited_write: bool = False   # Sequential overflow, not write-what-where

    # Control flow capabilities
    control_rip: bool = False     # Can hijack instruction pointer
    control_rsp: bool = False     # Can control stack pointer (stack pivot)

    # Other capabilities
    info_leak: bool = False       # Can leak memory contents
    heap_control: bool = False    # Can manipulate heap metadata/layout

    # Write characteristics
    write_size: str = ""  # "1 byte", "4 bytes", "arbitrary", "sequential overflow"
    write_count: str = ""  # "single", "multiple", "unlimited"

    # Requirements
    requires_leak: bool = False           # Needs info leak first (PIE/ASLR)
    requires_heap_feng_shui: bool = False # Needs heap grooming/layout control

    notes: str = ""

    def __repr__(self) -> str:
        caps = []
        if self.arbitrary_write:
            caps.append("arb-W")
        if self.arbitrary_read:
            caps.append("arb-R")
        if self.relative_write:
            caps.append("rel-W")
        if self.relative_read:
            caps.append("rel-R")
        if self.limited_write:
            caps.append("lim-W")
        if self.control_rip:
            caps.append("RIP")
        if self.control_rsp:
            caps.append("RSP")
        if self.info_leak:
            caps.append("leak")
        if self.heap_control:
            caps.append("heap")
        caps_str = ",".join(caps) if caps else "none"
        return f"ExploitPrimitive({self.name!r}, [{caps_str}])"

    def summary(self) -> str:
        caps = []
        if self.arbitrary_write:
            caps.append("arb-write")
        if self.arbitrary_read:
            caps.append("arb-read")
        if self.relative_write:
            caps.append("rel-write (OOB)")
        if self.relative_read:
            caps.append("rel-read (OOB)")
        if self.limited_write:
            caps.append("limited-write")
        if self.control_rip:
            caps.append("RIP control")
        if self.control_rsp:
            caps.append("RSP control (stack pivot)")
        if self.info_leak:
            caps.append("info-leak")
        if self.heap_control:
            caps.append("heap-ctrl")
        if self.requires_heap_feng_shui:
            caps.append("needs heap grooming")
        return f"{self.name}: {', '.join(caps) if caps else 'none'}"


@dataclass
class ExploitationConstraints:
    """
    Architectural constraints that block or limit exploitation techniques.

    This captures constraints that should be known BEFORE exploit development,
    saving time by ruling out impossible approaches early.
    """
    # Architecture info
    arch: str = "x86_64"  # x86_64, i386, arm64, arm
    pointer_size: int = 8

    # Null byte position in addresses (x86_64 userland: byte 6, i.e., 0x00007fff...)
    # This is an ARCHITECTURAL CONSTANT, not detected per-sample
    null_byte_position: int = 6

    # Maximum bytes writeable via strcpy before hitting null
    # x86_64: addresses have 6 non-null bytes (low 6), then 0x00 at position 6
    max_strcpy_bytes: int = 6

    # Can we build multi-gadget ROP chains via strcpy overflow?
    # FALSE on x86_64: each 8-byte address has null at byte 6, strcpy stops after first
    strcpy_rop_viable: bool = False

    # Explanation of why ROP is/isn't viable
    strcpy_rop_reason: str = ""

    # Techniques that WILL NOT WORK given these constraints
    blocked_techniques: List[str] = field(default_factory=list)

    # Techniques that MAY work
    viable_techniques: List[str] = field(default_factory=list)

    # Input handler that determines these constraints
    input_handler: str = ""

    def __repr__(self) -> str:
        return (f"ExploitationConstraints(arch={self.arch!r}, ptr={self.pointer_size}b, "
                f"strcpy_rop={self.strcpy_rop_viable}, blocked={len(self.blocked_techniques)})")

    def __post_init__(self):
        """Validate and set architecture-specific defaults."""
        # Validate architecture is known
        known_archs = ['x86_64', 'i386', 'aarch64', 'arm64', 'arm', 'arm32', 'armv7', 'mips', 'mips32', 'mips64']
        if self.arch not in known_archs:
            raise ValueError(f"ExploitationConstraints.arch must be one of {known_archs}, got {self.arch!r}")
        if self.pointer_size not in (4, 8):
            raise ValueError(f"ExploitationConstraints.pointer_size must be 4 or 8, got {self.pointer_size}")

        # Set architecture-specific defaults
        if self.arch == "x86_64":
            self.pointer_size = 8
            self.null_byte_position = 6
            self.max_strcpy_bytes = 6
            # On x86_64 with strcpy, ROP chains are NOT viable
            if self.input_handler in ['strcpy', 'strcat', 'sprintf', 'gets']:
                self.strcpy_rop_viable = False
                self.strcpy_rop_reason = (
                    "x86_64 addresses have null bytes at position 6-7 (0x00007fff...). "
                    "strcpy stops at first null, so only 6 bytes of first address are copied. "
                    "Multi-gadget ROP chains are impossible via strcpy overflow."
                )
                self.blocked_techniques = [
                    "strcpy multi-gadget ROP",
                    "strcpy ret2libc chain (pop_rdi + bin_sh + system)",
                    "strcpy stack pivot to buffer (pivot addr has nulls)",
                ]
                self.viable_techniques = [
                    "format string %n writes (bypass null byte limit)",
                    "partial overwrite (change low bytes to redirect within region)",
                    "ret2csu (if binary has usable __libc_csu_init gadgets)",
                    "single gadget redirect (one_gadget if constraints met)",
                ]
        elif self.arch == "i386":
            self.pointer_size = 4
            self.null_byte_position = 4  # 32-bit addresses can be fully non-null
            self.max_strcpy_bytes = 4
            # On i386, addresses CAN be null-free if chosen carefully
            self.strcpy_rop_viable = True  # Maybe, depends on specific addresses
            self.strcpy_rop_reason = "32-bit addresses may be null-free depending on ASLR"
        elif self.arch in ["aarch64", "arm64"]:
            self.pointer_size = 8
            # AArch64 uses 48-bit virtual addresses in userland (0x0000000000000000 - 0x0000FFFFFFFFFFFF)
            # High 16 bits are always 0, so null bytes at positions 6-7
            self.null_byte_position = 6
            self.max_strcpy_bytes = 6
            if self.input_handler in ['strcpy', 'strcat', 'sprintf', 'gets']:
                self.strcpy_rop_viable = False
                self.strcpy_rop_reason = (
                    "AArch64 userland addresses have null bytes at position 6-7 (48-bit VAs). "
                    "Same null byte issue as x86_64. "
                    "Additionally, AArch64 uses fixed-width 4-byte instructions."
                )
                self.blocked_techniques = [
                    "strcpy multi-gadget ROP",
                    "strcpy ret2libc chain",
                ]
                self.viable_techniques = [
                    "format string writes",
                    "partial overwrite (2-4 byte changes)",
                    "JOP (Jump-Oriented Programming) if gadgets available",
                    "one_gadget (if ARM version available and constraints met)",
                ]
        elif self.arch in ["arm", "arm32", "armv7"]:
            self.pointer_size = 4
            # ARM32 uses 32-bit addresses, can be fully non-null
            self.null_byte_position = 4
            self.max_strcpy_bytes = 4
            self.strcpy_rop_viable = True
            self.strcpy_rop_reason = (
                "ARM32 uses 32-bit addresses which may be null-free. "
                "Note: ARM has Thumb mode (2-byte) and ARM mode (4-byte) instructions. "
                "ROP gadgets must respect mode switching (BX instructions)."
            )
            if self.input_handler in ['strcpy', 'strcat', 'sprintf', 'gets']:
                self.viable_techniques = [
                    "ROP chains (if addresses are null-free)",
                    "ret2libc",
                    "Thumb gadgets (smaller addresses, more likely null-free)",
                ]
                self.blocked_techniques = [
                    # ARM32 doesn't inherently block ROP via strcpy
                ]
        elif self.arch in ["mips", "mips32"]:
            self.pointer_size = 4
            # MIPS32: 32-bit addresses, but cache coherency can complicate shellcode
            self.null_byte_position = 4
            self.max_strcpy_bytes = 4
            self.strcpy_rop_viable = True
            self.strcpy_rop_reason = (
                "MIPS32 uses 32-bit addresses which may be null-free. "
                "Note: MIPS has branch delay slots - gadgets include instruction after branch."
            )
        elif self.arch in ["mips64"]:
            self.pointer_size = 8
            self.null_byte_position = 6
            self.max_strcpy_bytes = 6
            self.strcpy_rop_viable = False
            self.strcpy_rop_reason = "MIPS64 has same null byte issue as other 64-bit architectures"

    def summary(self) -> str:
        lines = ["EXPLOITATION CONSTRAINTS:"]
        lines.append(f"  Architecture: {self.arch} ({self.pointer_size}-byte pointers)")
        lines.append(f"  Null byte position: byte {self.null_byte_position}")
        lines.append(f"  Max strcpy bytes: {self.max_strcpy_bytes}")
        lines.append(f"  strcpy ROP viable: {'YES' if self.strcpy_rop_viable else 'NO'}")

        if self.strcpy_rop_reason:
            lines.append(f"  Reason: {self.strcpy_rop_reason[:80]}...")

        if self.blocked_techniques:
            lines.append("  BLOCKED techniques:")
            for t in self.blocked_techniques[:5]:
                lines.append(f"    ✗ {t}")

        if self.viable_techniques:
            lines.append("  VIABLE techniques:")
            for t in self.viable_techniques[:5]:
                lines.append(f"    ✓ {t}")

        return "\n".join(lines)


# =============================================================================
# Binary Context - Main reconnaissance container
# =============================================================================

@dataclass
class BinaryContext:
    """
    Shared reconnaissance data for binary analysis.

    This class collects and stores all information needed for both
    mitigation analysis and exploit development. It can be:
    - Populated incrementally (collect what you need)
    - Serialized to JSON for caching
    - Passed between analysis phases
    """
    binary_path: str = ""

    # Collected reconnaissance data
    libc_info: Optional[LibcInfo] = None
    rop_gadgets: Optional[ROPGadgetInfo] = None
    elf_structure: Optional[ELFStructure] = None
    address_space: Optional[AddressSpaceInfo] = None
    payload_constraints: Optional[PayloadConstraints] = None
    seccomp_info: Optional[SeccompInfo] = None

    # Binary protections (from checksec)
    protections: Dict[str, bool] = field(default_factory=dict)

    # Detected input handlers
    input_handlers: List[str] = field(default_factory=list)

    # Write targets (ranked)
    write_targets: List[WriteTarget] = field(default_factory=list)

    # Exploit primitives (based on vuln type)
    exploit_primitives: Optional[ExploitPrimitive] = None

    # Exploitation constraints (architectural limits)
    exploitation_constraints: Optional[ExploitationConstraints] = None

    # System info
    glibc_version: str = ""
    glibc_major_minor: float = 0.0
    kernel_version: str = ""
    aslr_level: int = 2

    # Collection status
    _collected: Dict[str, bool] = field(default_factory=dict)

    def __repr__(self) -> str:
        name = Path(self.binary_path).name if self.binary_path else "unknown"
        prots = []
        if self.protections.get('pie'):
            prots.append("PIE")
        if self.protections.get('canary'):
            prots.append("canary")
        if self.protections.get('full_relro'):
            prots.append("RELRO")
        prot_str = ",".join(prots) if prots else "none"
        return f"BinaryContext({name!r}, [{prot_str}], glibc={self.glibc_major_minor})"

    def __post_init__(self):
        if self.binary_path:
            self.binary_path = str(Path(self.binary_path).resolve())

    # =========================================================================
    # Collection Methods
    # =========================================================================

    def collect_all(self, bad_bytes: List[int] = None, arch: str = "x86_64"):
        """Collect all reconnaissance data."""
        self.collect_protections()
        self.collect_input_handlers()
        self.collect_libc_info()
        self.collect_elf_structure()
        self.collect_rop_gadgets(bad_bytes)
        self.collect_address_space()
        self.collect_seccomp()
        self.infer_payload_constraints()
        self.infer_exploitation_constraints(arch)

    def collect_protections(self):
        """Collect binary protections using checksec/readelf."""
        if not self.binary_path:
            return

        self.protections = {
            'relro': False,
            'full_relro': False,
            'pie': False,
            'nx': True,  # Assume NX by default
            'canary': False,
            'fortify': False,
        }

        try:
            # Use readelf to check protections
            result = subprocess.run(
                ['readelf', '-d', self.binary_path],
                capture_output=True, text=True, timeout=10
            )

            output = result.stdout
            if 'BIND_NOW' in output:
                self.protections['full_relro'] = True
                self.protections['relro'] = True
            elif 'RELRO' in output or 'GNU_RELRO' in output:
                self.protections['relro'] = True

            # Check for PIE
            result = subprocess.run(
                ['readelf', '-h', self.binary_path],
                capture_output=True, text=True, timeout=10
            )
            if 'DYN' in result.stdout:
                self.protections['pie'] = True

            # Check for stack canary
            result = subprocess.run(
                ['readelf', '-s', self.binary_path],
                capture_output=True, text=True, timeout=10
            )
            if '__stack_chk_fail' in result.stdout:
                self.protections['canary'] = True

            # Check for FORTIFY
            if '__fortify_fail' in result.stdout or '_chk@' in result.stdout:
                self.protections['fortify'] = True

        except Exception as e:
            logger.debug(f"Protection check failed: {e}")

        self._collected['protections'] = True
        logger.info(f"Binary protections: {self.protections}")

    def collect_input_handlers(self):
        """Detect input handling functions from binary imports."""
        if not self.binary_path:
            return

        # Common input functions that affect payload constraints
        input_funcs = {
            'strcpy', 'strncpy', 'strcat', 'strncat',  # NUL-terminated
            'gets', 'fgets', 'getline',  # Line-based
            'scanf', 'fscanf', 'sscanf',  # Format-based
            'read', 'fread', 'recv', 'recvfrom',  # Raw binary
            'sprintf', 'snprintf', 'vsprintf',  # Format output
            'printf', 'fprintf', 'vprintf',  # Format (for format string vulns)
            'memcpy', 'memmove',  # Binary copy
        }

        try:
            result = subprocess.run(
                ['nm', '-D', self.binary_path],
                capture_output=True, text=True, timeout=10
            )

            for line in result.stdout.split('\n'):
                for func in input_funcs:
                    if f' {func}@' in line or f' {func}' in line.split()[-1:]:
                        if func not in self.input_handlers:
                            self.input_handlers.append(func)

        except Exception as e:
            logger.debug(f"Input handler detection failed: {e}")

        self._collected['input_handlers'] = True
        if self.input_handlers:
            logger.info(f"Detected input handlers: {', '.join(self.input_handlers)}")

    def collect_libc_info(self):
        """Query libc for offsets needed in exploitation."""
        self.libc_info = LibcInfo()

        try:
            # Find libc path
            if self.binary_path:
                result = subprocess.run(
                    ['ldd', self.binary_path],
                    capture_output=True, text=True, timeout=10
                )
                for line in result.stdout.split('\n'):
                    if 'libc.so' in line:
                        parts = line.split()
                        for part in parts:
                            if part.startswith('/'):
                                self.libc_info.path = part
                                break

            # Fallback: check common paths
            if not self.libc_info.path:
                for path in ['/lib/x86_64-linux-gnu/libc.so.6',
                             '/lib64/libc.so.6',
                             '/usr/lib/libc.so.6']:
                    if Path(path).exists():
                        self.libc_info.path = path
                        break

            if not self.libc_info.path:
                return

            # Get libc version
            result = subprocess.run(
                [self.libc_info.path],
                capture_output=True, text=True, timeout=5
            )
            self.libc_info.version = result.stdout.split('\n')[0] if result.stdout else ""

            # Get symbol offsets using nm
            result = subprocess.run(
                ['nm', '-D', self.libc_info.path],
                capture_output=True, text=True, timeout=30
            )

            for line in result.stdout.split('\n'):
                parts = line.split()
                if len(parts) >= 3:
                    addr, _, name = parts[0], parts[1], parts[2]
                    try:
                        offset = int(addr, 16)
                        if name == 'system':
                            self.libc_info.system_offset = offset
                        elif name == 'execve':
                            self.libc_info.execve_offset = offset
                        elif name == '__environ' or name == 'environ':
                            self.libc_info.environ_offset = offset
                        elif name == '__malloc_hook':
                            self.libc_info.malloc_hook_offset = offset
                        elif name == '__free_hook':
                            self.libc_info.free_hook_offset = offset
                    except ValueError:
                        continue

            # Find /bin/sh string offset
            result = subprocess.run(
                ['strings', '-t', 'x', self.libc_info.path],
                capture_output=True, text=True, timeout=30
            )
            for line in result.stdout.split('\n'):
                if '/bin/sh' in line:
                    parts = line.strip().split(None, 1)
                    if parts:
                        try:
                            self.libc_info.bin_sh_offset = int(parts[0], 16)
                            break
                        except ValueError:
                            continue

            # Try one_gadget if available
            try:
                result = subprocess.run(
                    ['one_gadget', self.libc_info.path],
                    capture_output=True, text=True, timeout=60
                )
                for line in result.stdout.split('\n'):
                    if line.startswith('0x'):
                        try:
                            offset = int(line.split()[0], 16)
                            self.libc_info.one_gadgets.append(offset)
                        except (ValueError, IndexError):
                            continue
            except FileNotFoundError:
                pass  # one_gadget not installed

        except Exception as e:
            logger.debug(f"Libc info collection failed: {e}")

        self._collected['libc_info'] = True
        logger.info(f"Libc path: {self.libc_info.path}")

    def collect_elf_structure(self):
        """Parse ELF structure for write targets."""
        if not self.binary_path:
            return

        self.elf_structure = ELFStructure()

        try:
            # Get section headers
            result = subprocess.run(
                ['readelf', '-S', self.binary_path],
                capture_output=True, text=True, timeout=10
            )

            for line in result.stdout.split('\n'):
                # Parse section info
                if '.got.plt' in line:
                    match = re.search(r'([0-9a-f]+)\s+([0-9a-f]+)\s+', line)
                    if match:
                        self.elf_structure.got_plt_addr = int(match.group(1), 16)
                        self.elf_structure.got_plt_size = int(match.group(2), 16)
                elif '.fini_array' in line:
                    match = re.search(r'([0-9a-f]+)\s+([0-9a-f]+)\s+', line)
                    if match:
                        self.elf_structure.fini_array_addr = int(match.group(1), 16)
                        self.elf_structure.fini_array_size = int(match.group(2), 16)
                elif '.init_array' in line:
                    match = re.search(r'([0-9a-f]+)\s+', line)
                    if match:
                        self.elf_structure.init_array_addr = int(match.group(1), 16)
                elif '.bss' in line and '.bss' in line.split()[0:2]:
                    match = re.search(r'([0-9a-f]+)\s+([0-9a-f]+)\s+', line)
                    if match:
                        self.elf_structure.bss_addr = int(match.group(1), 16)
                        self.elf_structure.bss_size = int(match.group(2), 16)

            # Get GOT entries
            result = subprocess.run(
                ['readelf', '-r', self.binary_path],
                capture_output=True, text=True, timeout=10
            )

            for line in result.stdout.split('\n'):
                if 'JUMP_SLOT' in line or 'GLOB_DAT' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        try:
                            addr = int(parts[0], 16)
                            name = parts[-1].split('@')[0]
                            self.elf_structure.got_entries[name] = addr
                        except (ValueError, IndexError):
                            continue

            # Get PLT entries
            result = subprocess.run(
                ['objdump', '-d', '-j', '.plt', self.binary_path],
                capture_output=True, text=True, timeout=10
            )

            for line in result.stdout.split('\n'):
                if '@plt>' in line:
                    match = re.search(r'([0-9a-f]+)\s+<(\w+)@plt>', line)
                    if match:
                        addr = int(match.group(1), 16)
                        name = match.group(2)
                        self.elf_structure.plt_entries[name] = addr

        except Exception as e:
            logger.debug(f"ELF structure analysis failed: {e}")

        self._collected['elf_structure'] = True
        logger.info(f"ELF structure: GOT={len(self.elf_structure.got_entries)} entries, "
                   f"PLT={len(self.elf_structure.plt_entries)} entries")

    def collect_rop_gadgets(self, bad_bytes: List[int] = None):
        """Analyze ROP gadgets in the binary."""
        if not self.binary_path:
            return

        if bad_bytes is None:
            bad_bytes = []
            if self.payload_constraints:
                bad_bytes = self.payload_constraints.bad_bytes

        self.rop_gadgets = ROPGadgetInfo()

        try:
            result = subprocess.run(
                ['ROPgadget', '--binary', self.binary_path],
                capture_output=True, text=True, timeout=120
            )

            gadgets = []
            for line in result.stdout.split('\n'):
                if ' : ' in line:
                    parts = line.split(' : ', 1)
                    if len(parts) == 2:
                        try:
                            addr = int(parts[0].strip(), 16)
                            insn = parts[1].strip()
                            gadgets.append({'address': addr, 'instructions': insn})
                        except ValueError:
                            continue

            self.rop_gadgets.total_gadgets = len(gadgets)

            # Filter by bad bytes
            def has_bad_bytes(addr: int) -> bool:
                addr_bytes = addr.to_bytes(8, 'little')
                return any(b in bad_bytes for b in addr_bytes)

            usable = []
            for g in gadgets:
                if not has_bad_bytes(g['address']):
                    usable.append(g)
                else:
                    self.rop_gadgets.filtered_by_bad_bytes += 1

            self.rop_gadgets.usable_gadgets = len(usable)
            self.rop_gadgets.all_gadgets = usable

            # Find essential gadgets
            for g in usable:
                insn = g['instructions'].lower()
                addr = g['address']

                if 'pop rdi' in insn and 'ret' in insn and not self.rop_gadgets.pop_rdi_ret:
                    self.rop_gadgets.pop_rdi_ret = addr
                elif 'pop rsi' in insn and 'ret' in insn and not self.rop_gadgets.pop_rsi_ret:
                    self.rop_gadgets.pop_rsi_ret = addr
                elif 'pop rdx' in insn and 'ret' in insn and not self.rop_gadgets.pop_rdx_ret:
                    self.rop_gadgets.pop_rdx_ret = addr
                elif 'pop rax' in insn and 'ret' in insn and not self.rop_gadgets.pop_rax_ret:
                    self.rop_gadgets.pop_rax_ret = addr
                elif insn == 'ret' and not self.rop_gadgets.ret:
                    self.rop_gadgets.ret = addr
                elif 'leave' in insn and 'ret' in insn and not self.rop_gadgets.leave_ret:
                    self.rop_gadgets.leave_ret = addr
                elif 'syscall' in insn and not self.rop_gadgets.syscall_ret:
                    self.rop_gadgets.syscall_ret = addr

        except FileNotFoundError:
            logger.warning("ROPgadget not installed")
        except Exception as e:
            logger.debug(f"ROP gadget analysis failed: {e}")

        self._collected['rop_gadgets'] = True
        logger.info(f"ROP gadgets: {self.rop_gadgets.total_gadgets} total, "
                   f"{self.rop_gadgets.usable_gadgets} usable")

    def collect_address_space(self, num_samples: int = 5):
        """Sample address space to understand ASLR entropy."""
        if not self.binary_path:
            return

        self.address_space = AddressSpaceInfo()
        binary_name = Path(self.binary_path).name

        binary_bases = []
        libc_bases = []
        stack_addrs = []
        heap_addrs = []

        for _ in range(num_samples):
            try:
                proc = subprocess.Popen(
                    [self.binary_path],
                    stdin=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )

                try:
                    with open(f"/proc/{proc.pid}/maps", 'r') as f:
                        for line in f:
                            parts = line.split()
                            if len(parts) < 6:
                                continue

                            addr_range = parts[0]
                            perms = parts[1]
                            pathname = parts[5] if len(parts) > 5 else ""

                            start_addr = int(addr_range.split('-')[0], 16)

                            if binary_name in pathname and 'x' in perms:
                                binary_bases.append(start_addr)
                            elif 'libc' in pathname and 'x' in perms:
                                libc_bases.append(start_addr)
                            elif '[stack]' in pathname:
                                stack_addrs.append(start_addr)
                            elif '[heap]' in pathname:
                                heap_addrs.append(start_addr)
                finally:
                    proc.kill()
                    proc.wait()

            except Exception as e:
                logger.debug(f"Address space sample failed: {e}")

        def analyze_samples(samples: List[int]):
            if not samples:
                return None, 0, True  # Assume nulls if no samples
            if len(samples) < 2:
                base = samples[0]
                # x86_64 ARCHITECTURAL CONSTRAINT: All userland addresses are
                # in canonical form 0x0000000000000000 - 0x00007FFFFFFFFFFF
                # This means bytes 6-7 are ALWAYS 0x00 for userland addresses.
                # Don't just check the sampled value - recognize the architectural fact.
                has_nulls = True  # Always true for x86_64 userland
                return base, 0, has_nulls

            base = samples[0]
            varying = 0
            for s in samples[1:]:
                varying |= (base ^ s)

            entropy = bin(varying).count('1')
            # x86_64 ARCHITECTURAL CONSTRAINT: userland addresses ALWAYS have
            # null bytes at positions 6-7 due to canonical address format.
            # The low 6 bytes may or may not contain nulls depending on the
            # specific address, but the high bytes are guaranteed null.
            has_nulls = True  # Always true for x86_64 userland
            return base, entropy, has_nulls

        if binary_bases:
            base, entropy, nulls = analyze_samples(binary_bases)
            self.address_space.binary_base_sample = base
            self.address_space.binary_entropy_bits = entropy
            self.address_space.binary_has_nulls = nulls

        if libc_bases:
            base, entropy, nulls = analyze_samples(libc_bases)
            self.address_space.libc_base_sample = base
            self.address_space.libc_entropy_bits = entropy
            self.address_space.libc_has_nulls = nulls

        if stack_addrs:
            base, entropy, nulls = analyze_samples(stack_addrs)
            self.address_space.stack_sample = base
            self.address_space.stack_entropy_bits = entropy
            self.address_space.stack_has_nulls = nulls

        if heap_addrs:
            base, _, _ = analyze_samples(heap_addrs)
            self.address_space.heap_sample = base

        self._collected['address_space'] = True
        base_str = f"0x{self.address_space.binary_base_sample:x}" if self.address_space.binary_base_sample else "N/A"
        logger.info(f"Address space sampled: binary={base_str}")

    def collect_seccomp(self):
        """Check for seccomp sandbox restrictions."""
        self.seccomp_info = SeccompInfo()

        try:
            # Check current process (may not reflect target)
            with open('/proc/self/status', 'r') as f:
                for line in f:
                    if line.startswith('Seccomp:'):
                        mode = int(line.split(':')[1].strip())
                        self.seccomp_info.seccomp_mode = mode
                        self.seccomp_info.seccomp_enabled = mode > 0
                        break

            # Try seccomp-tools if available
            if self.binary_path:
                try:
                    result = subprocess.run(
                        ['seccomp-tools', 'dump', self.binary_path],
                        capture_output=True, text=True, timeout=10
                    )
                    if result.returncode == 0 and result.stdout:
                        self.seccomp_info.filter_rules = result.stdout.strip().split('\n')

                        # Parse for blocked syscalls
                        output = result.stdout.lower()
                        if 'execve' in output and 'kill' in output:
                            self.seccomp_info.execve_allowed = False
                        if 'mprotect' in output and 'kill' in output:
                            self.seccomp_info.mprotect_allowed = False

                except FileNotFoundError:
                    pass  # seccomp-tools not installed

        except Exception as e:
            logger.debug(f"Seccomp check failed: {e}")

        self._collected['seccomp'] = True
        logger.info(f"Seccomp: {'enabled' if self.seccomp_info.seccomp_enabled else 'disabled'}")

    def infer_payload_constraints(self, input_handler: str = None):
        """Infer payload byte constraints based on input handling."""
        self.payload_constraints = PayloadConstraints()

        if input_handler:
            self.payload_constraints.input_handler = input_handler
        elif self.input_handlers:
            # Use first detected handler as primary
            self.payload_constraints.input_handler = self.input_handlers[0]

        handler = self.payload_constraints.input_handler.lower() if self.payload_constraints.input_handler else ""

        # NUL byte constraints
        if any(h in handler for h in ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf', 'printf']):
            self.payload_constraints.bad_bytes.append(0x00)
            self.payload_constraints.encoding_notes.append("NUL terminates string operations")

        # Newline constraints
        if any(h in handler for h in ['fgets', 'gets', 'getline']):
            self.payload_constraints.bad_bytes.append(0x0a)
            self.payload_constraints.newline_terminates = True
            self.payload_constraints.encoding_notes.append("Newline terminates line-based input")

        # Whitespace constraints (scanf with %s)
        if 'scanf' in handler:
            for b in [0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x20]:  # Whitespace
                if b not in self.payload_constraints.bad_bytes:
                    self.payload_constraints.bad_bytes.append(b)
            self.payload_constraints.encoding_notes.append("Whitespace terminates scanf %s")

        self._collected['payload_constraints'] = True

    def infer_exploitation_constraints(self, arch: str = "x86_64"):
        """
        Infer exploitation constraints based on architecture and input handlers.

        This determines what techniques are blocked vs viable BEFORE exploit
        development begins, preventing wasted effort on impossible approaches.
        """
        # Determine primary input handler
        input_handler = ""
        if self.payload_constraints and self.payload_constraints.input_handler:
            input_handler = self.payload_constraints.input_handler
        elif self.input_handlers:
            # Prioritize null-terminating handlers as they're most constraining
            for h in ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf']:
                if h in self.input_handlers:
                    input_handler = h
                    break
            if not input_handler:
                input_handler = self.input_handlers[0]

        # Create constraints with input handler context
        self.exploitation_constraints = ExploitationConstraints(
            arch=arch,
            input_handler=input_handler
        )

        # __post_init__ handles setting blocked/viable techniques based on arch+handler

        self._collected['exploitation_constraints'] = True
        logger.info(f"Exploitation constraints: strcpy_rop_viable={self.exploitation_constraints.strcpy_rop_viable}")

    def rank_write_targets(self, bad_bytes: List[int] = None):
        """Rank potential write targets based on feasibility."""
        if bad_bytes is None:
            bad_bytes = self.payload_constraints.bad_bytes if self.payload_constraints else []

        def has_bad_bytes(addr: int) -> bool:
            if not addr:
                return False
            return any(b in bad_bytes for b in addr.to_bytes(8, 'little'))

        targets = []

        # GOT entries (if not Full RELRO)
        if not self.protections.get('full_relro') and self.elf_structure:
            for func, addr in self.elf_structure.got_entries.items():
                targets.append(WriteTarget(
                    name=f"GOT[{func}]",
                    address=addr,
                    has_bad_bytes=has_bad_bytes(addr),
                    needs_leak=self.protections.get('pie', False),
                    reliability="high",
                    notes="Redirect function call"
                ))

        # .fini_array
        if self.elf_structure and self.elf_structure.fini_array_addr:
            targets.append(WriteTarget(
                name=".fini_array[0]",
                address=self.elf_structure.fini_array_addr,
                has_bad_bytes=has_bad_bytes(self.elf_structure.fini_array_addr),
                needs_leak=self.protections.get('pie', False),
                reliability="high",
                notes="Called at exit, bypasses RELRO"
            ))

        # __malloc_hook (glibc < 2.34)
        if self.libc_info and self.libc_info.malloc_hook_offset:
            if self.glibc_major_minor < 2.34:
                targets.append(WriteTarget(
                    name="__malloc_hook",
                    address=self.libc_info.malloc_hook_offset,
                    has_bad_bytes=has_bad_bytes(self.libc_info.malloc_hook_offset),
                    needs_leak=True,
                    reliability="high",
                    notes="Triggered on malloc()"
                ))

        # Return address
        targets.append(WriteTarget(
            name="return_address",
            address=0,
            needs_leak=True,
            reliability="medium",
            notes="Overwrite saved RIP"
        ))

        # Sort: no bad bytes first, then by reliability
        reliability_order = {'high': 0, 'medium': 1, 'low': 2}
        targets.sort(key=lambda t: (t.has_bad_bytes, reliability_order.get(t.reliability, 3)))

        self.write_targets = targets
        self._collected['write_targets'] = True

    # =========================================================================
    # Serialization
    # =========================================================================

    def to_dict(self) -> Dict[str, Any]:
        """Convert context to dictionary for JSON serialization."""
        result = {
            'binary_path': self.binary_path,
            'protections': self.protections,
            'input_handlers': self.input_handlers,
            'glibc_version': self.glibc_version,
            'glibc_major_minor': self.glibc_major_minor,
            'kernel_version': self.kernel_version,
            'aslr_level': self.aslr_level,
        }

        if self.libc_info:
            result['libc_info'] = asdict(self.libc_info)
        if self.rop_gadgets:
            # Exclude all_gadgets to keep JSON small
            rg = asdict(self.rop_gadgets)
            rg['all_gadgets'] = []  # Too large
            result['rop_gadgets'] = rg
        if self.elf_structure:
            result['elf_structure'] = asdict(self.elf_structure)
        if self.address_space:
            result['address_space'] = asdict(self.address_space)
        if self.payload_constraints:
            result['payload_constraints'] = asdict(self.payload_constraints)
        if self.seccomp_info:
            result['seccomp_info'] = asdict(self.seccomp_info)
        if self.write_targets:
            result['write_targets'] = [asdict(t) for t in self.write_targets]
        if self.exploit_primitives:
            result['exploit_primitives'] = asdict(self.exploit_primitives)
        if self.exploitation_constraints:
            result['exploitation_constraints'] = asdict(self.exploitation_constraints)

        return result

    def save(self, path: str):
        """Save context to JSON file."""
        with open(path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)
        logger.info(f"Context saved to {path}")

    @classmethod
    def load(cls, path: str) -> 'BinaryContext':
        """Load context from JSON file."""
        with open(path, 'r') as f:
            data = json.load(f)

        ctx = cls(binary_path=data.get('binary_path', ''))
        ctx.protections = data.get('protections', {})
        ctx.input_handlers = data.get('input_handlers', [])
        ctx.glibc_version = data.get('glibc_version', '')
        ctx.glibc_major_minor = data.get('glibc_major_minor', 0.0)
        ctx.kernel_version = data.get('kernel_version', '')
        ctx.aslr_level = data.get('aslr_level', 2)

        if 'libc_info' in data:
            ctx.libc_info = LibcInfo(**data['libc_info'])
        if 'rop_gadgets' in data:
            ctx.rop_gadgets = ROPGadgetInfo(**data['rop_gadgets'])
        if 'elf_structure' in data:
            ctx.elf_structure = ELFStructure(**data['elf_structure'])
        if 'address_space' in data:
            ctx.address_space = AddressSpaceInfo(**data['address_space'])
        if 'payload_constraints' in data:
            ctx.payload_constraints = PayloadConstraints(**data['payload_constraints'])
        if 'seccomp_info' in data:
            ctx.seccomp_info = SeccompInfo(**data['seccomp_info'])
        if 'write_targets' in data:
            ctx.write_targets = [WriteTarget(**t) for t in data['write_targets']]
        if 'exploit_primitives' in data:
            ctx.exploit_primitives = ExploitPrimitive(**data['exploit_primitives'])
        if 'exploitation_constraints' in data:
            ctx.exploitation_constraints = ExploitationConstraints(**data['exploitation_constraints'])

        logger.info(f"Context loaded from {path}")
        return ctx

    # =========================================================================
    # Summary
    # =========================================================================

    def summary(self) -> str:
        """Generate human-readable summary of collected data."""
        lines = [
            "=" * 60,
            "BINARY CONTEXT (Reconnaissance Data)",
            "=" * 60,
        ]

        if self.binary_path:
            lines.append(f"Binary: {self.binary_path}")

        if self.protections:
            prot_str = ", ".join(f"{k}={'yes' if v else 'no'}" for k, v in self.protections.items())
            lines.append(f"Protections: {prot_str}")

        if self.input_handlers:
            lines.append(f"Input handlers: {', '.join(self.input_handlers)}")

        if self.libc_info:
            lines.append("")
            lines.append(self.libc_info.summary())

        if self.rop_gadgets:
            lines.append("")
            lines.append(self.rop_gadgets.summary())

        if self.elf_structure:
            lines.append("")
            lines.append(self.elf_structure.summary())

        if self.address_space:
            lines.append("")
            lines.append(self.address_space.summary())

        if self.payload_constraints:
            lines.append("")
            lines.append(self.payload_constraints.summary())

        if self.seccomp_info:
            lines.append("")
            lines.append(self.seccomp_info.summary())

        if self.write_targets:
            lines.append("")
            lines.append("WRITE TARGETS:")
            for i, t in enumerate(self.write_targets[:5], 1):
                lines.append(f"  {i}. {t.summary()}")

        if self.exploitation_constraints:
            lines.append("")
            lines.append(self.exploitation_constraints.summary())

        lines.append("=" * 60)
        return "\n".join(lines)
