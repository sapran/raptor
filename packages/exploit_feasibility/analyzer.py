#!/usr/bin/env python3
"""
Mitigation Analyzer - Check exploitation viability BEFORE attempting exploits

This module analyzes system and binary mitigations to determine if LOCAL
exploitation is feasible. It should be the FIRST step in any exploitation
workflow to avoid wasting time on blocked attack vectors.

SCOPE: LOCAL EXPLOITATION ONLY
==============================
This analyzer checks mitigations relevant to LOCAL binary exploitation:
- Memory corruption (buffer overflows, heap exploits, format strings)
- Code execution on the same machine as the vulnerable binary

DOES NOT APPLY TO:
- Remote/web vulnerabilities (SQLi, XSS, SSRF, etc.)
- Network-based attacks
- Application-logic vulnerabilities

For remote vulnerabilities, the "mitigations" are application-level
(input validation, parameterized queries, CSP, etc.) not system-level.

Key mitigations checked:
- glibc runtime mitigations (%n disabled in glibc 2.38+)
- Binary protections (RELRO, PIE, NX, Stack Canary, FORTIFY_SOURCE)
- Kernel mitigations (ASLR, SMEP, SMAP)
- Vulnerability-specific blockers

Usage:
    analyzer = FeasibilityAnalyzer(binary_path)
    report = analyzer.full_analysis(vuln_type="format_string")

    if report.verdict == ExploitabilityVerdict.UNLIKELY:
        print("Exploitation unlikely with current mitigations")
        for suggestion in report.bypass_suggestions:
            print(f"  Try: {suggestion}")
"""

import re
import subprocess
from collections import defaultdict
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from enum import Enum

from core.logging import get_logger
from .exploit_context import ExploitContext

# Import from modular files - these are the canonical definitions
from .context import (
    OneGadget,
    ExploitationConstraints,
    LibcInfo,
    ROPGadgetInfo,
    ELFStructure,
    AddressSpaceInfo,
    SeccompInfo,
    PayloadConstraints,
    WriteTarget,
    ExploitPrimitive,
    BinaryContext,
)
from .vuln_types import ExploitabilityVerdict, VulnerabilityType
from .mitigations import (
    MitigationImpact,
    GlibcMitigation,
    GlibcMitigations,
    KernelMitigation,
    KernelMitigations,
)
from .profiles import (
    TargetContext,
    TargetProfile,
    create_local_profile,
    create_remote_profile,
    create_web_profile,
    create_kernel_profile,
)
from .strategies import (
    AnalysisStrategy,
    LocalBinaryStrategy,
    RemoteBinaryStrategy,
    WebApplicationStrategy,
    KernelStrategy,
    get_analysis_strategy,
)
from .primitives import (
    PrimitiveID,
    PrimitiveType,
    MitigationID,
    Primitive,
    ConfidenceScore,
    ExploitPath,
)
from .techniques import (
    TechniqueRequirements,
    get_technique_requirements,
    get_technique,
    get_techniques_for_goal,
    get_viable_techniques,
    get_missing_primitives,
)
from .targets import (
    BinaryTarget,
    GadgetQuality,
    BinarySpecificAnalysis,
    analyze_gadget_quality,
    assess_technique_viability,
)
from .graph import PrimitiveNode, PrimitiveDependencyGraph, create_dependency_graph
from .primitives import get_primitive_definitions
# Note: cache.py provides CachedOneGadget, CachedOneGadgetResult, CachedROPGadgets
# for lightweight caching. This module uses its own rich dataclass versions.

logger = get_logger()

# =============================================================================
# MODULE ARCHITECTURE NOTE
# =============================================================================
# This module provides FeasibilityReport and FeasibilityAnalyzer classes.
#
# All dataclasses are imported from their canonical locations:
#   - primitives.py: Primitive, ConfidenceScore, ExploitPath, get_primitive_definitions()
#   - graph.py: PrimitiveNode, PrimitiveDependencyGraph, create_dependency_graph()
#   - targets.py: BinaryTarget, GadgetQuality, BinarySpecificAnalysis
#   - context.py: OneGadget, LibcInfo, ROPGadgetInfo, ELFStructure, WriteTarget,
#                 AddressSpaceInfo, SeccompInfo, PayloadConstraints, ExploitPrimitive
#   - techniques.py: TechniqueRequirements, get_technique_requirements()
#   - cache.py: CachedROPGadgets, CachedOneGadget, CachedLibcInfo (lightweight)
# =============================================================================


def analyze_binary_targets(
    binary_path: str,
    elf_structure: 'ELFStructure',
    binary_protections: Dict[str, bool],
    bad_bytes: Optional[List[int]] = None
) -> BinarySpecificAnalysis:
    """
    Analyze a binary and identify concrete exploitation targets.

    This is the key function that ties abstract mitigations to real addresses.
    The agent calls this to get actionable target information.

    Args:
        binary_path: Path to the binary
        elf_structure: Parsed ELF structure with GOT/sections
        binary_protections: Dict with relro, pie, nx, canary status
        bad_bytes: Bytes that cannot appear in addresses (e.g., [0x00, 0x0a])

    Returns:
        BinarySpecificAnalysis with concrete targets and feasibility
    """
    bad_bytes = bad_bytes or [0x00]  # NUL is common bad byte

    analysis = BinarySpecificAnalysis(
        binary_path=binary_path,
        has_full_relro=binary_protections.get('full_relro', False),
        has_partial_relro=binary_protections.get('relro', False) and not binary_protections.get('full_relro', False),
        has_pie=binary_protections.get('pie', False),
        has_nx=binary_protections.get('nx', False),
        has_canary=binary_protections.get('canary', False),
    )

    # Analyze GOT entries as targets
    if elf_structure.got_entries:
        for func_name, got_addr in elf_structure.got_entries.items():
            target = BinaryTarget(
                name=f"GOT[{func_name}]",
                address=got_addr,
                target_type="got_entry",
                technique="got_overwrite",
            )

            # Check if blocked by RELRO
            if analysis.has_full_relro:
                target.viable = False
                target.blocked_by.append("full_relro")
            else:
                target.viable = True
                # GOT overwrite is high value - direct control flow hijack
                target.priority = 80

            # Check for bad bytes in address
            target.has_bad_bytes, target.bad_byte_positions = _check_bad_bytes(got_addr, bad_bytes)
            if target.has_bad_bytes and target.viable:
                target.priority -= 20  # Reduce priority if bad bytes

            # What's needed
            if analysis.has_pie:
                target.requires.append("pie_leak")
            target.requires.append("libc_leak")  # Need target value

            # Prioritize commonly-called functions
            if func_name in ('puts', 'printf', 'exit', 'free', 'malloc'):
                target.priority += 10
                target.notes = f"Called frequently - good hijack target"
            elif func_name in ('__stack_chk_fail',):
                target.priority += 5
                target.notes = "Called on stack smash - hijack for canary bypass"

            analysis.targets.append(target)
            analysis.got_targets.append(target)

    # Analyze .fini_array
    if elf_structure.fini_array_addr:
        target = BinaryTarget(
            name=".fini_array[0]",
            address=elf_structure.fini_array_addr,
            target_type="fini_array",
            technique="fini_array_overwrite",
        )

        if analysis.has_full_relro:
            target.viable = False
            target.blocked_by.append("full_relro")
        else:
            target.viable = True
            target.priority = 70  # Good target - called at exit

        target.has_bad_bytes, target.bad_byte_positions = _check_bad_bytes(
            elf_structure.fini_array_addr, bad_bytes
        )

        if analysis.has_pie:
            target.requires.append("pie_leak")
        target.requires.append("libc_leak")  # For target value (one_gadget/system)

        # Analyze current value at .fini_array for partial overwrite feasibility
        #
        # .fini_array typically contains:
        #   - PIE binary: address in PIE range (0x55.../0x56...)
        #   - Non-PIE: fixed address (0x40.../0x60...)
        #
        # Target value could be:
        #   - libc one_gadget (0x7f...) - cross-region, needs full write
        #   - binary gadget (same region) - partial overwrite may work
        #   - stack pivot target - depends on address
        #
        # We note the constraint but don't assume libc is the only target.
        if analysis.has_pie:
            target.current_value_type = "pie_addr"
            target.target_value_type = "varies"  # Could be libc OR binary gadget
            # For libc target: PIE (0x55) → libc (0x7f) requires 6 bytes
            # For binary gadget: partial overwrite within PIE region may work
            target.partial_overwrite_bytes_needed = 6  # For cross-region (libc)
            target.partial_overwrite_viable = True  # For same-region (binary gadget)
            target.notes = (
                "PIE binary: contains PIE addr. "
                "For libc one_gadget: need 6+ byte write (cross-region). "
                "For binary gadget: 2-byte partial overwrite may work within PIE range."
            )
        else:
            # Non-PIE: .fini_array contains fixed binary address
            target.current_value_type = "binary_addr"
            target.target_value_type = "varies"
            target.partial_overwrite_viable = True  # Can partial overwrite to nearby addresses
            target.notes = "Non-PIE: fixed address, partial overwrite to nearby targets viable"

        analysis.targets.append(target)
        analysis.fini_array_targets.append(target)

    # Analyze .bss for writable data targets
    if elf_structure.bss_addr:
        target = BinaryTarget(
            name=".bss writable region",
            address=elf_structure.bss_addr,
            target_type="writable_data",
            technique="data_write",
            viable=True,  # Always writable
            priority=30,
        )
        target.has_bad_bytes, target.bad_byte_positions = _check_bad_bytes(
            elf_structure.bss_addr, bad_bytes
        )
        if analysis.has_pie:
            target.requires.append("pie_leak")
        target.notes = "Writable - store shellcode/ROP chain/fake struct"
        analysis.targets.append(target)
        analysis.other_targets.append(target)

    # Determine viable techniques based on targets and protections
    assess_technique_viability(analysis)

    return analysis


def _check_bad_bytes(address: int, bad_bytes: List[int]) -> Tuple[bool, List[int]]:
    """Check if address contains bad bytes, return positions."""
    positions = []
    addr_bytes = address.to_bytes(8, 'little')
    for i, b in enumerate(addr_bytes):
        if b in bad_bytes:
            positions.append(i)
    return bool(positions), positions


# Note: analyze_gadget_quality and assess_technique_viability are imported from targets.py


# ═══════════════════════════════════════════════════════════════════════════════
# PRIMITIVE DEPENDENCY GRAPH
# ═══════════════════════════════════════════════════════════════════════════════
#
# NOTE: Primitive, PrimitiveNode, ConfidenceScore, ExploitPath are imported from
# primitives.py. PrimitiveDependencyGraph and create_dependency_graph are imported
# from graph.py. get_primitive_definitions() provides the PRIMITIVES dictionary.
#
# Example chain: format_string_vuln → libc_leak → ret2libc → code_execution


# Note: VulnerabilityType is now imported from vuln_types.py


# ═══════════════════════════════════════════════════════════════════════════════
# FEASIBILITY REPORT AND ANALYZER
# ═══════════════════════════════════════════════════════════════════════════════
#
# NOTE: PayloadConstraints, OneGadget, LibcInfo, ROPGadgetInfo, ELFStructure,
# WriteTarget, AddressSpaceInfo, SeccompInfo, ExploitPrimitive are imported from
# context.py (canonical definitions).

@dataclass
class FeasibilityReport:
    """Complete mitigation assessment report."""
    verdict: ExploitabilityVerdict = ExploitabilityVerdict.UNKNOWN

    # Issues that completely block exploitation
    blockers: List[str] = field(default_factory=list)

    # Issues that complicate but don't block exploitation
    warnings: List[str] = field(default_factory=list)

    # Suggested ways to bypass or work around mitigations
    bypass_suggestions: List[str] = field(default_factory=list)

    # Requirements for setting up a vulnerable environment
    environment_requirements: List[str] = field(default_factory=list)

    # Payload byte constraints (bad bytes, encoding requirements)
    payload_constraints: Optional[PayloadConstraints] = None

    # Detailed findings
    glibc_version: str = ""
    glibc_major_minor: float = 0.0
    glibc_n_disabled: bool = False
    glibc_mitigations: Optional[GlibcMitigations] = None  # Comprehensive glibc mitigation tracking

    binary_protections: Dict[str, bool] = field(default_factory=dict)
    kernel_mitigations: Dict[str, str] = field(default_factory=dict)
    kernel_mitigations_detailed: Optional[KernelMitigations] = None  # Comprehensive kernel mitigation tracking
    compiler_mitigations: Dict[str, bool] = field(default_factory=dict)

    # Raw data for LLM context
    raw_checksec: str = ""

    # ─────────────────────────────────────────────────────────────────────────
    # Extended analysis (runtime-queried, no databases)
    # ─────────────────────────────────────────────────────────────────────────

    # Detected input handlers from binary imports
    detected_input_handlers: List[str] = field(default_factory=list)

    # Format string exploitation context
    format_string_call_count: int = 0  # How many printf/fprintf calls in binary
    format_string_sinks: Dict[str, int] = field(default_factory=dict)  # {func: count}
    single_shot_format_string: bool = False  # Only one printf call = limited exploitation

    # Input handler constraints
    max_embeddable_addresses: int = 0  # How many 64-bit addresses can be embedded
    # strcpy: 1 (null at byte 6 terminates, only 1 address at end)
    # fgets/read: unlimited (binary safe or line-based)

    # Libc partial-overwrite gadgets (useful addresses in 0x0000-0xFFFF range)
    libc_2byte_gadgets: List[Dict[str, Any]] = field(default_factory=list)  # Gadgets reachable via 2-byte overwrite

    # Libc information (queried from actual libc)
    libc_info: Optional[LibcInfo] = None

    # ROP gadget analysis
    rop_gadgets: Optional[ROPGadgetInfo] = None

    # ELF structure (sections, GOT entries)
    elf_structure: Optional[ELFStructure] = None

    # Address space information
    address_space: Optional[AddressSpaceInfo] = None

    # Seccomp/sandbox status
    seccomp: Optional[SeccompInfo] = None

    # Ranked write targets
    write_targets: List[WriteTarget] = field(default_factory=list)

    # Exploit primitives (what the vuln gives you)
    exploit_primitives: Optional[ExploitPrimitive] = None

    # Exploitation constraints (what techniques are blocked/viable)
    exploitation_constraints: Optional[ExploitationConstraints] = None

    # Binary-specific analysis (ties mitigations to concrete targets)
    binary_specific: Optional[BinarySpecificAnalysis] = None

    # Target profile (captures context: local/remote/web/kernel)
    profile: Optional[TargetProfile] = None

    # Gadget quality assessment
    gadget_quality: Optional[GadgetQuality] = None

    # Confidence tracking for each finding (Phase 3)
    # Maps finding name to confidence level: "detected", "provided", "inferred", "assumed", "unknown"
    confidence: Dict[str, str] = field(default_factory=dict)

    # Context-specific notes (web guidance, kernel warnings, etc.)
    context_notes: List[str] = field(default_factory=list)

    def add_finding(self, key: str, value: Any, confidence_level: str) -> None:
        """
        Add a finding with confidence tracking.

        Args:
            key: The attribute name to set
            value: The value to set
            confidence_level: One of "detected", "provided", "inferred", "assumed", "unknown"
        """
        setattr(self, key, value)
        self.confidence[key] = confidence_level

    def to_dict(self) -> Dict:
        """Convert to dictionary for serialization."""
        result = {
            "verdict": self.verdict.value,
            "blockers": self.blockers,
            "warnings": self.warnings,
            "bypass_suggestions": self.bypass_suggestions,
            "environment_requirements": self.environment_requirements,
            "glibc_version": self.glibc_version,
            "glibc_n_disabled": self.glibc_n_disabled,
            "binary_protections": self.binary_protections,
            "kernel_mitigations": self.kernel_mitigations,
            "raw_checksec": self.raw_checksec,  # Raw checksec output for LLM context
        }
        if self.payload_constraints:
            result["payload_constraints"] = {
                "bad_bytes": self.payload_constraints.bad_bytes,
                "bad_byte_reasons": {
                    str(k): v for k, v in self.payload_constraints.bad_byte_reasons.items()
                },
                "input_handler": self.payload_constraints.input_handler,
                "printable_only": self.payload_constraints.must_be_printable,
                "allowed_charset": self.payload_constraints.allowed_charset,
                "encoding_suggestions": self.payload_constraints.encoding_suggestions,
            }
        return result

    def summary(self) -> str:
        """Generate human-readable summary."""
        lines = [
            "=" * 65,
            "MITIGATION ANALYSIS REPORT",
            "=" * 65,
        ]

        # Binary protections table
        lines.append("\n### BINARY PROTECTIONS ###")
        lines.append(f"  {'Protection':<20} {'Status':<10} {'Impact'}")
        lines.append("  " + "-" * 60)

        protections = [
            ("Stack Canary", self.binary_protections.get('canary', False),
             "Detects stack buffer overflows"),
            ("NX (DEP)", self.binary_protections.get('nx', True),
             "No execute on stack - need ROP"),
            ("PIE", self.binary_protections.get('pie', False),
             "Randomizes binary base address"),
            ("Full RELRO", self.binary_protections.get('full_relro', False),
             "GOT read-only after startup"),
            ("FORTIFY_SOURCE", self.binary_protections.get('fortify', False),
             "Runtime buffer overflow checks"),
        ]

        for name, enabled, impact in protections:
            status = "ENABLED" if enabled else "disabled"
            lines.append(f"  {name:<20} {status:<10} {impact}")

        # Runtime mitigations table
        lines.append("\n### RUNTIME MITIGATIONS ###")
        lines.append(f"  {'Mitigation':<20} {'Status':<10} {'Impact'}")
        lines.append("  " + "-" * 60)

        aslr_status = f"Level {self.kernel_aslr}" if hasattr(self, 'kernel_aslr') else "Level 2"
        n_status = "ENABLED" if not self.glibc_n_disabled else "DISABLED"
        hooks_status = "removed" if self.glibc_major_minor >= 2.34 else "available"

        runtime = [
            ("ASLR", aslr_status, "Randomizes memory layout"),
            ("glibc %n", n_status, "Format string write primitive"),
            ("glibc hooks", hooks_status, "__malloc_hook/__free_hook"),
        ]

        for name, status, impact in runtime:
            lines.append(f"  {name:<20} {status:<10} {impact}")

        # Verdict
        lines.append("\n### VERDICT ###")
        lines.append(f"  {self.verdict.value.upper()}")
        lines.append(f"  glibc: {self.glibc_version}")

        # Blockers (if any)
        if self.blockers:
            lines.append("\n### BLOCKERS (exploitation not possible) ###")
            for b in self.blockers:
                lines.append(f"  [X] {b}")

        # Attack surface
        lines.append("\n### ATTACK SURFACE ###")
        available = []
        blocked = []

        if not self.glibc_n_disabled:
            available.append("Format string write (%n) - arbitrary write")
        else:
            blocked.append("Format string write (%n) - disabled in glibc")

        available.append("Format string read (%p/%s) - info leak")

        if not self.binary_protections.get('canary'):
            available.append("Stack buffer overflow - no canary")
        else:
            blocked.append("Stack overflow - protected by canary")

        if not self.binary_protections.get('full_relro'):
            available.append("GOT overwrite - redirect calls")
            available.append(".fini_array overwrite - called at exit()")
        else:
            blocked.append("GOT overwrite - blocked by Full RELRO")
            blocked.append(".fini_array overwrite - blocked by Full RELRO")

        if self.binary_protections.get('nx'):
            blocked.append("Shellcode on stack - blocked by NX")
            available.append("ROP/ret2libc - code reuse attack")

        if self.binary_protections.get('pie'):
            blocked.append("Hardcoded addresses - randomized by PIE")

        lines.append("  Available vectors:")
        for a in available:
            lines.append(f"    [+] {a}")

        if blocked:
            lines.append("  Blocked by mitigations:")
            for b in blocked:
                lines.append(f"    [-] {b}")

        # Bypass suggestions (show for unlikely or difficult verdicts)
        if self.bypass_suggestions and self.verdict in (
            ExploitabilityVerdict.UNLIKELY,
            ExploitabilityVerdict.DIFFICULT
        ):
            lines.append("\n### SUGGESTIONS TO IMPROVE ODDS ###")
            for s in self.bypass_suggestions[:5]:
                lines.append(f"  - {s}")

        # Payload constraints
        if self.payload_constraints and self.payload_constraints.bad_bytes:
            lines.append("\n### PAYLOAD CONSTRAINTS ###")
            bad = ", ".join(f"0x{b:02x}" for b in self.payload_constraints.bad_bytes[:8])
            lines.append(f"  Bad bytes: {bad}")
            if self.payload_constraints.input_handler:
                lines.append(f"  Input handler: {self.payload_constraints.input_handler}")

        # Extended analysis: Libc offsets (if collected)
        if self.libc_info and (self.libc_info.system_offset or self.libc_info.bin_sh_offset):
            lines.append("\n### LIBC OFFSETS (for exploit development) ###")
            lines.append(f"  Path: {self.libc_info.path}")
            if self.libc_info.system_offset:
                lines.append(f"  system():    0x{self.libc_info.system_offset:x}")
            if self.libc_info.execve_offset:
                lines.append(f"  execve():    0x{self.libc_info.execve_offset:x}")
            if self.libc_info.bin_sh_offset:
                lines.append(f"  \"/bin/sh\":   0x{self.libc_info.bin_sh_offset:x}")
            if self.libc_info.one_gadgets:
                lines.append(f"  one_gadgets: {len(self.libc_info.one_gadgets)} found")
                for og in self.libc_info.one_gadgets[:3]:
                    lines.append(f"               0x{og:x}")

        # Extended analysis: ROP gadgets (if collected)
        if self.rop_gadgets and self.rop_gadgets.total_gadgets > 0:
            lines.append("\n### ROP GADGETS ###")
            lines.append(f"  Total: {self.rop_gadgets.total_gadgets}, "
                        f"Usable: {self.rop_gadgets.usable_gadgets}")
            if self.rop_gadgets.filtered_by_bad_bytes:
                lines.append(f"  Filtered (bad bytes): {self.rop_gadgets.filtered_by_bad_bytes}")

            # Show key gadgets
            gadgets_found = []
            if self.rop_gadgets.pop_rdi_ret:
                gadgets_found.append(f"pop rdi; ret @ 0x{self.rop_gadgets.pop_rdi_ret:x}")
            if self.rop_gadgets.pop_rsi_ret:
                gadgets_found.append(f"pop rsi; ret @ 0x{self.rop_gadgets.pop_rsi_ret:x}")
            if self.rop_gadgets.pop_rdx_ret:
                gadgets_found.append(f"pop rdx; ret @ 0x{self.rop_gadgets.pop_rdx_ret:x}")
            if self.rop_gadgets.pop_rax_ret:
                gadgets_found.append(f"pop rax; ret @ 0x{self.rop_gadgets.pop_rax_ret:x}")
            if self.rop_gadgets.ret:
                gadgets_found.append(f"ret @ 0x{self.rop_gadgets.ret:x}")
            if self.rop_gadgets.syscall_ret:
                gadgets_found.append(f"syscall @ 0x{self.rop_gadgets.syscall_ret:x}")

            if gadgets_found:
                lines.append("  Key gadgets:")
                for g in gadgets_found:
                    lines.append(f"    {g}")

        # Extended analysis: Write targets (if collected)
        if self.write_targets:
            lines.append("\n### WRITE TARGETS (ranked) ###")
            for i, t in enumerate(self.write_targets[:5], 1):
                flags = []
                if t.needs_leak:
                    flags.append("needs leak")
                if t.has_bad_bytes:
                    flags.append("bad bytes")
                flag_str = f" [{', '.join(flags)}]" if flags else ""
                addr_str = f"0x{t.address:x}" if t.address else "dynamic"
                lines.append(f"  {i}. {t.name} @ {addr_str}{flag_str}")

        # Exploitation constraints (CRITICAL - what techniques are blocked)
        if self.exploitation_constraints:
            lines.append("\n### EXPLOITATION CONSTRAINTS ###")
            lines.append(f"  Architecture: {self.exploitation_constraints.arch}")
            lines.append(f"  Null byte position: byte {self.exploitation_constraints.null_byte_position}")
            lines.append(f"  Max strcpy bytes: {self.exploitation_constraints.max_strcpy_bytes}")
            lines.append(f"  strcpy ROP viable: {'YES' if self.exploitation_constraints.strcpy_rop_viable else 'NO'}")

            if self.exploitation_constraints.blocked_techniques:
                lines.append("\n  BLOCKED TECHNIQUES (do not attempt):")
                for t in self.exploitation_constraints.blocked_techniques:
                    lines.append(f"    ✗ {t}")

            if self.exploitation_constraints.viable_techniques:
                lines.append("\n  VIABLE TECHNIQUES (try these instead):")
                for t in self.exploitation_constraints.viable_techniques:
                    lines.append(f"    ✓ {t}")

        # Raw checksec output (for reference)
        if self.raw_checksec:
            lines.append("\n### RAW CHECKSEC OUTPUT ###")
            # Indent the checksec output
            for line in self.raw_checksec.strip().split('\n'):
                lines.append(f"  {line}")

        lines.append("\n" + "=" * 65)
        return "\n".join(lines)

    def to_context(self, binary_path: str = None) -> ExploitContext:
        """
        Convert FeasibilityReport to a ExploitContext for exploit development.

        This creates a flexible JSON-queryable store of all reconnaissance
        data collected during analysis. Use this in exploit development
        instead of re-running recon commands.

        Example:
            report = analyzer.full_analysis(extended=True)
            recon = report.to_context()

            # Query by dot-path
            system_offset = recon.get('libc.system_offset')
            has_canary = recon.get('binary.protections.canary')

            # Or use attribute syntax
            system_offset = recon.libc.system_offset
        """
        recon = ExploitContext(binary_path=binary_path)

        # Verdict and assessment
        recon.set('verdict', self.verdict.value, source='FeasibilityAnalyzer')
        recon.set('blockers', self.blockers, source='FeasibilityAnalyzer')
        recon.set('warnings', self.warnings, source='FeasibilityAnalyzer')

        # glibc info
        recon.set('libc.version', self.glibc_version, source='glibc runtime query')
        recon.set('libc.version_float', self.glibc_major_minor, source='glibc runtime query')
        recon.set('libc.n_disabled', self.glibc_n_disabled, source='glibc %n verification')
        recon.set('libc.hooks_available', self.glibc_major_minor < 2.34,
                  source='glibc version check',
                  notes='__malloc_hook/__free_hook removed in glibc 2.34')

        if self.libc_info:
            recon.set('libc.path', self.libc_info.path, source='ldd')
            if self.libc_info.system_offset:
                recon.set('libc.system_offset', self.libc_info.system_offset, source='nm -D libc')
            if self.libc_info.execve_offset:
                recon.set('libc.execve_offset', self.libc_info.execve_offset, source='nm -D libc')
            if self.libc_info.bin_sh_offset:
                recon.set('libc.bin_sh_offset', self.libc_info.bin_sh_offset, source='strings -t x libc')
            if self.libc_info.malloc_hook_offset:
                recon.set('libc.malloc_hook_offset', self.libc_info.malloc_hook_offset, source='nm -D libc')
            if self.libc_info.free_hook_offset:
                recon.set('libc.free_hook_offset', self.libc_info.free_hook_offset, source='nm -D libc')
            if self.libc_info.one_gadgets:
                recon.set('libc.one_gadgets', self.libc_info.one_gadgets, source='one_gadget')

        # Binary protections
        for prot, enabled in self.binary_protections.items():
            recon.set(f'binary.protections.{prot}', enabled, source='checksec/readelf')

        # Kernel mitigations
        for mit, value in self.kernel_mitigations.items():
            recon.set(f'kernel.{mit}', value, source='/proc or sysctl')

        # ROP gadgets
        if self.rop_gadgets:
            recon.set('rop.total_gadgets', self.rop_gadgets.total_gadgets, source='ROPgadget')
            recon.set('rop.usable_gadgets', self.rop_gadgets.usable_gadgets, source='ROPgadget')
            recon.set('rop.filtered_count', self.rop_gadgets.filtered_by_bad_bytes, source='ROPgadget')
            if self.rop_gadgets.pop_rdi_ret:
                recon.set('rop.pop_rdi_ret', self.rop_gadgets.pop_rdi_ret, source='ROPgadget')
            if self.rop_gadgets.pop_rsi_ret:
                recon.set('rop.pop_rsi_ret', self.rop_gadgets.pop_rsi_ret, source='ROPgadget')
            if self.rop_gadgets.pop_rdx_ret:
                recon.set('rop.pop_rdx_ret', self.rop_gadgets.pop_rdx_ret, source='ROPgadget')
            if self.rop_gadgets.pop_rax_ret:
                recon.set('rop.pop_rax_ret', self.rop_gadgets.pop_rax_ret, source='ROPgadget')
            if self.rop_gadgets.ret:
                recon.set('rop.ret', self.rop_gadgets.ret, source='ROPgadget')
            if self.rop_gadgets.syscall_ret:
                recon.set('rop.syscall_ret', self.rop_gadgets.syscall_ret, source='ROPgadget')

        # ELF structure
        if self.elf_structure:
            if self.elf_structure.got_plt_addr:
                recon.set('binary.sections.got_plt_addr', self.elf_structure.got_plt_addr, source='readelf -S')
            if self.elf_structure.fini_array_addr:
                recon.set('binary.sections.fini_array_addr', self.elf_structure.fini_array_addr, source='readelf -S')
            if self.elf_structure.bss_addr:
                recon.set('binary.sections.bss_addr', self.elf_structure.bss_addr, source='readelf -S')
            if self.elf_structure.got_entries:
                recon.set('binary.got_entries', self.elf_structure.got_entries, source='readelf -r')

        # Address space
        if self.address_space:
            if self.address_space.binary_base_sample:
                recon.set('address_space.binary_base', self.address_space.binary_base_sample, source='/proc/pid/maps')
            if self.address_space.libc_base_sample:
                recon.set('address_space.libc_base', self.address_space.libc_base_sample, source='/proc/pid/maps')
            if self.address_space.stack_sample:
                recon.set('address_space.stack_base', self.address_space.stack_sample, source='/proc/pid/maps')
            recon.set('address_space.binary_has_nulls', self.address_space.binary_has_nulls, source='address analysis')
            recon.set('address_space.libc_has_nulls', self.address_space.libc_has_nulls, source='address analysis')

        # Payload constraints
        if self.payload_constraints:
            recon.set('payload.bad_bytes', self.payload_constraints.bad_bytes, source='input handler analysis')
            recon.set('payload.input_handler', self.payload_constraints.input_handler, source='binary imports')
            if self.payload_constraints.must_be_printable:
                recon.set('payload.printable_only', True, source='input handler analysis')

        # Input handlers
        if self.detected_input_handlers:
            recon.set('binary.input_handlers', self.detected_input_handlers, source='nm -D')

        # Write targets
        if self.write_targets:
            targets = []
            for t in self.write_targets:
                targets.append({
                    'name': t.name,
                    'address': t.address,
                    'has_bad_bytes': t.has_bad_bytes,
                    'needs_leak': t.needs_leak,
                    'reliability': t.reliability,
                    'notes': t.notes,
                })
            recon.set('write_targets', targets, source='FeasibilityAnalyzer')

        # Seccomp
        if self.seccomp:
            recon.set('seccomp.enabled', self.seccomp.seccomp_enabled, source='seccomp-tools')
            recon.set('seccomp.mode', self.seccomp.seccomp_mode, source='seccomp-tools')
            recon.set('seccomp.execve_allowed', self.seccomp.execve_allowed, source='seccomp-tools')

        # Exploitation constraints (CRITICAL for exploit technique selection)
        if self.exploitation_constraints:
            recon.set('constraints.arch', self.exploitation_constraints.arch,
                     source='Architecture detection')
            recon.set('constraints.pointer_size', self.exploitation_constraints.pointer_size,
                     source='Architecture detection')
            recon.set('constraints.null_byte_position', self.exploitation_constraints.null_byte_position,
                     source='x86_64 canonical address format',
                     notes='Userland addresses are 0x0000000000000000-0x00007FFFFFFFFFFF')
            recon.set('constraints.max_strcpy_bytes', self.exploitation_constraints.max_strcpy_bytes,
                     source='Architecture + input handler analysis')
            recon.set('constraints.strcpy_rop_viable', self.exploitation_constraints.strcpy_rop_viable,
                     source='Architecture + input handler analysis',
                     notes=self.exploitation_constraints.strcpy_rop_reason)
            recon.set('constraints.blocked_techniques', self.exploitation_constraints.blocked_techniques,
                     source='Constraint analysis',
                     notes='DO NOT attempt these techniques - architecturally impossible')
            recon.set('constraints.viable_techniques', self.exploitation_constraints.viable_techniques,
                     source='Constraint analysis',
                     notes='These techniques MAY work given the constraints')
            recon.set('constraints.input_handler', self.exploitation_constraints.input_handler,
                     source='Binary import analysis')

        return recon

    def save(self, path: str):
        """
        Save report to JSON file for later use by exploit development.

        The saved file can be loaded with FeasibilityReport.load() or
        used directly as JSON by exploit scripts.
        """
        import json
        from pathlib import Path as P

        # Convert to recon store and save
        recon = self.to_context()

        # Also include the raw report data for full fidelity
        data = {
            'recon': recon.to_dict(),
            'report': self.to_dict(),
        }

        path = P(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        with open(path, 'w') as f:
            json.dump(data, f, indent=2, default=str)

        logger.info(f"FeasibilityReport saved to {path}")

    @classmethod
    def load(cls, path: str) -> 'FeasibilityReport':
        """
        Load a saved FeasibilityReport from JSON file.

        Returns a FeasibilityReport with all data restored. The associated
        ExploitContext can be accessed via report.to_context().
        """
        import json

        with open(path, 'r') as f:
            data = json.load(f)

        report_data = data.get('report', {})

        # Reconstruct the report
        report = cls()
        report.verdict = ExploitabilityVerdict(report_data.get('verdict', 'unknown'))
        report.blockers = report_data.get('blockers', [])
        report.warnings = report_data.get('warnings', [])
        report.bypass_suggestions = report_data.get('bypass_suggestions', [])
        report.glibc_version = report_data.get('glibc_version', '')
        report.glibc_n_disabled = report_data.get('glibc_n_disabled', False)
        report.binary_protections = report_data.get('binary_protections', {})
        report.kernel_mitigations = report_data.get('kernel_mitigations', {})

        # Parse glibc version
        if report.glibc_version:
            match = re.search(r'(\d+)\.(\d+)', report.glibc_version)
            if match:
                report.glibc_major_minor = float(f"{match.group(1)}.{match.group(2)}")

        # Restore payload constraints if present
        if 'payload_constraints' in report_data:
            pc = report_data['payload_constraints']
            report.payload_constraints = PayloadConstraints(
                bad_bytes=pc.get('bad_bytes', []),
                input_handler=pc.get('input_handler', ''),
            )

        logger.info(f"FeasibilityReport loaded from {path}")
        return report

    @classmethod
    def load_context(cls, path: str) -> ExploitContext:
        """
        Load just the ExploitContext from a saved report file.

        Use this when you only need the context data, not the full report.
        """
        import json

        with open(path, 'r') as f:
            data = json.load(f)

        return ExploitContext.from_dict(data.get('recon', {}))


class FeasibilityAnalyzer:
    """
    Analyze mitigations BEFORE attempting exploitation.

    This class checks for security mitigations at multiple levels:
    1. glibc/runtime mitigations (blocks entire exploit classes)
    2. Binary protections (RELRO, PIE, NX, Canary)
    3. Kernel mitigations (ASLR, SMEP, SMAP)
    4. Compiler mitigations (FORTIFY_SOURCE, CFI)
    5. Vulnerability-specific blockers

    The analysis should be run BEFORE any exploit development to avoid
    wasting time on impossible exploits.
    """

    # glibc version thresholds for various mitigations
    GLIBC_N_DISABLED_VERSION = 2.38  # %n disabled by default
    GLIBC_PTR_MANGLE_VERSION = 2.3   # Pointer mangling introduced

    def __init__(
        self,
        binary_path: Optional[Path] = None,
        profile: Optional[TargetProfile] = None
    ):
        """
        Initialize the mitigation analyzer.

        Args:
            binary_path: Path to binary being analyzed (optional for system-only checks)
            profile: Pre-configured target profile (for remote/web/kernel contexts).
                    If provided, takes precedence over binary_path for context.
        """
        # Set up profile (provided profile takes precedence)
        if profile:
            self.profile = profile
            # Use binary path from profile if not explicitly provided
            if not binary_path and profile.binary_path:
                binary_path = profile.binary_path
        elif binary_path:
            # Create local profile from binary path
            self.profile = create_local_profile(str(binary_path))
        else:
            # No profile, no binary - create empty local profile
            self.profile = create_local_profile(None)

        # Set up binary path
        self.binary = Path(binary_path).resolve() if binary_path else None
        if self.binary and not self.binary.exists():
            logger.warning(f"Binary not found: {binary_path}")
            self.binary = None

        # Select analysis strategy based on profile context
        self.strategy = get_analysis_strategy(self.profile)

    def full_analysis(self, vuln_type: str = None,
                       input_handler: str = None,
                       extended: bool = False) -> FeasibilityReport:
        """
        Run complete mitigation analysis.

        This is the main entry point. It checks all mitigation categories
        and computes a final verdict on exploitability.

        Args:
            vuln_type: Type of vulnerability (e.g., "format_string", "buffer_overflow")
                      Used for vulnerability-specific mitigation checks.
            input_handler: Optional input handling function (e.g., "strcpy", "fgets", "scanf")
                          Used to infer payload byte constraints.
            extended: If True, run extended analysis (libc offsets, ROP gadgets,
                     ELF structure, seccomp, write targets). This is slower but
                     provides more detailed exploitation guidance.

        Returns:
            FeasibilityReport with complete analysis results
        """
        logger.info("=" * 60)
        logger.info("MITIGATION ANALYSIS - Checking exploitation viability")
        logger.info(f"Context: {self.profile.context.value}")
        logger.info("=" * 60)

        report = FeasibilityReport()

        # Use profile from __init__ (may be local, remote, web, or kernel)
        report.profile = self.profile

        # Add context-specific warnings from strategy
        context_warnings = self.strategy.get_context_warnings()
        report.context_notes.extend(context_warnings)

        # Web applications: skip memory mitigations entirely
        if not self.strategy.should_check_memory_mitigations():
            logger.info("Web application context - skipping memory mitigation checks")
            report.verdict = ExploitabilityVerdict.UNKNOWN
            report.context_notes.append(
                "Memory corruption mitigations not applicable for web context. "
                "Check: input validation, parameterized queries, CSP, CORS, authentication."
            )
            if hasattr(self.strategy, 'get_relevant_checks'):
                checks = self.strategy.get_relevant_checks()
                report.context_notes.append(f"Relevant checks: {', '.join(checks)}")
            return report

        # 1. CRITICAL: Check glibc mitigations first (can block entire exploit classes)
        logger.info("Checking glibc/runtime mitigations...")
        self._check_glibc_mitigations(report, vuln_type=vuln_type)

        # 2. Check binary protections
        if self.binary:
            logger.info(f"Checking binary protections: {self.binary}")
            self._check_binary_protections(report)
            # Note: checksec output is now captured via pwntools in _check_binary_protections
        else:
            logger.info("No binary specified - skipping binary protection checks")

        # 3. Check kernel mitigations
        logger.info("Checking kernel mitigations...")
        self._check_kernel_mitigations(report)

        # 4. Check compiler mitigations
        if self.binary:
            logger.info("Checking compiler mitigations...")
            self._check_compiler_mitigations(report)

        # 5. Vulnerability-specific checks
        if vuln_type:
            logger.info(f"Checking {vuln_type}-specific mitigations...")
            self._check_vuln_specific(report, vuln_type)

        # 6. Infer payload constraints (bad bytes, encoding requirements)
        if vuln_type or input_handler:
            logger.info("Inferring payload byte constraints...")
            self._infer_payload_constraints(report, vuln_type or "", input_handler)

        # 7. Determine final verdict
        self._compute_verdict(report)

        # 8. Extended analysis (optional - libc, ROP, ELF, seccomp, write targets)
        if extended and self.binary:
            self.extended_analysis(report, vuln_type)

        # Log summary
        logger.info(f"Analysis complete. Verdict: {report.verdict.value}")
        if report.blockers:
            for blocker in report.blockers:
                logger.warning(f"BLOCKER: {blocker}")

        return report

    def quick_check(self, vuln_type: str) -> Tuple[bool, str]:
        """
        Quick check if a vulnerability type is exploitable.

        Args:
            vuln_type: Vulnerability type to check

        Returns:
            Tuple of (is_exploitable, reason)
        """
        report = self.full_analysis(vuln_type)

        if report.verdict == ExploitabilityVerdict.UNLIKELY:
            reason = "; ".join(report.blockers) if report.blockers else "No known viable path"
            return False, reason
        else:
            return True, "Exploitation appears feasible"

    def _check_glibc_mitigations(self, report: FeasibilityReport, vuln_type: str = None):
        """
        Check glibc version and runtime mitigations.

        Key mitigations:
        - glibc 2.38+: %n format specifier disabled by default
        - glibc 2.34+: __free_hook/__malloc_hook removed
        - glibc 2.3+: Pointer mangling in thread structures

        For remote targets, uses provided glibc version instead of local detection.

        Args:
            report: FeasibilityReport to populate
            vuln_type: Vulnerability type (if known) - used to decide whether to test %n
        """
        # Use strategy to get glibc version (detected for local, provided for remote)
        glibc_version_str, confidence = self.strategy.get_glibc_version()
        report.confidence['glibc_version'] = confidence

        if glibc_version_str:
            report.glibc_version = glibc_version_str

            # Parse version
            match = re.search(r'(\d+)\.(\d+)', glibc_version_str)
            if match:
                major = int(match.group(1))
                minor = int(match.group(2))
                version = major + minor / 100.0
                report.glibc_major_minor = version

                # Update profile with glibc version
                if report.profile:
                    report.profile.glibc_version = f"{major}.{minor}"

                # Check for %n disabled (glibc 2.38+)
                if version >= self.GLIBC_N_DISABLED_VERSION:
                    report.glibc_n_disabled = True
                    confidence_note = f" ({confidence})" if confidence != "detected" else ""
                    report.blockers.append(
                        f"glibc {version}{confidence_note}: %n format specifier DISABLED at runtime "
                        f"(not a compile-time option - cannot be bypassed with compiler flags)"
                    )
                    report.bypass_suggestions.extend([
                        "Use Docker/container with older glibc (e.g., Ubuntu 20.04 with glibc 2.31)",
                        "Use chroot with older glibc libraries",
                        "Statically link binary with older glibc",
                        "Find alternative write primitive (not format string %n)",
                        "Use LD_PRELOAD with custom printf implementation (complex)",
                    ])
                    report.environment_requirements.append(
                        f"Requires glibc < {self.GLIBC_N_DISABLED_VERSION} for format string %n writes"
                    )

                # Check for hooks removed (glibc 2.34+)
                if version >= 2.34:
                    report.warnings.append(
                        f"glibc {version}: __free_hook/__malloc_hook removed - "
                        "cannot use hook overwrite techniques"
                    )

                # Note pointer mangling
                if version >= 2.3:
                    report.warnings.append(
                        "Pointer mangling enabled in glibc - affects thread-local exploits"
                    )

                logger.info(f"glibc version: {version} (confidence: {confidence})")
                if report.glibc_n_disabled:
                    logger.warning(f"CRITICAL: %n format specifier is DISABLED in glibc {version}")

                # Create comprehensive glibc mitigations object
                report.glibc_mitigations = GlibcMitigations(
                    version=version,
                    version_string=glibc_version_str
                )

        elif confidence == "unknown" and self.strategy.should_skip_empirical_tests():
            # Remote target with unknown glibc - warn and assume modern
            report.warnings.append(
                "Remote target: glibc version unknown - assuming modern mitigations. "
                "Provide glibc_version in profile for accurate analysis."
            )
            # Conservative: assume %n is blocked
            report.glibc_n_disabled = True
            report.confidence['glibc_n_disabled'] = 'assumed'
            report.blockers.append(
                "glibc version unknown (remote target): Assuming %n disabled. "
                "Provide glibc_version to get accurate analysis."
            )

        # For local targets, verify %n empirically if version suggests it might be disabled
        # For remote targets, skip the empirical test (can't run code on remote)
        if report.glibc_n_disabled and not self.strategy.should_skip_empirical_tests():
            self._verify_printf_n(report)
            report.confidence['glibc_n_disabled'] = 'tested'
        elif report.glibc_n_disabled:
            report.confidence['glibc_n_disabled'] = 'inferred'

    def _verify_printf_n(self, report: FeasibilityReport):
        """
        Actually test if %n works in printf.

        This is the definitive test - compile and run a test program
        to see if %n actually writes.
        """
        test_code = '''
#include <stdio.h>
int main() {
    int x = 12345;
    printf("%n", &x);
    return (x == 0) ? 0 : 1;  // Return 0 if %n worked (wrote 0)
}
'''
        try:
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f:
                f.write(test_code)
                src_path = f.name

            bin_path = src_path.replace('.c', '')

            # Compile without fortify
            compile_result = subprocess.run(
                ["gcc", "-o", bin_path, src_path, "-w", "-U_FORTIFY_SOURCE"],
                capture_output=True, text=True, timeout=10
            )

            if compile_result.returncode == 0:
                # Run the test
                run_result = subprocess.run(
                    [bin_path],
                    capture_output=True, text=True, timeout=5
                )

                if run_result.returncode == 0:
                    logger.info("VERIFIED: %n format specifier IS working")
                    # Remove blocker if we added one
                    report.blockers = [b for b in report.blockers if "%n" not in b]
                    report.glibc_n_disabled = False
                    # Update glibc_mitigations if present
                    if report.glibc_mitigations:
                        report.glibc_mitigations.format_n_disabled = False
                        report.glibc_mitigations.format_n_verified = True
                        # Rebuild mitigations with verified status
                        report.glibc_mitigations.__post_init__()
                else:
                    logger.warning("VERIFIED: %n format specifier is NOT working")
                    if not report.glibc_n_disabled:
                        report.glibc_n_disabled = True
                        report.blockers.append(
                            "VERIFIED: %n format specifier does not write (runtime disabled)"
                        )
                    # Update glibc_mitigations if present
                    if report.glibc_mitigations:
                        report.glibc_mitigations.format_n_disabled = True
                        report.glibc_mitigations.format_n_verified = True
                        report.glibc_mitigations.__post_init__()

            # Cleanup
            import os
            try:
                os.unlink(src_path)
                os.unlink(bin_path)
            except OSError:
                pass  # File cleanup failure is non-critical

        except Exception as e:
            logger.debug(f"Could not verify %n behavior: {e}")

    def _check_binary_protections(self, report: FeasibilityReport):
        """
        Check binary security features using pwntools ELF (primary) with readelf fallback.

        Checks:
        - RELRO (Relocation Read-Only) - Full or Partial
        - PIE (Position Independent Executable)
        - NX (No-Execute / DEP)
        - Stack Canary
        - FORTIFY_SOURCE (bounds checking)

        Uses pwntools for fast, reliable detection (same as checksec command).
        Falls back to readelf/objdump if pwntools unavailable.
        """
        if not self.binary:
            return

        protections = {}
        pwntools_available = False

        # ─────────────────────────────────────────────────────────────────────
        # Primary: Use pwntools ELF (fast and reliable, same as checksec)
        # ─────────────────────────────────────────────────────────────────────
        try:
            from pwn import ELF
            import pwnlib.context as pwn_context
            # Suppress pwntools output
            pwn_context.context.log_level = 'error'

            elf = ELF(str(self.binary), checksec=False)
            pwntools_available = True

            # RELRO
            if elf.relro == 'Full':
                protections["relro"] = True
                protections["full_relro"] = True
                report.warnings.append(
                    "Full RELRO: GOT is read-only after startup - "
                    "GOT overwrite not possible"
                )
            elif elf.relro == 'Partial':
                protections["relro"] = True
                protections["partial_relro"] = True
                report.warnings.append(
                    "Partial RELRO: Some GOT entries writable"
                )
            else:
                protections["relro"] = False

            # PIE
            protections["pie"] = elf.pie
            if elf.pie:
                report.warnings.append(
                    "PIE enabled: Binary base address is randomized (with ASLR)"
                )

            # NX
            protections["nx"] = elf.nx
            if not elf.nx:
                report.warnings.append(
                    "NX DISABLED: Stack is executable - shellcode possible"
                )
            else:
                report.warnings.append(
                    "NX enabled: Stack not executable - need ROP/ret2libc"
                )

            # Stack Canary
            protections["canary"] = elf.canary
            if elf.canary:
                report.warnings.append(
                    "Stack canary enabled: Stack buffer overflow will be detected"
                )
                report.bypass_suggestions.append(
                    "Leak canary value via format string or other info disclosure"
                )

            # FORTIFY_SOURCE (pwntools checks for _chk functions)
            protections["fortify"] = elf.fortify
            if elf.fortify:
                report.warnings.append(
                    "FORTIFY_SOURCE: Bounds checking on string/memory functions"
                )

            # Store raw checksec output for reference
            report.raw_checksec = elf.checksec(banner=False)

            # Store arch info
            protections["arch"] = elf.arch
            protections["bits"] = elf.bits

            logger.info(f"Binary protections (pwntools): {protections}")

        except ImportError:
            logger.debug("pwntools not available, falling back to manual checks")
        except Exception as e:
            logger.debug(f"pwntools check failed: {e}, falling back to manual checks")

        # ─────────────────────────────────────────────────────────────────────
        # Fallback: Use readelf/objdump if pwntools unavailable or failed
        # ─────────────────────────────────────────────────────────────────────
        if not pwntools_available:
            try:
                # Check RELRO
                result = subprocess.run(
                    ["readelf", "-l", str(self.binary)],
                    capture_output=True, text=True, timeout=5
                )
                if result.returncode == 0:
                    if "GNU_RELRO" in result.stdout:
                        protections["relro"] = True

                        # Check for Full RELRO (BIND_NOW)
                        dyn_result = subprocess.run(
                            ["readelf", "-d", str(self.binary)],
                            capture_output=True, text=True, timeout=5
                        )
                        if "BIND_NOW" in dyn_result.stdout or "(NOW)" in dyn_result.stdout:
                            protections["full_relro"] = True
                            report.warnings.append(
                                "Full RELRO: GOT is read-only after startup - "
                                "GOT overwrite not possible"
                            )
                        else:
                            protections["partial_relro"] = True
                            report.warnings.append(
                                "Partial RELRO: Some GOT entries writable"
                            )
                    else:
                        protections["relro"] = False

                # Check PIE
                result = subprocess.run(
                    ["readelf", "-h", str(self.binary)],
                    capture_output=True, text=True, timeout=5
                )
                if result.returncode == 0:
                    if "DYN (Position-Independent Executable" in result.stdout or \
                       "Type:                              DYN" in result.stdout:
                        protections["pie"] = True
                        report.warnings.append(
                            "PIE enabled: Binary base address is randomized (with ASLR)"
                        )
                    else:
                        protections["pie"] = False

                # Check NX (No-Execute stack)
                result = subprocess.run(
                    ["readelf", "-l", str(self.binary)],
                    capture_output=True, text=True, timeout=5
                )
                if result.returncode == 0:
                    # Look for GNU_STACK segment
                    if "GNU_STACK" in result.stdout:
                        # Check if RWE (read-write-execute) - means NX disabled
                        lines = result.stdout.split('\n')
                        for i, line in enumerate(lines):
                            if "GNU_STACK" in line:
                                # Check flags in this or next line
                                stack_line = line + (lines[i+1] if i+1 < len(lines) else "")
                                if "RWE" in stack_line:
                                    protections["nx"] = False
                                    report.warnings.append(
                                        "NX DISABLED: Stack is executable - shellcode possible"
                                    )
                                else:
                                    protections["nx"] = True
                                    report.warnings.append(
                                        "NX enabled: Stack not executable - need ROP/ret2libc"
                                    )
                                break
                    else:
                        protections["nx"] = True  # Default to NX enabled if no GNU_STACK

                # Check Stack Canary
                result = subprocess.run(
                    ["objdump", "-d", str(self.binary)],
                    capture_output=True, text=True, timeout=15
                )
                if result.returncode == 0:
                    if "__stack_chk_fail" in result.stdout:
                        protections["canary"] = True
                        report.warnings.append(
                            "Stack canary enabled: Stack buffer overflow will be detected"
                        )
                        report.bypass_suggestions.append(
                            "Leak canary value via format string or other info disclosure"
                        )
                    else:
                        protections["canary"] = False

                # Check FORTIFY_SOURCE (fallback via symbol check)
                result = subprocess.run(
                    ["objdump", "-t", str(self.binary)],
                    capture_output=True, text=True, timeout=10
                )
                if result.returncode == 0:
                    symbols = result.stdout.lower()
                    fortify_symbols = ["__chk", "_chk@", "__fortify", "__sprintf_chk",
                                      "__strcpy_chk", "__memcpy_chk"]
                    if any(sym in symbols for sym in fortify_symbols):
                        protections["fortify"] = True
                        report.warnings.append(
                            "FORTIFY_SOURCE: Bounds checking on string/memory functions"
                        )
                    else:
                        protections["fortify"] = False

                logger.info(f"Binary protections (readelf fallback): {protections}")

            except subprocess.TimeoutExpired:
                report.warnings.append("Binary protection check timed out")
            except Exception as e:
                report.warnings.append(f"Binary protection check failed: {e}")

        report.binary_protections = protections
        report.confidence['binary_protections'] = 'detected'

        # For remote targets, apply any profile overrides
        if hasattr(self, 'strategy') and self.strategy.should_skip_empirical_tests():
            # Remote target - check for profile overrides
            if self.profile.has_pie is not None:
                protections['pie'] = self.profile.has_pie
                report.confidence['pie'] = 'provided'
            if self.profile.has_nx is not None:
                protections['nx'] = self.profile.has_nx
                report.confidence['nx'] = 'provided'
            if self.profile.has_canary is not None:
                protections['canary'] = self.profile.has_canary
                report.confidence['canary'] = 'provided'
            if self.profile.has_full_relro is not None:
                protections['full_relro'] = self.profile.has_full_relro
                report.confidence['full_relro'] = 'provided'
            report.binary_protections = protections

        # Update profile with detected protections
        if report.profile:
            report.profile.has_pie = protections.get('pie', None)
            report.profile.has_nx = protections.get('nx', None)
            report.profile.has_canary = protections.get('canary', None)
            report.profile.has_full_relro = protections.get('full_relro', None)

    def _check_checksec(self, report: FeasibilityReport):
        """
        Run checksec tool if available for comprehensive check.
        """
        if not self.binary:
            return

        try:
            result = subprocess.run(
                ["checksec", "--file", str(self.binary)],
                capture_output=True, text=True, timeout=10
            )
            if result.returncode == 0:
                report.raw_checksec = result.stdout
                logger.info(f"checksec output:\n{result.stdout}")
        except FileNotFoundError:
            logger.debug("checksec not installed - using manual checks")
        except Exception as e:
            logger.debug(f"checksec failed: {e}")

    def _read_sysctl(self, path: str, default: int = 0) -> int:
        """Read an integer sysctl value, returning default if not accessible."""
        try:
            with open(f"/proc/sys/{path.replace('.', '/')}") as f:
                return int(f.read().strip())
        except (FileNotFoundError, PermissionError, ValueError):
            return default

    def _check_kernel_mitigations(self, report: FeasibilityReport):
        """
        Check kernel-level security features via sysctl.

        For kernel exploitation context, uses KernelStrategy for detailed checks.
        For userspace exploitation, checks basic kernel mitigations (ASLR, etc.).

        Comprehensive checks include:
        - ASLR (Address Space Layout Randomization)
        - SMEP/SMAP (CPU features)
        - mmap_min_addr (NULL pointer protection)
        - ptrace_scope (YAMA)
        - BPF restrictions
        - User namespace restrictions
        - Symlink/hardlink protections
        - Module loading restrictions
        - Perf event restrictions
        """
        # For kernel exploitation context, use strategy's detailed checks
        if isinstance(self.strategy, KernelStrategy):
            kernel_mits, confidence = self.strategy.get_kernel_mitigations()
            report.kernel_mitigations = kernel_mits
            report.confidence['kernel_mitigations'] = confidence
            # Add warnings from strategy
            for warning in self.strategy.get_context_warnings():
                if warning not in report.context_notes:
                    report.context_notes.append(warning)
            return

        kernel = {}

        # ─────────────────────────────────────────────────────────────────────
        # Read all sysctl values
        # ─────────────────────────────────────────────────────────────────────
        aslr_level = self._read_sysctl("kernel/randomize_va_space", 0)
        mmap_min_addr = self._read_sysctl("vm/mmap_min_addr", 0)
        kptr_restrict = self._read_sysctl("kernel/kptr_restrict", 0)
        dmesg_restrict = self._read_sysctl("kernel/dmesg_restrict", 0)
        perf_event_paranoid = self._read_sysctl("kernel/perf_event_paranoid", 0)
        ptrace_scope = self._read_sysctl("kernel/yama/ptrace_scope", 0)
        unprivileged_bpf = self._read_sysctl("kernel/unprivileged_bpf_disabled", 0)
        unprivileged_userns = self._read_sysctl("kernel/unprivileged_userns_clone", 1)
        modules_disabled = self._read_sysctl("kernel/modules_disabled", 0)
        kexec_load_disabled = self._read_sysctl("kernel/kexec_load_disabled", 0)
        protected_symlinks = self._read_sysctl("fs/protected_symlinks", 0)
        protected_hardlinks = self._read_sysctl("fs/protected_hardlinks", 0)
        protected_fifos = self._read_sysctl("fs/protected_fifos", 0)
        protected_regular = self._read_sysctl("fs/protected_regular", 0)
        suid_dumpable = self._read_sysctl("fs/suid_dumpable", 0)

        # Get kernel version
        kernel_version = ""
        try:
            result = subprocess.run(
                ["uname", "-r"],
                capture_output=True, text=True, timeout=5
            )
            if result.returncode == 0:
                kernel_version = result.stdout.strip()
                logger.info(f"Kernel version: {kernel_version}")
        except (subprocess.SubprocessError, OSError):
            pass  # Kernel version detection failure is non-critical

        # ─────────────────────────────────────────────────────────────────────
        # Populate kernel dict for report.kernel
        # ─────────────────────────────────────────────────────────────────────
        kernel["version"] = kernel_version
        kernel["aslr"] = str(aslr_level)
        kernel["aslr_description"] = {
            0: "Disabled",
            1: "Conservative (stack/mmap only)",
            2: "Full (stack/mmap/heap/PIE)"
        }.get(aslr_level, "Unknown")

        if aslr_level != 0:
            report.warnings.append(
                f"ASLR level {aslr_level} ({kernel['aslr_description']}): "
                "Address randomization enabled"
            )
            report.bypass_suggestions.append(
                "Disable ASLR: `setarch -R <binary>` or "
                "`echo 0 | sudo tee /proc/sys/kernel/randomize_va_space`"
            )
        else:
            logger.info("ASLR is disabled")

        # Check SMEP/SMAP (from /proc/cpuinfo)
        try:
            with open("/proc/cpuinfo") as f:
                cpuinfo = f.read()

            if "smep" in cpuinfo:
                kernel["smep"] = "enabled"
                report.warnings.append(
                    "SMEP enabled: Cannot execute user-space code in kernel mode"
                )
            else:
                kernel["smep"] = "not_present"

            if "smap" in cpuinfo:
                kernel["smap"] = "enabled"
                report.warnings.append(
                    "SMAP enabled: Cannot access user-space data in kernel mode"
                )
            else:
                kernel["smap"] = "not_present"
        except Exception as e:
            logger.debug(f"Could not check SMEP/SMAP: {e}")

        report.kernel_mitigations = kernel

        # ─────────────────────────────────────────────────────────────────────
        # Create comprehensive KernelMitigations object
        # ─────────────────────────────────────────────────────────────────────
        report.kernel_mitigations_detailed = KernelMitigations(
            kernel_version=kernel_version,
            aslr_level=aslr_level,
            mmap_min_addr=mmap_min_addr,
            kptr_restrict=kptr_restrict,
            dmesg_restrict=dmesg_restrict,
            perf_event_paranoid=perf_event_paranoid,
            ptrace_scope=ptrace_scope,
            unprivileged_bpf_disabled=unprivileged_bpf,
            unprivileged_userns_clone=unprivileged_userns,
            modules_disabled=modules_disabled,
            kexec_load_disabled=kexec_load_disabled,
            protected_symlinks=protected_symlinks,
            protected_hardlinks=protected_hardlinks,
            protected_fifos=protected_fifos,
            protected_regular=protected_regular,
            suid_dumpable=suid_dumpable,
        )

        # Log summary
        km = report.kernel_mitigations_detailed
        blockers = km.get_blockers()
        primitive_reqs = km.get_primitive_requirements()
        complications = km.get_complications()
        if blockers:
            logger.info(f"Kernel BLOCKERS: {[m.name for m in blockers]}")
        if primitive_reqs:
            logger.debug(f"Kernel primitive requirements: {[m.name for m in primitive_reqs]}")
        if complications:
            logger.debug(f"Kernel complications: {[m.name for m in complications]}")

    def _check_compiler_mitigations(self, report: FeasibilityReport):
        """
        Check compiler-inserted security features.

        Checks:
        - FORTIFY_SOURCE (bounds checking) - may already be set by _check_binary_protections
        - Control Flow Integrity (CFI)
        """
        if not self.binary:
            return

        compiler = {}

        # FORTIFY_SOURCE may already be detected by pwntools in _check_binary_protections
        # Only check if not already set
        if report.binary_protections.get("fortify") is not None:
            compiler["fortify_source"] = report.binary_protections["fortify"]
        else:
            # Fallback: check symbols manually
            try:
                result = subprocess.run(
                    ["objdump", "-t", str(self.binary)],
                    capture_output=True, text=True, timeout=10
                )
                if result.returncode == 0:
                    symbols = result.stdout.lower()
                    fortify_symbols = ["__chk", "_chk@", "__fortify", "__sprintf_chk",
                                      "__strcpy_chk", "__memcpy_chk"]
                    if any(sym in symbols for sym in fortify_symbols):
                        compiler["fortify_source"] = True
                        report.warnings.append(
                            "FORTIFY_SOURCE: Bounds checking on string/memory functions"
                        )
                    else:
                        compiler["fortify_source"] = False
            except Exception as e:
                logger.debug(f"FORTIFY check failed: {e}")

        # Check for CFI (Control Flow Integrity) - always check via symbols
        try:
            result = subprocess.run(
                ["objdump", "-t", str(self.binary)],
                capture_output=True, text=True, timeout=10
            )
            if result.returncode == 0:
                symbols = result.stdout.lower()
                if "__cfi" in symbols or "cfi_check" in symbols:
                    compiler["cfi"] = True
                    report.warnings.append(
                        "CFI (Control Flow Integrity): Indirect calls validated"
                    )
        except Exception as e:
            logger.debug(f"CFI check failed: {e}")

        report.compiler_mitigations = compiler

    def _check_vuln_specific(self, report: FeasibilityReport, vuln_type: str):
        """
        Check vulnerability-specific mitigations with accurate per-class mappings.

        Mitigation relevance matrix:
        ┌─────────────────┬───────┬────────┬─────┬───────┬─────────┬───────┬─────────┬─────┐
        │ Mitigation      │StackB │ HeapB  │ UAF │ DblFr │ FmtStr  │ TypeC │ InfoLk  │ IntO│
        ├─────────────────┼───────┼────────┼─────┼───────┼─────────┼───────┼─────────┼─────┤
        │ Stack Canary    │  ✓✓   │   -    │  -  │   -   │    -    │   -   │    -    │  ?  │
        │ NX/DEP          │  ✓    │   ✓    │  ✓  │   ✓   │    ✓    │   ✓   │    -    │  ?  │
        │ ASLR+PIE        │  ✓    │   ✓    │  ✓  │   ✓   │    ✓    │   ✓   │ defeats │  ?  │
        │ Full RELRO      │  -    │   ✓    │  ✓  │   ✓   │    ✓    │   ✓   │    -    │  ?  │
        │ FORTIFY_SOURCE  │  ✓    │   ✓    │  -  │   -   │    ✓    │   -   │    -    │  ✓  │
        │ glibc %n block  │  -    │   -    │  -  │   -   │   ✓✓    │   -   │    -    │  -  │
        │ glibc hooks     │  -    │   ✓    │  ✓  │   ✓   │    -    │   -   │    -    │  -  │
        │ tcache harden   │  -    │   ✓    │  ✓  │  ✓✓   │    -    │   -   │    -    │  -  │
        │ CFI             │  -    │   -    │  -  │   -   │    -    │  ✓✓   │    -    │  -  │
        └─────────────────┴───────┴────────┴─────┴───────┴─────────┴───────┴─────────┴─────┘
        ✓✓ = primary/blocking, ✓ = relevant, - = not relevant, ? = depends on consequence
        """
        vuln_type = vuln_type.lower().replace("-", "_").replace(" ", "_")

        # ═══════════════════════════════════════════════════════════════════════
        # REMOTE/WEB VULNERABILITIES - Local mitigations do NOT apply
        # ═══════════════════════════════════════════════════════════════════════

        if any(x in vuln_type for x in ["sql", "sqli"]) and "command" not in vuln_type:
            report.warnings.append(
                "SQL INJECTION: Local mitigations (ASLR, NX, canary) do NOT apply. "
                "Defenses: parameterized queries, input validation, WAF, DB permissions."
            )
            return

        if any(x in vuln_type for x in ["xss", "cross_site"]):
            report.warnings.append(
                "XSS: Local mitigations do NOT apply (browser-side vulnerability). "
                "Defenses: CSP, HttpOnly cookies, output encoding, sanitization."
            )
            return

        if "ssrf" in vuln_type:
            report.warnings.append(
                "SSRF: Local mitigations do NOT apply (network-level). "
                "Defenses: URL allowlists, network segmentation, egress filtering."
            )
            return

        if any(x in vuln_type for x in ["path_traversal", "directory_traversal", "lfi"]):
            report.warnings.append(
                "PATH TRAVERSAL: Local memory mitigations do NOT apply. "
                "Defenses: chroot/jail, path canonicalization, file permissions."
            )
            return

        if any(x in vuln_type for x in ["command_injection", "os_command", "shell_injection"]):
            report.warnings.append(
                "COMMAND INJECTION: Injected commands run with app privileges. "
                "Memory mitigations irrelevant. Defenses: seccomp, AppArmor/SELinux, "
                "sandboxing, input validation, avoid shell=True."
            )
            return

        # ═══════════════════════════════════════════════════════════════════════
        # ENABLING VULNERABILITIES - Not directly exploitable, check consequence
        # ═══════════════════════════════════════════════════════════════════════

        if any(x in vuln_type for x in ["integer", "int_overflow", "numeric"]):
            report.warnings.append(
                "INTEGER OVERFLOW: ENABLING vulnerability - not directly exploitable."
            )
            report.warnings.append("Can lead to (not always memory corruption!):")
            report.warnings.append("  → Memory corruption (buffer/heap overflow) - check those mitigations")
            report.warnings.append("  → Logic bugs (wrong comparison, wrong branch taken)")
            report.warnings.append("  → Resource issues (wrong loop bounds, bad alloc size → DoS)")
            report.warnings.append("  → Array OOB read/write (wrong index, not necessarily overflow)")
            report.warnings.append("Mitigations depend entirely on the CONSEQUENCE.")
            if report.compiler_mitigations.get("fortify_source"):
                report.warnings.append(
                    "  [!] FORTIFY_SOURCE present - may catch some buffer size mismatches"
                )
            return

        if any(x in vuln_type for x in ["signedness", "sign_extension", "sign_error"]):
            report.warnings.append(
                "SIGNEDNESS ERROR: ENABLING vulnerability - not directly exploitable."
            )
            report.warnings.append("Can lead to (not just size calculations!):")
            report.warnings.append("  → Comparison bugs (signed vs unsigned → wrong branch)")
            report.warnings.append("  → Loop issues (negative counter → huge positive value)")
            report.warnings.append("  → Array indexing (negative index → large positive offset)")
            report.warnings.append("  → Truncation (large value → small type → data loss)")
            report.warnings.append("Mitigations depend entirely on the CONSEQUENCE.")
            return

        if any(x in vuln_type for x in ["info_leak", "oob_read", "out_of_bounds_read", "memory_disclosure"]):
            report.warnings.append(
                "INFO LEAK / OOB READ: ENABLING vulnerability - not direct code exec. "
                "Enables: ASLR bypass (address leak), canary leak, heap metadata leak."
            )
            report.warnings.append(
                "This primitive DEFEATS mitigations rather than being blocked by them."
            )
            report.warnings.append("Check what the leaked info enables (ROP, heap exploit, etc.).")
            return

        if any(x in vuln_type for x in ["uninit", "uninitialized"]):
            report.warnings.append(
                "UNINITIALIZED MEMORY: ENABLING vulnerability - info disclosure. "
                "Leaks stack/heap contents (addresses, canary, heap pointers)."
            )
            report.warnings.append(
                "Similar to info leak - enables bypassing ASLR/canary."
            )
            return

        if any(x in vuln_type for x in ["null_deref", "null_pointer", "nullptr"]):
            report.warnings.append(
                "NULL DEREFERENCE: Usually just a crash (SIGSEGV) in userland."
            )
            report.warnings.append(
                "Kernel: Exploitable if mmap_min_addr=0 (disabled on modern systems)."
            )
            try:
                with open("/proc/sys/vm/mmap_min_addr", "r") as f:
                    mmap_min = f.read().strip()
                    if mmap_min == "0":
                        report.warnings.append(
                            "  [!] mmap_min_addr=0 - NULL page mappable (rare, exploitable)"
                        )
                    else:
                        report.warnings.append(
                            f"  mmap_min_addr={mmap_min} - NULL page not mappable (crash only)"
                        )
            except (IOError, ValueError):
                pass  # mmap_min_addr check failure is non-critical
            return

        if any(x in vuln_type for x in ["race", "toctou", "time_of_check"]):
            report.warnings.append(
                "RACE CONDITION: ENABLING vulnerability - consequence varies. "
                "File race (TOCTOU) → privilege escalation, symlink attacks. "
                "Memory race → UAF, double-free, corrupted state."
            )
            report.warnings.append("Check mitigations for the CONSEQUENCE.")
            return

        # ═══════════════════════════════════════════════════════════════════════
        # LOCAL MEMORY CORRUPTION - Specific mitigations per class
        # ═══════════════════════════════════════════════════════════════════════

        # ─────────────────────────────────────────────────────────────────────
        # FORMAT STRING - Three distinct exploitation modes
        # ─────────────────────────────────────────────────────────────────────

        # SPRINTF OVERFLOW: sprintf(buf, user_input) → buffer overflow via format expansion
        # This is NOT blocked by %n mitigation - it's a buffer overflow!
        if any(x in vuln_type for x in ["sprintf", "snprintf_overflow", "vsprintf"]):
            report.warnings.append(
                "SPRINTF OVERFLOW: Buffer overflow via format expansion. "
                "User controls format → many %x → output overflows buffer. "
                "This is NOT blocked by %n mitigation!"
            )
            # Check BUFFER OVERFLOW mitigations, not format string mitigations
            if report.binary_protections.get("canary"):
                report.warnings.append(
                    "Stack canary: Will detect if output buffer is on stack."
                )
            if report.binary_protections.get("nx"):
                report.warnings.append("NX: Need ROP after control.")
            if report.binary_protections.get("pie") and \
               report.kernel_mitigations.get("aslr", "0") != "0":
                report.warnings.append("PIE + ASLR: Need leak for reliable ROP.")
            if report.compiler_mitigations.get("fortify_source"):
                report.warnings.append(
                    "FORTIFY_SOURCE: snprintf_chk may limit damage if size known at compile time."
                )
            return

        # FORMAT STRING READ: %p/%s/%x for info disclosure (ENABLING)
        if any(x in vuln_type for x in ["format_read", "fmt_read", "format_leak"]):
            report.warnings.append(
                "FORMAT STRING READ (%p, %s, %x): ALWAYS WORKS - no glibc mitigation. "
                "This is an ENABLING vulnerability (info disclosure)."
            )
            report.warnings.append(
                "Enables: ASLR bypass (leak addresses), canary leak, heap pointer leak."
            )
            report.warnings.append(
                "Not directly exploitable for code exec - check what the leak enables."
            )
            return

        # FORMAT STRING WRITE: %n for arbitrary write
        if any(x in vuln_type for x in ["format", "printf", "fmt_str", "format_write"]):
            # Check if this is explicitly a write or generic format string
            is_write = any(x in vuln_type for x in ["write", "%n", "arbitrary"])

            if report.glibc_n_disabled:
                report.blockers.append(
                    "FORMAT STRING WRITE BLOCKED: %n disabled in glibc 2.38+. "
                    "Only info disclosure (%p, %s, %x) possible - no arbitrary write."
                )
                report.environment_requirements.append(
                    f"Requires glibc < {self.GLIBC_N_DISABLED_VERSION} for write primitive"
                )
                report.warnings.append(
                    "NOTE: Format string READ still works for info disclosure (ASLR/canary bypass)."
                )
                report.warnings.append(
                    "NOTE: If using sprintf(buf, input), check for buffer OVERFLOW instead."
                )
            else:
                # %n works - check other mitigations
                report.warnings.append(
                    "FORMAT STRING WRITE (%n): Arbitrary write primitive available."
                )
                if report.binary_protections.get("full_relro"):
                    report.warnings.append(
                        "Full RELRO: GOT/.fini_array overwrite blocked. "
                        "Alternatives: return address on stack, __malloc_hook (if glibc <2.34)"
                    )
                if report.binary_protections.get("pie") and \
                   report.kernel_mitigations.get("aslr", "0") != "0":
                    report.warnings.append(
                        "PIE + ASLR: Need address leak first. "
                        "Use format string read (%p) to leak stack/libc addresses."
                    )
                if report.binary_protections.get("nx"):
                    report.warnings.append(
                        "NX: After gaining control, need ROP/ret2libc (no shellcode)."
                    )
                # Stack canary NOT relevant for format string write
                report.warnings.append(
                    "Stack canary: NOT relevant - format string write skips over it."
                )
            return

        # STACK BUFFER OVERFLOW
        if any(x in vuln_type for x in ["stack", "buffer_overflow", "bof"]) and "heap" not in vuln_type:
            # Primary blocker: Stack canary
            if report.binary_protections.get("canary"):
                report.warnings.append(
                    "STACK CANARY: Detects sequential overflow before return. "
                    "Bypass: leak canary (format string, info leak), or overwrite "
                    "non-return targets (function pointers, SEH on Windows)."
                )
            # NX blocks shellcode
            if report.binary_protections.get("nx"):
                report.warnings.append(
                    "NX: Cannot execute shellcode on stack. Need ROP/ret2libc."
                )
            # ASLR/PIE need leak for ROP
            if report.binary_protections.get("pie") and \
               report.kernel_mitigations.get("aslr", "0") != "0":
                report.warnings.append(
                    "PIE + ASLR: Need address leak for ROP gadgets/libc addresses."
                )
            elif report.kernel_mitigations.get("aslr", "0") != "0":
                report.warnings.append(
                    "ASLR (no PIE): Binary addresses fixed, but libc randomized. "
                    "Can use binary gadgets, need leak for libc."
                )
            # FORTIFY may catch obvious cases
            if report.compiler_mitigations.get("fortify_source"):
                report.warnings.append(
                    "FORTIFY_SOURCE: May abort on obvious overflows (strcpy with known size)."
                )
            # NOTE: Full RELRO not directly relevant to stack overflow
            return

        # HEAP BUFFER OVERFLOW
        if any(x in vuln_type for x in ["heap_overflow", "heap_buffer"]):
            self._check_heap_mitigations(report, "heap overflow")
            return

        # USE-AFTER-FREE
        if any(x in vuln_type for x in ["uaf", "use_after_free"]):
            self._check_heap_mitigations(report, "use-after-free")
            # Additional UAF-specific
            report.warnings.append(
                "UAF: Exploitation depends on heap layout control (spray, groom). "
                "Goal: reallocate freed object with controlled data, trigger use."
            )
            return

        # DOUBLE FREE
        if any(x in vuln_type for x in ["double_free", "double-free"]):
            # tcache is PRIMARY mitigation for double-free
            if report.glibc_major_minor >= 2.29:
                report.warnings.append(
                    "TCACHE HARDENING (glibc 2.29+): Double-free detection via key. "
                    "Bypass: overwrite tcache key, or use fastbin (larger allocs)."
                )
            self._check_heap_mitigations(report, "double-free")
            return

        # TYPE CONFUSION
        if any(x in vuln_type for x in ["type_confusion", "type_conf"]):
            # CFI is PRIMARY mitigation
            if report.compiler_mitigations.get("cfi"):
                report.warnings.append(
                    "CFI: Validates indirect calls - blocks vtable hijacking. "
                    "Bypass: target non-CFI-protected calls, or corrupt data (not code ptrs)."
                )
            report.warnings.append(
                "TYPE CONFUSION: Usually leads to arbitrary R/W primitive. "
                "After gaining R/W, check ASLR/PIE for address requirements."
            )
            # ASLR/PIE relevant if exploiting R/W
            if report.binary_protections.get("pie") and \
               report.kernel_mitigations.get("aslr", "0") != "0":
                report.warnings.append(
                    "PIE + ASLR: If type confusion gives R/W, need leak first."
                )
            return

    def _check_heap_mitigations(self, report: FeasibilityReport, context: str):
        """
        Check heap-specific mitigations (shared by heap overflow, UAF, double-free).

        Relevant mitigations for heap exploitation:
        - glibc hooks removed (2.34+): no __free_hook/__malloc_hook
        - tcache hardening (2.29+): key checks, double-free detection
        - Full RELRO: no GOT overwrite
        - ASLR: need heap/libc address leak
        - NX: no shellcode on heap
        """
        # glibc hooks - major target removed
        if report.glibc_major_minor >= 2.34:
            report.warnings.append(
                f"GLIBC 2.34+: __free_hook/__malloc_hook REMOVED. "
                f"Cannot use hook overwrite for {context}. "
                "Alternatives: __exit_funcs, FILE vtables, TLS-dtor, stack pivot."
            )
        elif report.glibc_major_minor >= 2.29:
            report.warnings.append(
                f"GLIBC 2.29-2.33: Hooks still available but tcache hardened. "
                f"__free_hook/__malloc_hook remain valid targets for {context}."
            )

        # tcache hardening
        if report.glibc_major_minor >= 2.29:
            report.warnings.append(
                "TCACHE (2.29+): Safe-linking, key checks. "
                "Bypass: heap leak to decrypt safe-linking, or avoid tcache (larger chunks)."
            )

        # Full RELRO blocks GOT
        if report.binary_protections.get("full_relro"):
            report.warnings.append(
                "FULL RELRO: GOT is read-only. Cannot overwrite GOT entries. "
                "Target hooks (if available), FILE structs, or return addresses."
            )

        # ASLR/PIE
        if report.kernel_mitigations.get("aslr", "0") != "0":
            report.warnings.append(
                "ASLR: Need heap address leak for reliable exploitation. "
                "Also need libc leak for hook/system addresses."
            )

        # NX
        if report.binary_protections.get("nx"):
            report.warnings.append(
                "NX: Cannot execute shellcode on heap. Need code reuse (ROP, JOP)."
            )

    def _infer_payload_constraints(self, report: FeasibilityReport, vuln_type: str,
                                    input_handler: Optional[str] = None):
        """
        Infer payload byte constraints based on vulnerability type and input handler.

        Different input vectors have different restrictions on what bytes can appear
        in the exploit payload. This is CRITICAL for exploit development:

        String functions (strcpy, strcat, strcmp, strlen):
            - NUL (0x00) terminates the copy
            - Payload must be NUL-free until the intended end

        Line-based input (fgets, gets, recv with newline parsing):
            - Newline (0x0a) terminates input
            - Carriage return (0x0d) may also terminate

        scanf %s:
            - Whitespace terminates (space 0x20, tab 0x09, newline 0x0a, etc.)

        Format string (printf family):
            - NUL terminates format processing
            - % has special meaning (use %% to escape)

        Network protocols:
            - Often newline (0x0a) or CRLF (0x0d0a) terminates
            - HTTP headers: 0x0d0a terminates lines

        Encoding filters:
            - Base64: A-Za-z0-9+/= only
            - URL-safe: unreserved chars only
            - Printable: 0x20-0x7e only
            - Alphanumeric: A-Za-z0-9 only
        """
        vuln_lower = vuln_type.lower() if vuln_type else ""
        handler_lower = input_handler.lower() if input_handler else ""

        constraints = PayloadConstraints()

        # ─────────────────────────────────────────────────────────────────────
        # Infer from input handler if specified
        # ─────────────────────────────────────────────────────────────────────
        if handler_lower:
            constraints.input_handler = input_handler

            # String copy functions - NUL terminates
            if any(x in handler_lower for x in ['strcpy', 'strcat', 'strncpy', 'strncat',
                                                  'strcmp', 'strncmp', 'strlen', 'memcpy']):
                constraints.bad_bytes.append(0x00)
                constraints.bad_byte_reasons[0x00] = "NUL terminates string copy"
                constraints.encoding_suggestions.append(
                    "Avoid NUL bytes in payload, or use partial overwrites"
                )
                # CRITICAL: On x86_64, addresses have null at byte 6 (0x00007f...)
                # strcpy stops at null, so only ONE address can be embedded at payload end
                constraints.max_embeddable_addresses = 1

            # Line-based input - newline terminates
            if any(x in handler_lower for x in ['fgets', 'gets', 'getline', 'readline']):
                constraints.bad_bytes.append(0x0a)
                constraints.bad_byte_reasons[0x0a] = "Newline terminates fgets/gets"
                constraints.bad_bytes.append(0x00)
                constraints.bad_byte_reasons[0x00] = "NUL may terminate early"
                # fgets/gets allow null bytes WITHIN the input (they stop at newline)
                # So multiple addresses can be embedded as long as no newline
                constraints.max_embeddable_addresses = -1  # Unlimited

            # scanf %s - whitespace terminates
            if 'scanf' in handler_lower:
                for ws in [0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x20]:
                    constraints.bad_bytes.append(ws)
                constraints.bad_byte_reasons[0x20] = "Space terminates scanf %s"
                constraints.bad_byte_reasons[0x0a] = "Newline terminates scanf %s"
                # scanf %s stops at whitespace, and 64-bit addresses have nulls
                # Similar to strcpy - only 1 address at end
                constraints.max_embeddable_addresses = 1

            # Network recv/read - binary safe, length-limited only
            if any(x in handler_lower for x in ['recv', 'read', 'socket', 'network']):
                constraints.encoding_suggestions.append(
                    "Check protocol for line terminators (\\n, \\r\\n)"
                )
                # Binary safe - can embed any bytes including null
                constraints.max_embeddable_addresses = -1  # Unlimited

            # Base64 decoder - alphanumeric + /+=
            if any(x in handler_lower for x in ['base64', 'b64']):
                constraints.must_be_alphanumeric = True
                constraints.allowed_charset = "A-Za-z0-9+/="
                constraints.encoding_suggestions.append(
                    "Payload must be valid Base64 - use encoder"
                )

            # URL decode - printable, some chars encoded
            if any(x in handler_lower for x in ['urldecode', 'url_decode', 'percent']):
                constraints.must_be_printable = True
                constraints.allowed_charset = "printable ASCII (0x20-0x7e)"
                constraints.encoding_suggestions.append(
                    "Use URL encoding for special characters"
                )

            # XML/HTML input - restricted characters
            if any(x in handler_lower for x in ['xml', 'html', 'sax', 'dom']):
                constraints.must_be_printable = True
                # < > & " ' are special in XML
                for b in [0x3c, 0x3e, 0x26, 0x22, 0x27]:  # < > & " '
                    if b not in constraints.bad_bytes:
                        constraints.bad_bytes.append(b)
                constraints.bad_byte_reasons[0x3c] = "< starts XML tag"
                constraints.bad_byte_reasons[0x26] = "& starts XML entity"
                constraints.encoding_suggestions.append(
                    "Use XML entities or CDATA for special characters"
                )

            # JSON input
            if 'json' in handler_lower:
                constraints.must_be_printable = True
                # Control characters and quotes need escaping
                for b in [0x22, 0x5c]:  # " and \
                    if b not in constraints.bad_bytes:
                        constraints.bad_bytes.append(b)
                constraints.bad_byte_reasons[0x22] = "Quote terminates JSON string"
                constraints.bad_byte_reasons[0x5c] = "Backslash is escape character"

            # Alphanumeric filter detected
            if any(x in handler_lower for x in ['alnum', 'alphanumeric', 'isalnum']):
                constraints.must_be_alphanumeric = True
                constraints.allowed_charset = "A-Za-z0-9"
                # All non-alphanumeric bytes are bad
                for b in range(256):
                    if not (0x30 <= b <= 0x39 or 0x41 <= b <= 0x5a or 0x61 <= b <= 0x7a):
                        if b not in constraints.bad_bytes:
                            constraints.bad_bytes.append(b)
                constraints.encoding_suggestions.append(
                    "Use alphanumeric shellcode encoder (alpha2, ALPHA3)"
                )

            # Printable filter detected
            if any(x in handler_lower for x in ['print', 'isprint', 'ascii']):
                constraints.must_be_printable = True
                constraints.allowed_charset = "printable ASCII (0x20-0x7e)"
                # Non-printable bytes are bad
                for b in range(256):
                    if not (0x20 <= b <= 0x7e):
                        if b not in constraints.bad_bytes:
                            constraints.bad_bytes.append(b)

        # ─────────────────────────────────────────────────────────────────────
        # Infer from vulnerability type
        # ─────────────────────────────────────────────────────────────────────

        # Format string - special characters
        if any(x in vuln_lower for x in ['format', 'printf', 'sprintf']):
            if 0x00 not in constraints.bad_bytes:
                constraints.bad_bytes.append(0x00)
                constraints.bad_byte_reasons[0x00] = "NUL terminates format string"
            constraints.encoding_suggestions.append(
                "Use %hhn for single-byte writes to avoid NUL issues in addresses"
            )
            constraints.encoding_suggestions.append(
                "Addresses with NUL bytes: write lower bytes first, or use stack addresses"
            )

        # Buffer overflow - depends on copy function
        if any(x in vuln_lower for x in ['buffer', 'overflow', 'strcpy', 'sprintf']):
            if 0x00 not in constraints.bad_bytes:
                constraints.bad_bytes.append(0x00)
                constraints.bad_byte_reasons[0x00] = "NUL likely terminates buffer copy"
            constraints.encoding_suggestions.append(
                "ROP chains: choose gadgets without NUL bytes in addresses"
            )
            constraints.encoding_suggestions.append(
                "On x86-64: high addresses often have leading NULs, use stack pivot"
            )

        # ─────────────────────────────────────────────────────────────────────
        # General encoding suggestions based on constraints
        # ─────────────────────────────────────────────────────────────────────
        if constraints.must_be_alphanumeric:
            constraints.encoding_suggestions.append(
                "Use alphanumeric shellcode encoder (alpha2, ALPHA3, msfvenom -e x86/alpha_mixed)"
            )
            constraints.encoding_suggestions.append(
                "ROP: Find gadgets at alphanumeric addresses only (0x30-0x39, 0x41-0x5a, 0x61-0x7a)"
            )
        elif constraints.must_be_printable:
            constraints.encoding_suggestions.append(
                "Use printable shellcode encoder"
            )
            constraints.encoding_suggestions.append(
                "ROP: Find gadgets at printable addresses (0x20-0x7e)"
            )

        if constraints.bad_bytes and not constraints.encoding_suggestions:
            constraints.encoding_suggestions.append(
                "Analyze which addresses/gadgets avoid bad bytes"
            )

        report.payload_constraints = constraints

        # ─────────────────────────────────────────────────────────────────────
        # Create exploitation constraints (blocked vs viable techniques)
        # This is CRITICAL to prevent wasted effort on impossible techniques
        # ─────────────────────────────────────────────────────────────────────
        # Detect architecture from binary
        from .constants import detect_architecture
        if self.binary:
            arch = detect_architecture(str(self.binary))
            logger.info(f"Detected architecture: {arch}")
        else:
            arch = "x86_64"  # Default if no binary
        effective_handler = handler_lower or constraints.input_handler or ""

        # Create ExploitationConstraints with architecture + input handler context
        # The __post_init__ method will automatically determine blocked/viable techniques
        report.exploitation_constraints = ExploitationConstraints(
            arch=arch,
            input_handler=effective_handler
        )

        # Log critical constraint for exploit developers
        if not report.exploitation_constraints.strcpy_rop_viable:
            logger.warning(
                f"CONSTRAINT: strcpy ROP chains NOT viable on {arch} "
                f"(null bytes at position {report.exploitation_constraints.null_byte_position})"
            )
            for technique in report.exploitation_constraints.blocked_techniques:
                logger.warning(f"  BLOCKED: {technique}")

    def _compute_verdict(self, report: FeasibilityReport):
        """
        Compute final exploitability verdict based on all findings.

        The verdict considers:
        1. Critical blockers (e.g., %n disabled with no bypass)
        2. Empirically verified capabilities (e.g., %n actually works)
        3. Available write targets (e.g., .fini_array if GOT is protected)
        """
        # Check for critical blockers
        has_critical_blocker = False
        blocker_has_workaround = False

        for blocker in report.blockers:
            # %n disabled is critical for format string exploitation
            if '%n' in blocker.lower():
                # But check if empirical test showed it actually works
                if not report.glibc_n_disabled:
                    # Empirical test passed - not actually blocked
                    continue
                has_critical_blocker = True

        if has_critical_blocker:
            # Even with critical blockers, we say "unlikely" not "blocked"
            # There may always be obscure methods we don't know about
            if report.bypass_suggestions or report.environment_requirements:
                report.verdict = ExploitabilityVerdict.UNLIKELY
                logger.warning(
                    "Verdict: UNLIKELY - "
                    "No known viable path, but workarounds may exist (older glibc, etc.)"
                )
            else:
                report.verdict = ExploitabilityVerdict.UNLIKELY
                logger.warning(
                    "Verdict: UNLIKELY - "
                    "No known viable path with current mitigations"
                )
            return

        # Check for positive indicators that override warning count
        # If %n is verified working but standard targets (GOT, hooks) are blocked,
        # exploitation is DIFFICULT, not "likely" - alternative targets have high requirements
        if hasattr(report, 'glibc_n_disabled') and report.glibc_n_disabled is False:
            # %n verified working - but check if standard targets are available
            has_full_relro = report.binary_protections.get('full_relro', False)
            hooks_removed = (report.glibc_mitigations and
                           report.glibc_mitigations.hooks_removed if report.glibc_mitigations else False)

            if has_full_relro and hooks_removed:
                # Both GOT and hooks blocked - alternative targets are very limited
                # NOTE: Full RELRO also blocks .fini_array!
                report.verdict = ExploitabilityVerdict.DIFFICULT
                logger.info(
                    "Verdict: DIFFICULT - "
                    "%n works but GOT AND .fini_array (Full RELRO) blocked, hooks removed, "
                    "only stack/heap targets remain (require extra leaks)"
                )
            elif has_full_relro or hooks_removed:
                # One standard target blocked - still difficult but slightly easier
                report.verdict = ExploitabilityVerdict.DIFFICULT
                logger.info(
                    "Verdict: DIFFICULT - "
                    "%n works but some standard targets blocked"
                )
            else:
                # Standard targets available - truly likely exploitable
                report.verdict = ExploitabilityVerdict.LIKELY_EXPLOITABLE
                logger.info(
                    "Verdict: LIKELY_EXPLOITABLE - "
                    "%n format specifier verified working, standard targets available"
                )
            return

        # No stack canary = direct return address overwrite possible
        if not report.binary_protections.get('canary', True):
            report.verdict = ExploitabilityVerdict.LIKELY_EXPLOITABLE
            logger.info(
                "Verdict: LIKELY_EXPLOITABLE - "
                "No stack canary, return address overwrite possible"
            )
            return

        # Fall back to warning-based heuristic
        if len(report.warnings) >= 3:
            report.verdict = ExploitabilityVerdict.LIKELY_EXPLOITABLE
            logger.info(
                "Verdict: LIKELY_EXPLOITABLE - "
                "Multiple mitigations but exploitation may be possible"
            )
        elif report.warnings:
            report.verdict = ExploitabilityVerdict.LIKELY_EXPLOITABLE
            logger.info(
                "Verdict: LIKELY_EXPLOITABLE - "
                "Few mitigations present, exploitation likely feasible"
            )
        else:
            report.verdict = ExploitabilityVerdict.LIKELY_EXPLOITABLE
            logger.info(
                "Verdict: LIKELY_EXPLOITABLE - "
                "No significant mitigations detected"
            )

    # ═══════════════════════════════════════════════════════════════════════════
    # EXTENDED ANALYSIS METHODS (runtime-queried, no databases)
    # ═══════════════════════════════════════════════════════════════════════════

    def _detect_input_handlers(self, report: FeasibilityReport):
        """
        Detect input handling functions from binary imports.

        Scans binary's dynamic symbols to identify how input is read.
        This helps infer payload byte constraints automatically.
        """
        if not self.binary:
            return

        dangerous_input_funcs = {
            # String functions (NUL terminates)
            'strcpy': 'NUL terminates',
            'strncpy': 'NUL terminates',
            'strcat': 'NUL terminates',
            'strncat': 'NUL terminates',
            'sprintf': 'NUL terminates, format expansion',
            'vsprintf': 'NUL terminates, format expansion',
            'snprintf': 'NUL terminates (safer)',

            # Line-based input (newline terminates)
            'gets': 'DANGEROUS, newline terminates',
            'fgets': 'newline terminates',
            'getline': 'newline terminates',

            # scanf family (whitespace terminates %s)
            'scanf': 'whitespace terminates %s',
            'fscanf': 'whitespace terminates %s',
            'sscanf': 'whitespace terminates %s',

            # Network/file (may have protocol-specific terminators)
            'recv': 'check protocol terminators',
            'recvfrom': 'check protocol terminators',
            'read': 'raw bytes, check usage',

            # Format string sinks
            'printf': 'format string sink',
            'fprintf': 'format string sink',
            'syslog': 'format string sink',
        }

        try:
            # Use nm to get dynamic symbols
            result = subprocess.run(
                ['nm', '-D', str(self.binary)],
                capture_output=True, text=True, timeout=10
            )

            detected = []
            if result.returncode == 0:
                for func, note in dangerous_input_funcs.items():
                    # Match function name (with possible @ version suffix)
                    if re.search(rf'\b{func}(@|$|\s)', result.stdout):
                        detected.append(func)
                        logger.debug(f"Detected input handler: {func} ({note})")

            report.detected_input_handlers = detected

            if detected:
                logger.info(f"Detected input handlers: {', '.join(detected)}")

            # Count format string calls in the binary
            # This is critical: only ONE printf call = single-shot exploitation only
            self._count_format_string_calls(report)

        except Exception as e:
            logger.debug(f"Input handler detection failed: {e}")

    def _count_format_string_calls(self, report: FeasibilityReport):
        """
        Count how many times format string functions are called.

        Single printf call = limited exploitation options:
        - Can only do ONE multi-byte write
        - Cannot chain writes across multiple calls
        - Makes .fini_array exploit harder (need one-shot gadget)

        Multiple printf calls = more options:
        - Can chain writes across calls
        - Can do staged exploitation
        """
        if not self.binary:
            return

        # Format string functions that could be exploitable if format arg is user-controlled
        # Note: We count all calls - static analysis can't determine if format arg is controlled
        # Direct output (most exploitable): printf, fprintf, dprintf
        # Buffer output (exploitable via %n): sprintf, snprintf, vsprintf, vsnprintf
        # Variadic versions: vprintf, vfprintf
        format_funcs = ['printf', 'fprintf', 'sprintf', 'snprintf', 'vprintf',
                       'vfprintf', 'vsprintf', 'vsnprintf', 'dprintf']

        try:
            # Use objdump to find call instructions
            result = subprocess.run(
                ['objdump', '-d', str(self.binary)],
                capture_output=True, text=True, timeout=30
            )

            if result.returncode == 0:
                total_calls = 0
                sink_counts = {}

                for func in format_funcs:
                    # Match: call <printf@plt> or call *<addr> with printf in relocation
                    # Pattern: callq ... <printf@plt>
                    count = len(re.findall(rf'call[q]?\s+[^<]*<{func}@plt>', result.stdout))
                    if count > 0:
                        sink_counts[func] = count
                        total_calls += count

                report.format_string_call_count = total_calls
                report.format_string_sinks = sink_counts
                report.single_shot_format_string = (total_calls == 1)

                if total_calls > 0:
                    logger.info(f"Format string sinks: {sink_counts} (total: {total_calls})")
                    if report.single_shot_format_string:
                        logger.warning(
                            "SINGLE FORMAT STRING CALL: Limited exploitation - "
                            "cannot chain writes across multiple printf calls"
                        )

        except Exception as e:
            logger.debug(f"Format string call counting failed: {e}")

    def _query_libc_info(self, report: FeasibilityReport):
        """
        Query the actual libc for offsets (no database needed).

        Uses ldd to find libc path, then nm/strings to get offsets.
        """
        if not self.binary:
            return

        libc_info = LibcInfo()

        try:
            # Get libc path from ldd
            result = subprocess.run(
                ['ldd', str(self.binary)],
                capture_output=True, text=True, timeout=10
            )

            if result.returncode == 0:
                # Parse libc path: libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x...)
                match = re.search(r'libc\.so\.\d+\s+=>\s+(\S+)', result.stdout)
                if match:
                    libc_info.path = match.group(1)
                    logger.info(f"Libc path: {libc_info.path}")

            if not libc_info.path:
                return

            # Get libc version
            try:
                ver_result = subprocess.run(
                    [libc_info.path],
                    capture_output=True, text=True, timeout=5
                )
                # First line usually contains version
                if ver_result.stdout:
                    first_line = ver_result.stdout.split('\n')[0]
                    libc_info.version = first_line
            except (subprocess.SubprocessError, OSError):
                pass  # Libc version detection failure is non-critical

            # Query offsets using nm -D
            nm_result = subprocess.run(
                ['nm', '-D', libc_info.path],
                capture_output=True, text=True, timeout=30
            )

            if nm_result.returncode == 0:
                symbols = nm_result.stdout

                # system() - handle versioned symbols like system@@GLIBC_2.2.5
                match = re.search(r'^([0-9a-f]+)\s+\w+\s+system(?:@@|\s|$)', symbols, re.MULTILINE)
                if match:
                    libc_info.system_offset = int(match.group(1), 16)

                # execve()
                match = re.search(r'^([0-9a-f]+)\s+\w+\s+execve(?:@@|\s|$)', symbols, re.MULTILINE)
                if match:
                    libc_info.execve_offset = int(match.group(1), 16)

                # __malloc_hook
                match = re.search(r'^([0-9a-f]+)\s+\w+\s+__malloc_hook(?:@@|\s|$)', symbols, re.MULTILINE)
                if match:
                    libc_info.malloc_hook_offset = int(match.group(1), 16)

                # __free_hook
                match = re.search(r'^([0-9a-f]+)\s+\w+\s+__free_hook(?:@@|\s|$)', symbols, re.MULTILINE)
                if match:
                    libc_info.free_hook_offset = int(match.group(1), 16)

            # Find "/bin/sh" string offset
            strings_result = subprocess.run(
                ['strings', '-t', 'x', libc_info.path],
                capture_output=True, text=True, timeout=30
            )

            if strings_result.returncode == 0:
                match = re.search(r'^\s*([0-9a-f]+)\s+/bin/sh$', strings_result.stdout, re.MULTILINE)
                if match:
                    libc_info.bin_sh_offset = int(match.group(1), 16)

            # Try one_gadget if available
            try:
                og_result = subprocess.run(
                    ['one_gadget', libc_info.path],
                    capture_output=True, text=True, timeout=60
                )
                if og_result.returncode == 0:
                    # Parse one_gadget output with constraints:
                    # 0xf8d09 execve("/bin/sh", rbp-0x50, r15)
                    # constraints:
                    #   address rbp-0x48 is writable
                    #   r14 == NULL || ...
                    lines = og_result.stdout.split('\n')
                    current_gadget = None
                    current_constraints = []

                    for line in lines:
                        # New gadget entry
                        gadget_match = re.match(r'^(0x[0-9a-f]+)\s+(.+)$', line)
                        if gadget_match:
                            # Save previous gadget if exists
                            if current_gadget is not None:
                                current_gadget.constraints = current_constraints
                                libc_info.one_gadgets_detailed.append(current_gadget)
                                libc_info.one_gadgets.append(current_gadget.offset)

                            offset = int(gadget_match.group(1), 16)
                            desc = gadget_match.group(2)
                            current_gadget = OneGadget(offset=offset, description=desc)
                            current_constraints = []

                            # Classify partial overwrite feasibility by write size needed
                            #
                            # If we have a libc address somewhere (e.g., GOT entry pointing to libc),
                            # we can partial-overwrite it to reach different libc offsets:
                            #   - 1 byte:  offsets 0x00-0xFF (256 bytes from any aligned libc addr)
                            #   - 2 bytes: offsets 0x0000-0xFFFF (64KB, ~12 bits of ASLR entropy)
                            #   - 3 bytes: offsets 0x000000-0xFFFFFF (16MB)
                            #   - 4 bytes: offsets 0x00000000-0xFFFFFFFF (4GB, always covers libc)
                            #
                            # Note: This assumes we START from a libc address.
                            # Cross-region writes (PIE → libc) are different and need full 8 bytes.
                            current_gadget.bytes_from_base = (offset.bit_length() + 7) // 8

                            # Categorize by practical partial overwrite scenarios:
                            # - 2-byte partial: offset < 0x10000 (rare, high ASLR entropy remains)
                            # - 3-byte partial: offset < 0x1000000 (common, ~12 bits ASLR to brute)
                            # We report the minimum bytes needed, let user decide if viable
                            current_gadget.partial_overwrite_viable = True  # All are technically possible
                            # The meaningful question is: how many bytes to write?

                        # Constraint line (starts with spaces after "constraints:")
                        elif current_gadget is not None and line.strip() and not line.startswith('constraints'):
                            constraint = line.strip()
                            if constraint:
                                current_constraints.append(constraint)

                    # Don't forget last gadget
                    if current_gadget is not None:
                        current_gadget.constraints = current_constraints
                        libc_info.one_gadgets_detailed.append(current_gadget)
                        libc_info.one_gadgets.append(current_gadget.offset)

                    # Find best (lowest offset) one_gadget for partial overwrite scenarios
                    if libc_info.one_gadgets_detailed:
                        best = min(libc_info.one_gadgets_detailed, key=lambda g: g.offset)
                        libc_info.best_partial_gadget = best
                        # "Has partial overwrite gadget" = at least one with offset < 0x10000 (2-byte)
                        # This is the most restrictive case (strcpy can write 6 bytes max)
                        libc_info.has_partial_overwrite_gadget = best.offset < 0x10000
                        logger.info(
                            f"Best one_gadget: 0x{best.offset:x} "
                            f"({best.bytes_from_base} bytes needed, "
                            f"2-byte viable: {libc_info.has_partial_overwrite_gadget})"
                        )

            except FileNotFoundError:
                logger.debug("one_gadget not installed")
            except Exception as e:
                logger.debug(f"one_gadget failed: {e}")

            # Search for useful gadgets in 2-byte partial overwrite range (0x0000-0xFFFF)
            # These are reachable from any libc address via 2-byte overwrite
            self._find_2byte_libc_gadgets(report, libc_info.path)

            report.libc_info = libc_info

        except Exception as e:
            logger.debug(f"Libc query failed: {e}")

    def _find_2byte_libc_gadgets(self, report: FeasibilityReport, libc_path: str):
        """
        Find useful gadgets in libc's 2-byte partial overwrite range (0x0000-0xFFFF).

        If you have a libc address on the stack and can do a 2-byte partial overwrite,
        these gadgets are reachable. Common useful patterns:
        - leave; ret (stack pivot)
        - call *REG (indirect call)
        - jmp *REG (indirect jump)
        - syscall (if registers controlled)
        - pop rdi; ret (for ret2libc setup)

        This is the "0x2XXXX range" analysis from exploit development.
        """
        useful_gadgets = []

        try:
            # Use ROPgadget to find gadgets in low offset range
            result = subprocess.run(
                ['ROPgadget', '--binary', libc_path, '--offset', '0x0'],
                capture_output=True, text=True, timeout=120
            )

            if result.returncode != 0:
                logger.debug("ROPgadget failed on libc")
                return

            # Parse gadgets and filter to 2-byte range
            # Format: 0x00000000000XXXXX : gadget instruction
            for line in result.stdout.split('\n'):
                match = re.match(r'^(0x[0-9a-f]+)\s*:\s*(.+)$', line.strip())
                if not match:
                    continue

                offset = int(match.group(1), 16)
                gadget = match.group(2).strip()

                # Only keep gadgets in 2-byte range (0x0000-0xFFFF)
                # Actually, let's look at 0x20000-0x30000 range too (common "2XXXX" range)
                # This is where partial overwrites often land
                if offset > 0x30000:
                    continue

                # Look for particularly useful gadgets
                usefulness = None
                if 'leave' in gadget and 'ret' in gadget:
                    usefulness = 'stack_pivot'
                elif re.search(r'call\s+\*', gadget):
                    usefulness = 'indirect_call'
                elif re.search(r'jmp\s+\*', gadget):
                    usefulness = 'indirect_jmp'
                elif gadget.strip() == 'syscall':
                    usefulness = 'syscall'
                elif 'pop rdi' in gadget and 'ret' in gadget:
                    usefulness = 'pop_rdi'
                elif 'pop rsi' in gadget and 'ret' in gadget:
                    usefulness = 'pop_rsi'
                elif gadget.strip() == 'ret':
                    usefulness = 'ret_sled'

                if usefulness:
                    useful_gadgets.append({
                        'offset': offset,
                        'gadget': gadget,
                        'type': usefulness,
                        'bytes_needed': 2 if offset < 0x10000 else 3
                    })

            # Sort by offset and keep most useful ones
            useful_gadgets.sort(key=lambda g: g['offset'])

            # Deduplicate by type (keep lowest offset for each type)
            seen_types = set()
            deduped = []
            for g in useful_gadgets:
                if g['type'] not in seen_types:
                    deduped.append(g)
                    seen_types.add(g['type'])

            report.libc_2byte_gadgets = deduped[:10]  # Keep top 10

            if deduped:
                logger.info(f"Found {len(deduped)} useful libc gadgets in 2-byte range")
                for g in deduped[:3]:
                    logger.debug(f"  0x{g['offset']:x}: {g['gadget']} ({g['type']})")

        except FileNotFoundError:
            logger.debug("ROPgadget not installed")
        except subprocess.TimeoutExpired:
            logger.debug("ROPgadget timed out on libc")
        except Exception as e:
            logger.debug(f"2-byte gadget search failed: {e}")

    def _analyze_rop_gadgets(self, report: FeasibilityReport, bad_bytes: List[int] = None):
        """
        Analyze ROP gadgets in binary using ROPgadget.

        Finds essential gadgets and filters by bad bytes.
        """
        if not self.binary:
            return

        if bad_bytes is None:
            bad_bytes = []
            if report.payload_constraints:
                bad_bytes = report.payload_constraints.bad_bytes

        rop_info = ROPGadgetInfo()

        try:
            # Run ROPgadget
            result = subprocess.run(
                ['ROPgadget', '--binary', str(self.binary)],
                capture_output=True, text=True, timeout=120
            )

            if result.returncode != 0:
                logger.debug("ROPgadget failed or not installed")
                return

            # Parse gadgets
            gadgets = []
            for line in result.stdout.split('\n'):
                # Format: 0x0000000000401234 : pop rdi ; ret
                match = re.match(r'^(0x[0-9a-f]+)\s+:\s+(.+)$', line.strip())
                if match:
                    addr = int(match.group(1), 16)
                    instr = match.group(2).strip()
                    gadgets.append((addr, instr))

            rop_info.total_gadgets = len(gadgets)

            # Filter by bad bytes
            def has_bad_byte(addr: int) -> bool:
                addr_bytes = addr.to_bytes(8, 'little')
                return any(b in bad_bytes for b in addr_bytes)

            # Charset filtering helpers
            def is_printable_addr(addr: int) -> bool:
                """Check if all non-null bytes in address are printable ASCII."""
                for b in addr.to_bytes(8, 'little'):
                    if b != 0 and not (0x20 <= b <= 0x7e):
                        return False
                return True

            def is_alphanumeric_addr(addr: int) -> bool:
                """Check if all non-null bytes in address are alphanumeric."""
                for b in addr.to_bytes(8, 'little'):
                    if b != 0 and not (0x30 <= b <= 0x39 or 0x41 <= b <= 0x5a or 0x61 <= b <= 0x7a):
                        return False
                return True

            usable = [(addr, instr) for addr, instr in gadgets if not has_bad_byte(addr)]
            rop_info.usable_gadgets = len(usable)
            rop_info.filtered_by_bad_bytes = len(gadgets) - len(usable)

            # Count charset-compatible gadgets (for constrained input scenarios)
            rop_info.printable_gadgets = sum(1 for addr, _ in usable if is_printable_addr(addr))
            rop_info.alphanumeric_gadgets = sum(1 for addr, _ in usable if is_alphanumeric_addr(addr))

            # If payload constraints require charset filtering, note the impact
            if report.payload_constraints:
                if report.payload_constraints.must_be_alphanumeric:
                    rop_info.filtered_by_charset = rop_info.usable_gadgets - rop_info.alphanumeric_gadgets
                    logger.info(f"Charset filter (alphanumeric): {rop_info.alphanumeric_gadgets} gadgets usable")
                elif report.payload_constraints.must_be_printable:
                    rop_info.filtered_by_charset = rop_info.usable_gadgets - rop_info.printable_gadgets
                    logger.info(f"Charset filter (printable): {rop_info.printable_gadgets} gadgets usable")

            # Find essential gadgets (from usable set)
            for addr, instr in usable:
                instr_lower = instr.lower()

                # pop rdi ; ret
                if 'pop rdi' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rdi_ret:
                    if instr_lower.strip() in ['pop rdi ; ret', 'pop rdi; ret']:
                        rop_info.pop_rdi_ret = addr

                # pop rsi ; ret (may have pop r15)
                if 'pop rsi' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rsi_ret:
                    rop_info.pop_rsi_ret = addr

                # pop rdx ; ret
                if 'pop rdx' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rdx_ret:
                    rop_info.pop_rdx_ret = addr

                # pop rax ; ret
                if 'pop rax' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rax_ret:
                    rop_info.pop_rax_ret = addr

                # pop rbx ; ret
                if 'pop rbx' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rbx_ret:
                    rop_info.pop_rbx_ret = addr

                # pop rcx ; ret
                if 'pop rcx' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rcx_ret:
                    rop_info.pop_rcx_ret = addr

                # pop rbp ; ret
                if 'pop rbp' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rbp_ret:
                    rop_info.pop_rbp_ret = addr

                # pop rsp ; ret (stack pivot gadget)
                if 'pop rsp' in instr_lower and 'ret' in instr_lower and not rop_info.pop_rsp_ret:
                    rop_info.pop_rsp_ret = addr

                # syscall ; ret
                if 'syscall' in instr_lower and not rop_info.syscall_ret:
                    rop_info.syscall_ret = addr

                # leave ; ret (stack pivot)
                if 'leave' in instr_lower and 'ret' in instr_lower and not rop_info.leave_ret:
                    if instr_lower.strip() in ['leave ; ret', 'leave; ret']:
                        rop_info.leave_ret = addr

                # call rax (useful for calling function pointers)
                if 'call rax' in instr_lower and not rop_info.call_rax:
                    rop_info.call_rax = addr

                # Simple ret
                if instr_lower.strip() == 'ret' and not rop_info.ret:
                    rop_info.ret = addr

            # Store some gadgets for reference (convert to dict format for all_gadgets)
            rop_info.all_gadgets = [
                {'address': addr, 'instruction': instr}
                for addr, instr in usable[:50]
            ]

            report.rop_gadgets = rop_info
            logger.info(f"ROP gadgets: {rop_info.total_gadgets} total, {rop_info.usable_gadgets} usable")

        except FileNotFoundError:
            logger.debug("ROPgadget not installed")
        except Exception as e:
            logger.debug(f"ROP gadget analysis failed: {e}")

    def _analyze_elf_structure(self, report: FeasibilityReport):
        """
        Analyze ELF structure for write targets.

        Uses readelf to find sections and GOT entries.
        """
        if not self.binary:
            return

        elf = ELFStructure()

        try:
            # Get section headers
            result = subprocess.run(
                ['readelf', '-S', str(self.binary)],
                capture_output=True, text=True, timeout=10
            )

            if result.returncode == 0:
                # Parse sections - handle both single-line and multi-line formats
                # Modern readelf uses two lines per section:
                #   [23] .fini_array       FINI_ARRAY       0000000000003db0  00002db0
                #        0000000000000008  0000000000000008  WA       0     0     8
                # Older formats have it on one line

                lines = result.stdout.split('\n')
                current_section = None
                current_addr = None

                for i, line in enumerate(lines):
                    # Try to match section header line: [Nr] Name Type Address Offset
                    # Name can be truncated with [...] for long names
                    match = re.search(
                        r'\[\s*\d+\]\s+(\.[\w.\[\]]+)\s+\w+\s+([0-9a-f]+)\s+[0-9a-f]+',
                        line
                    )
                    if match:
                        name = match.group(1)
                        # Handle truncated names like ".note.gnu.pr[...]"
                        if '[...]' in name:
                            name = name.split('[...]')[0]
                        addr = int(match.group(2), 16)

                        # Check if size is on this line (old format) or next line (new format)
                        # Old: [ 1] .interp PROGBITS 0000000000400200 00000200 0000001c 00 A 0 0 1
                        size_match = re.search(
                            r'\[\s*\d+\]\s+\.[\w.\[\]]+\s+\w+\s+[0-9a-f]+\s+[0-9a-f]+\s+([0-9a-f]+)',
                            line
                        )
                        if size_match:
                            size = int(size_match.group(1), 16)
                        else:
                            # Size is on next line (new format)
                            if i + 1 < len(lines):
                                size_line = lines[i + 1].strip()
                                size_match = re.match(r'^([0-9a-f]+)', size_line)
                                if size_match:
                                    size = int(size_match.group(1), 16)
                                else:
                                    size = 0
                            else:
                                size = 0

                        if name == '.got.plt' or name == '.got':
                            elf.got_plt_addr = addr
                            elf.got_plt_size = size
                        elif name == '.fini_array':
                            elf.fini_array_addr = addr
                            elf.fini_array_size = size
                        elif name == '.init_array':
                            elf.init_array_addr = addr
                            elf.init_array_size = size
                        elif name == '.bss':
                            elf.bss_addr = addr
                            elf.bss_size = size
                        elif name == '.data':
                            elf.data_addr = addr
                            elf.data_size = size

            # Get GOT entries (relocations)
            rel_result = subprocess.run(
                ['readelf', '-r', str(self.binary)],
                capture_output=True, text=True, timeout=10
            )

            if rel_result.returncode == 0:
                # Parse: Offset Info Type Sym.Value Sym.Name + Addend
                for line in rel_result.stdout.split('\n'):
                    # Match: 000000601018 000200000007 R_X86_64_JUMP_SLO 0000000000000000 printf@GLIBC_2.2.5
                    match = re.search(
                        r'^([0-9a-f]+)\s+[0-9a-f]+\s+\S+\s+[0-9a-f]+\s+(\w+)',
                        line.strip()
                    )
                    if match:
                        addr = int(match.group(1), 16)
                        func = match.group(2).split('@')[0]  # Remove version
                        if func and addr:
                            elf.got_entries[func] = addr

            report.elf_structure = elf
            logger.info(f"ELF structure: GOT={len(elf.got_entries)} entries, "
                       f"fini_array={'yes' if elf.fini_array_addr else 'no'}")

        except Exception as e:
            logger.debug(f"ELF analysis failed: {e}")

    def _check_seccomp(self, report: FeasibilityReport):
        """
        Check for seccomp sandbox restrictions.

        Queries /proc/self/status and tries seccomp-tools if available.
        """
        seccomp = SeccompInfo()

        try:
            # Check current process seccomp status (for reference)
            with open('/proc/self/status', 'r') as f:
                status = f.read()
                match = re.search(r'^Seccomp:\s*(\d+)', status, re.MULTILINE)
                if match:
                    mode = int(match.group(1))
                    if mode > 0:
                        seccomp.seccomp_mode = mode
                        seccomp.seccomp_enabled = True
                        logger.warning(f"Seccomp enabled (mode {mode}) on analysis process")

            # Try seccomp-tools on binary if available
            if self.binary:
                try:
                    result = subprocess.run(
                        ['seccomp-tools', 'dump', str(self.binary)],
                        capture_output=True, text=True, timeout=30,
                        input=''  # Don't hang waiting for input
                    )

                    if result.returncode == 0 and result.stdout:
                        seccomp.seccomp_enabled = True
                        seccomp.seccomp_mode = 2  # Filter mode

                        # Parse for blocked syscalls
                        if 'execve' in result.stdout and 'KILL' in result.stdout:
                            seccomp.execve_allowed = False
                            seccomp.blocked_syscalls.append('execve')

                        if 'mprotect' in result.stdout and 'KILL' in result.stdout:
                            seccomp.mprotect_allowed = False
                            seccomp.blocked_syscalls.append('mprotect')

                except FileNotFoundError:
                    logger.debug("seccomp-tools not installed")
                except subprocess.TimeoutExpired:
                    logger.debug("seccomp-tools timed out (binary may need input)")
                except Exception as e:
                    logger.debug(f"seccomp-tools failed: {e}")

            report.seccomp = seccomp

            if seccomp.seccomp_enabled:
                logger.info(f"Seccomp: enabled (mode {seccomp.seccomp_mode})")
                if not seccomp.execve_allowed:
                    report.blockers.append("SECCOMP: execve() blocked - cannot spawn shell")
            else:
                logger.info("Seccomp: disabled")

        except Exception as e:
            logger.debug(f"Seccomp check failed: {e}")

    def _rank_write_targets(self, report: FeasibilityReport, bad_bytes: List[int] = None):
        """
        Rank write targets based on mitigations and feasibility.

        Deterministic ranking - no database needed.
        """
        if bad_bytes is None:
            bad_bytes = []
            if report.payload_constraints:
                bad_bytes = report.payload_constraints.bad_bytes

        def addr_has_bad_bytes(addr: int) -> bool:
            if not addr:
                return False
            addr_bytes = addr.to_bytes(8, 'little')
            return any(b in bad_bytes for b in addr_bytes)

        targets = []

        # GOT entries (if not Full RELRO)
        if not report.binary_protections.get('full_relro'):
            if report.elf_structure and report.elf_structure.got_entries:
                for func, addr in report.elf_structure.got_entries.items():
                    targets.append(WriteTarget(
                        name=f"GOT[{func}]",
                        address=addr,
                        has_bad_bytes=addr_has_bad_bytes(addr),
                        needs_leak=report.binary_protections.get('pie', False),
                        reliability="high",
                        notes="Overwrite to redirect function call"
                    ))
        else:
            logger.debug("Full RELRO - GOT not writable")

        # .fini_array (only works if NOT Full RELRO)
        # Full RELRO maps .fini_array read-only after startup
        if report.elf_structure and report.elf_structure.fini_array_addr:
            if not report.binary_protections.get('full_relro'):
                addr = report.elf_structure.fini_array_addr
                targets.append(WriteTarget(
                    name=".fini_array[0]",
                    address=addr,
                    has_bad_bytes=addr_has_bad_bytes(addr),
                    needs_leak=report.binary_protections.get('pie', False),
                    reliability="high",
                    notes="Called at exit(), works with Partial RELRO"
                ))
            else:
                logger.debug("Full RELRO - .fini_array not writable")

        # .init_array (only works if NOT Full RELRO, and called EARLY during startup)
        # Less useful than .fini_array since it's called before main()
        if report.elf_structure and report.elf_structure.init_array_addr:
            if not report.binary_protections.get('full_relro'):
                addr = report.elf_structure.init_array_addr
                targets.append(WriteTarget(
                    name=".init_array[0]",
                    address=addr,
                    has_bad_bytes=addr_has_bad_bytes(addr),
                    needs_leak=report.binary_protections.get('pie', False),
                    reliability="low",  # Called before main, limited use
                    notes="Called at startup (before main), limited exploitation window"
                ))
            else:
                logger.debug("Full RELRO - .init_array not writable")

        # __malloc_hook (if glibc < 2.34)
        if report.libc_info and report.libc_info.malloc_hook_offset:
            if report.glibc_major_minor < 2.34:
                targets.append(WriteTarget(
                    name="__malloc_hook",
                    address=report.libc_info.malloc_hook_offset,
                    has_bad_bytes=addr_has_bad_bytes(report.libc_info.malloc_hook_offset),
                    needs_leak=True,  # Need libc base
                    reliability="high",
                    notes="Triggered on malloc(), needs libc leak"
                ))

        # __free_hook (if glibc < 2.34)
        if report.libc_info and report.libc_info.free_hook_offset:
            if report.glibc_major_minor < 2.34:
                targets.append(WriteTarget(
                    name="__free_hook",
                    address=report.libc_info.free_hook_offset,
                    has_bad_bytes=addr_has_bad_bytes(report.libc_info.free_hook_offset),
                    needs_leak=True,
                    reliability="high",
                    notes="Triggered on free(), needs libc leak"
                ))

        # Return address (stack) - always an option
        targets.append(WriteTarget(
            name="return_address",
            address=0,  # Stack address, varies at runtime
            is_absolute=True,  # Stack addresses are absolute (once leaked)
            has_bad_bytes=False,  # Usually no bad bytes in stack
            needs_leak=True,  # Need stack leak
            reliability="medium",
            notes="Overwrite saved RIP on stack"
        ))

        # Sort by: no bad bytes > has bad bytes, then high > medium > low reliability
        reliability_order = {'high': 0, 'medium': 1, 'low': 2}
        targets.sort(key=lambda t: (t.has_bad_bytes, reliability_order.get(t.reliability, 3)))

        report.write_targets = targets
        logger.info(f"Write targets: {len(targets)} identified")

    def _sample_address_space(self, report: FeasibilityReport, num_samples: int = 5):
        """
        Sample the address space to understand ASLR entropy and null byte issues.

        Runs the binary multiple times to observe address variations.
        No database needed - direct runtime observation.
        """
        if not self.binary:
            logger.debug("No binary path - skipping address space sampling")
            return

        addr_info = AddressSpaceInfo()

        # Collect samples by running binary and reading /proc/pid/maps
        binary_bases = []
        libc_bases = []
        ld_bases = []  # Dynamic linker (ld-linux)
        stack_addrs = []
        heap_addrs = []

        binary_name = self.binary.name

        for i in range(num_samples):
            try:
                # Start process, get its maps, then kill it
                # Use timeout to avoid hanging on interactive binaries
                proc = subprocess.Popen(
                    [str(self.binary)],
                    stdin=subprocess.PIPE,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )

                try:
                    # Read /proc/pid/maps
                    maps_path = f"/proc/{proc.pid}/maps"
                    with open(maps_path, 'r') as f:
                        maps_content = f.read()

                    # Parse maps
                    for line in maps_content.strip().split('\n'):
                        parts = line.split()
                        if len(parts) < 6:
                            continue

                        addr_range = parts[0]
                        perms = parts[1]
                        pathname = parts[5] if len(parts) > 5 else ""

                        start_addr = int(addr_range.split('-')[0], 16)

                        # Binary base (executable region of our binary)
                        if binary_name in pathname and 'x' in perms:
                            binary_bases.append(start_addr)

                        # Libc base
                        if 'libc' in pathname and 'x' in perms:
                            libc_bases.append(start_addr)

                        # Dynamic linker base (ld-linux-x86-64.so, ld-linux.so, ld.so)
                        # Useful for ret2dlresolve attacks
                        if ('ld-linux' in pathname or 'ld.so' in pathname) and 'x' in perms:
                            ld_bases.append(start_addr)

                        # Stack
                        if '[stack]' in pathname:
                            stack_addrs.append(start_addr)

                        # Heap
                        if '[heap]' in pathname:
                            heap_addrs.append(start_addr)

                finally:
                    # Clean up
                    proc.kill()
                    proc.wait()

            except Exception as e:
                logger.debug(f"Sample {i} failed: {e}")
                continue

        # Calculate entropy from observed variations
        def calculate_entropy(samples: List[int]) -> tuple:
            """Calculate approximate entropy bits from address samples."""
            if not samples or len(samples) < 2:
                return (samples[0] if samples else None, 0, False)

            # Get the base sample
            base = samples[0]

            # Find bits that vary
            varying_bits = 0
            for s in samples[1:]:
                varying_bits |= (base ^ s)

            # Count bits that vary
            entropy = bin(varying_bits).count('1')

            # Check for null bytes in typical addresses
            has_nulls = any(b == 0 for b in base.to_bytes(8, 'little'))

            return (base, entropy, has_nulls)

        # Process samples
        if binary_bases:
            base, entropy, has_nulls = calculate_entropy(binary_bases)
            addr_info.binary_base_sample = base
            addr_info.binary_entropy_bits = entropy
            addr_info.binary_has_nulls = has_nulls
            logger.info(f"Binary base: 0x{base:x}, entropy: ~{entropy} bits")

        if libc_bases:
            base, entropy, has_nulls = calculate_entropy(libc_bases)
            addr_info.libc_base_sample = base
            addr_info.libc_entropy_bits = entropy
            addr_info.libc_has_nulls = has_nulls
            logger.info(f"Libc base: 0x{base:x}, entropy: ~{entropy} bits")

        if ld_bases:
            base, entropy, has_nulls = calculate_entropy(ld_bases)
            addr_info.ld_base_sample = base
            logger.info(f"Dynamic linker base: 0x{base:x}, entropy: ~{entropy} bits")

        if stack_addrs:
            base, entropy, has_nulls = calculate_entropy(stack_addrs)
            addr_info.stack_sample = base
            addr_info.stack_entropy_bits = entropy
            addr_info.stack_has_nulls = has_nulls
            logger.info(f"Stack: 0x{base:x}, entropy: ~{entropy} bits")

        if heap_addrs:
            base, _, _ = calculate_entropy(heap_addrs)
            addr_info.heap_sample = base

        report.address_space = addr_info

    def _analyze_exploit_primitives(self, report: FeasibilityReport, vuln_type: str):
        """
        Determine what exploit primitives a vulnerability class provides.

        Deterministic categorization based on vuln type.
        """
        if not vuln_type:
            return

        vuln_lower = vuln_type.lower()
        primitive = ExploitPrimitive(name=vuln_type)

        # Format string write (%n)
        if any(x in vuln_lower for x in ['format_string_write', 'format_write', 'printf']):
            primitive.arbitrary_write = not report.glibc_n_disabled
            primitive.arbitrary_read = True  # %s, %p always work
            primitive.info_leak = True
            primitive.write_size = "1-8 bytes per write (hhn/hn/n)"
            primitive.write_count = "multiple"
            primitive.requires_leak = report.binary_protections.get('pie', False)
            primitive.notes = "Write via %n, read via %p/%s. If %n blocked, read-only."

        # Format string read (info leak)
        elif any(x in vuln_lower for x in ['format_string_read', 'format_read', 'format_leak']):
            primitive.info_leak = True
            primitive.arbitrary_read = True
            primitive.notes = "Read stack/memory via %p, %s, %x. Enables other attacks."

        # sprintf overflow
        elif 'sprintf' in vuln_lower:
            primitive.control_rip = True  # If overflows return address
            primitive.limited_write = True
            primitive.write_size = "sequential overflow"
            primitive.write_count = "once"
            primitive.notes = "Buffer overflow via format expansion, not %n."

        # Stack buffer overflow
        elif any(x in vuln_lower for x in ['stack', 'buffer_overflow', 'bof']):
            primitive.control_rip = True
            primitive.limited_write = True  # Sequential, not arbitrary
            primitive.write_size = "sequential overflow"
            primitive.write_count = "once"
            primitive.requires_leak = (
                report.binary_protections.get('canary', False) or
                report.binary_protections.get('pie', False)
            )
            primitive.notes = "Overwrite return address. May need canary/PIE leak."

        # Heap overflow
        elif 'heap' in vuln_lower and 'overflow' in vuln_lower:
            primitive.heap_control = True
            primitive.relative_write = True  # OOB write relative to chunk
            primitive.limited_write = True
            primitive.write_size = "depends on heap layout"
            primitive.requires_leak = True
            primitive.requires_heap_feng_shui = True
            primitive.notes = "Corrupt heap metadata or adjacent chunks."

        # Use-after-free
        elif any(x in vuln_lower for x in ['uaf', 'use_after_free']):
            primitive.heap_control = True
            primitive.arbitrary_write = True  # With proper grooming
            primitive.arbitrary_read = True   # Via fake object
            primitive.requires_leak = True
            primitive.requires_heap_feng_shui = True
            primitive.notes = "Reallocate freed object, control via fake structure."

        # Double-free
        elif 'double_free' in vuln_lower:
            primitive.heap_control = True
            primitive.arbitrary_write = True  # tcache dup -> write-what-where
            primitive.requires_leak = True
            primitive.requires_heap_feng_shui = True
            primitive.notes = "tcache dup for arbitrary write, needs heap leak for safe-linking."

        # Out-of-bounds read
        elif any(x in vuln_lower for x in ['oob_read', 'out_of_bounds_read', 'array_read']):
            primitive.relative_read = True
            primitive.info_leak = True
            primitive.notes = "Read beyond buffer bounds, leak adjacent memory."

        # Out-of-bounds write
        elif any(x in vuln_lower for x in ['oob_write', 'out_of_bounds_write', 'array_write']):
            primitive.relative_write = True
            primitive.limited_write = True
            primitive.notes = "Write beyond buffer bounds, corrupt adjacent memory."

        # Integer overflow - consequences vary widely
        elif any(x in vuln_lower for x in ['integer_overflow', 'int_overflow']):
            # Integer overflows can lead to many things depending on context
            # We mark potential capabilities, but exploitation depends on where the
            # overflowed value is used (allocation size, array index, loop counter, etc.)
            primitive.relative_write = True  # Often enables OOB access
            primitive.relative_read = True
            primitive.notes = (
                "Integer overflow consequences vary: may cause undersized allocation "
                "(heap overflow), OOB array access, or logic bugs. Analyze where the "
                "overflowed value is used."
            )
            # Only set heap feng shui if specifically heap-related
            if 'heap' in vuln_lower or 'malloc' in vuln_lower or 'alloc' in vuln_lower:
                primitive.heap_control = True
                primitive.requires_heap_feng_shui = True

        # Check if stack pivot is possible based on ROP gadgets
        if report.rop_gadgets:
            if report.rop_gadgets.leave_ret or report.rop_gadgets.pop_rsp_ret:
                primitive.control_rsp = True  # Can do stack pivot

        report.exploit_primitives = primitive
        logger.info(f"Exploit primitives: write={primitive.arbitrary_write}, "
                   f"read={primitive.arbitrary_read}, rip={primitive.control_rip}")

    def _analyze_binary_specific(self, report: FeasibilityReport):
        """
        Perform binary-specific analysis tying mitigations to concrete targets.

        This provides actionable output for exploit development:
        - Which targets are viable given protections
        - What techniques work with this binary
        - Gadget quality assessment
        """
        if not self.binary or not report.elf_structure:
            logger.debug("Binary or ELF structure not available - skipping binary-specific analysis")
            return

        # Determine bad bytes from payload constraints
        bad_bytes = [0x00]  # NUL always bad
        if report.payload_constraints:
            bad_bytes = list(set(bad_bytes + report.payload_constraints.bad_bytes))

        # Run binary target analysis
        binary_analysis = analyze_binary_targets(
            binary_path=str(self.binary),
            elf_structure=report.elf_structure,
            binary_protections=report.binary_protections,
            bad_bytes=bad_bytes
        )

        # Analyze gadget quality if we have ROP info
        if report.rop_gadgets:
            gadget_quality = analyze_gadget_quality(report.rop_gadgets, bad_bytes)
            binary_analysis.gadgets = gadget_quality
            report.gadget_quality = gadget_quality

            # Update viable techniques based on gadget availability
            if gadget_quality.can_ret2libc:
                if "stack_buffer_overflow_ret2libc" not in binary_analysis.viable_techniques:
                    binary_analysis.viable_techniques.append("stack_buffer_overflow_ret2libc")
            else:
                if "stack_buffer_overflow_ret2libc" in binary_analysis.viable_techniques:
                    binary_analysis.blocked_techniques["stack_buffer_overflow_ret2libc"] = "Missing pop rdi gadget"
                    binary_analysis.viable_techniques.remove("stack_buffer_overflow_ret2libc")

            if gadget_quality.can_execve_rop:
                if "stack_buffer_overflow_rop" not in binary_analysis.viable_techniques:
                    binary_analysis.viable_techniques.append("stack_buffer_overflow_rop")

        report.binary_specific = binary_analysis

        # Log summary
        viable_count = len(binary_analysis.get_viable_targets())
        blocked_count = len([t for t in binary_analysis.targets if not t.viable])
        logger.info(f"Binary-specific analysis: {viable_count} viable targets, {blocked_count} blocked")

        best_target = binary_analysis.get_best_target()
        if best_target:
            logger.info(f"Best target: {best_target.name} @ 0x{best_target.address:x}")

    def extended_analysis(self, report: FeasibilityReport, vuln_type: str = None):
        """
        Run all extended analysis (input handlers, libc, ROP, ELF, etc.).

        This is separate from basic mitigation checks to allow incremental use.
        """
        logger.info("Running extended analysis...")

        # 1. Detect input handlers from binary
        self._detect_input_handlers(report)

        # 2. Infer exploitation constraints from detected input handlers
        #    This populates blocked_techniques and viable_techniques
        if report.detected_input_handlers and not report.exploitation_constraints:
            # Use the most constraining detected handler
            primary_handler = None
            for h in ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf']:
                if h in report.detected_input_handlers:
                    primary_handler = h
                    break
            if not primary_handler and report.detected_input_handlers:
                primary_handler = report.detected_input_handlers[0]

            if primary_handler:
                logger.info(f"Inferring constraints from detected handler: {primary_handler}")
                self._infer_payload_constraints(report, vuln_type or "", primary_handler)

        # 3. Query libc for offsets
        self._query_libc_info(report)

        # 4. Analyze ELF structure
        self._analyze_elf_structure(report)

        # 5. Check seccomp
        self._check_seccomp(report)

        # 6. Sample address space (ASLR entropy, null bytes)
        self._sample_address_space(report)

        # 7. ROP gadget analysis (uses bad bytes from payload_constraints)
        self._analyze_rop_gadgets(report)

        # 8. Rank write targets
        self._rank_write_targets(report)

        # 9. Analyze exploit primitives
        if vuln_type:
            self._analyze_exploit_primitives(report, vuln_type)

        # 10. Binary-specific analysis (ties mitigations to concrete targets)
        self._analyze_binary_specific(report)

        logger.info("Extended analysis complete")


def check_system_exploitability(vuln_type: str = None) -> FeasibilityReport:
    """
    Convenience function to check system exploitability without a specific binary.

    Args:
        vuln_type: Optional vulnerability type for targeted checks

    Returns:
        FeasibilityReport with system-level mitigation analysis
    """
    analyzer = FeasibilityAnalyzer()
    return analyzer.full_analysis(vuln_type)


def check_binary_exploitability(binary_path: str, vuln_type: str = None) -> FeasibilityReport:
    """
    Convenience function to check binary exploitability.

    Args:
        binary_path: Path to binary to analyze
        vuln_type: Optional vulnerability type for targeted checks

    Returns:
        FeasibilityReport with complete mitigation analysis
    """
    analyzer = FeasibilityAnalyzer(binary_path)
    return analyzer.full_analysis(vuln_type)


# =============================================================================
# Type Aliases for New Naming Convention
# =============================================================================
# These provide forward-compatible names while maintaining backward compatibility

# FeasibilityReport is the preferred name going forward
FeasibilityReport = FeasibilityReport

# FeasibilityAnalyzer is the preferred name going forward
FeasibilityAnalyzer = FeasibilityAnalyzer
