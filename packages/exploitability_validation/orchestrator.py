"""
Exploitability Validation Orchestrator

Executes the multi-stage validation pipeline with:
- Deterministic stage execution
- JSON schema validation
- Error recovery
- Progress tracking
"""

import os
import json
import logging
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any, Callable
from enum import Enum

from .schemas import (
    validate_checklist,
    validate_findings,
    validate_attack_tree,
    validate_attack_paths,
    validate_attack_surface,
    create_empty_checklist,
    create_empty_findings,
    ValidationError
)

logger = logging.getLogger(__name__)


class Stage(Enum):
    """Pipeline stages."""
    INVENTORY = "0"
    ONESHOT = "A"
    PROCESS = "B"
    SANITY = "C"
    RULING = "D"
    FEASIBILITY = "E"


class StageStatus(Enum):
    """Status of a stage execution."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


# Human-readable display for status values (per CLAUDE.md style guide)
STATUS_DISPLAY = {
    # Final statuses
    "EXPLOITABLE": "Exploitable",
    "CONFIRMED_CONSTRAINED": "Confirmed (constrained)",
    "CONFIRMED_BLOCKED": "Confirmed (blocked)",
    "CONFIRMED": "Confirmed",
    "CONFIRMED_UNVERIFIED": "Confirmed (unverified)",
    # Validation statuses
    "pending": "Pending",
    "not_disproven": "Not disproven",
    "disproven": "Disproven",
    "confirmed": "Confirmed",
    "ruled_out": "Ruled out",
    "poc_success": "PoC success",
    # Error states
    "error": "Error",
    "unknown": "Unknown",
}


@dataclass
class StageResult:
    """Result of a stage execution."""
    stage: Stage
    status: StageStatus
    output_files: List[str] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    duration_seconds: float = 0.0
    retry_count: int = 0


@dataclass
class PipelineConfig:
    """Configuration for the validation pipeline."""
    target_path: str
    workdir: str
    vuln_type: Optional[str] = None
    binary_path: Optional[str] = None
    findings_file: Optional[str] = None  # Pre-existing findings to validate
    skip_feasibility: bool = False
    max_retries: int = 3
    validate_schemas: bool = True

    # Stage-specific config
    stage_b_max_attempts: int = 5  # Max attempts per attack path
    stage_b_proximity_threshold: int = 3  # Min proximity to continue


@dataclass
class PipelineState:
    """Current state of the pipeline."""
    config: PipelineConfig
    current_stage: Optional[Stage] = None
    stage_results: Dict[Stage, StageResult] = field(default_factory=dict)
    checklist: Optional[Dict] = None
    findings: Optional[Dict] = None
    attack_tree: Optional[Dict] = None
    attack_paths: Optional[List] = None
    attack_surface: Optional[Dict] = None
    hypotheses: Optional[List] = None
    disproven: Optional[List] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    def get_output_path(self, filename: str) -> str:
        """Get full path for an output file."""
        return os.path.join(self.config.workdir, filename)

    def save_json(self, filename: str, data: Any) -> str:
        """Save data to JSON file in workdir."""
        path = self.get_output_path(filename)
        with open(path, 'w') as f:
            json.dump(data, f, indent=2, default=str)
        return path

    def load_json(self, filename: str) -> Any:
        """Load JSON file from workdir."""
        path = self.get_output_path(filename)
        if os.path.exists(path):
            with open(path, 'r') as f:
                return json.load(f)
        return None


# Memory corruption types that require Stage E
MEMORY_CORRUPTION_TYPES = {
    'buffer_overflow', 'heap_overflow', 'stack_overflow',
    'format_string', 'use_after_free', 'double_free',
    'integer_overflow', 'out_of_bounds_read', 'out_of_bounds_write'
}


class ValidationOrchestrator:
    """
    Orchestrates the exploitability validation pipeline.

    Usage:
        config = PipelineConfig(
            target_path="/path/to/code",
            workdir=".out/exploitability-validation-20260122/",
            vuln_type="command_injection"
        )
        orchestrator = ValidationOrchestrator(config)
        result = orchestrator.run()
    """

    def __init__(self, config: PipelineConfig):
        self.config = config
        self.state = PipelineState(config=config)
        self.stage_handlers: Dict[Stage, Callable] = {
            Stage.INVENTORY: self._run_stage_0,
            Stage.ONESHOT: self._run_stage_a,
            Stage.PROCESS: self._run_stage_b,
            Stage.SANITY: self._run_stage_c,
            Stage.RULING: self._run_stage_d,
            Stage.FEASIBILITY: self._run_stage_e,
        }
        self._recovery_handlers: Dict[Stage, Callable] = {}

    def run(self) -> PipelineState:
        """Run the full validation pipeline."""
        self.state.started_at = datetime.now()

        # Create workdir
        os.makedirs(self.config.workdir, exist_ok=True)

        # Determine starting stage
        if self.config.findings_file:
            # Load findings and create minimal checklist (skips full inventory)
            self._load_existing_findings()
            # Run Stage B (Process), C (Sanity), D (Ruling), E (Feasibility)
            # Skip Stage 0 (Inventory) and A (One-Shot) since findings already provided
            stages = [Stage.PROCESS, Stage.SANITY, Stage.RULING, Stage.FEASIBILITY]
            logger.info(f"Pre-existing findings provided - skipping Stage 0 and A")
        else:
            stages = list(Stage)

        # Execute stages
        for stage in stages:
            result = self._execute_stage(stage)
            self.state.stage_results[stage] = result

            if result.status == StageStatus.FAILED:
                logger.error(f"Stage {stage.name} failed: {result.errors}")
                if not self._attempt_recovery(stage, result):
                    break

            # Check if we should skip remaining stages
            if self._should_skip_remaining(stage, result):
                break

        self.state.completed_at = datetime.now()
        self._generate_report()

        return self.state

    def _execute_stage(self, stage: Stage) -> StageResult:
        """Execute a single stage with retry logic."""
        self.state.current_stage = stage
        logger.info(f"Starting Stage {stage.value}: {stage.name}")

        result = StageResult(stage=stage, status=StageStatus.RUNNING)
        start_time = datetime.now()

        for attempt in range(self.config.max_retries):
            result.retry_count = attempt
            try:
                handler = self.stage_handlers[stage]
                output_files = handler()
                result.output_files = output_files
                result.status = StageStatus.COMPLETED

                # Validate outputs if enabled
                if self.config.validate_schemas:
                    validation_errors = self._validate_stage_outputs(stage)
                    if validation_errors:
                        result.warnings.extend(validation_errors)

                break

            except Exception as e:
                error_msg = f"Attempt {attempt + 1}/{self.config.max_retries}: {str(e)}"
                result.errors.append(error_msg)
                logger.warning(error_msg)

                if attempt == self.config.max_retries - 1:
                    result.status = StageStatus.FAILED

        result.duration_seconds = (datetime.now() - start_time).total_seconds()
        return result

    def _run_stage_0(self) -> List[str]:
        """Stage 0: Inventory - Build checklist of functions."""
        from .checklist_builder import build_checklist

        checklist = build_checklist(
            self.config.target_path,
            self.config.workdir,
            exclude_patterns=["*_test.*", "test_*", "*_mock.*", "mock_*", "__tests__/", "tests/", "fixtures/"]
        )

        self.state.checklist = checklist
        path = self.state.get_output_path("checklist.json")

        logger.info(f"Stage 0 complete: {checklist['total_files']} files, {checklist['total_functions']} functions")
        return [path]

    def _run_stage_a(self) -> List[str]:
        """Stage A: One-Shot - Quick exploitability check."""
        if not self.state.checklist:
            self.state.checklist = self.state.load_json("checklist.json")

        findings = create_empty_findings("A", self.config.target_path, self.config.vuln_type)

        # This is where LLM analysis would be invoked
        # For now, create structure for LLM to fill
        findings["_instruction"] = (
            "Analyze each function in checklist.json for the target vulnerability type. "
            "For each candidate, attempt to verify exploitability and build a harmless PoC. "
            "Update status to: poc_success, not_disproven, or disproven."
        )

        self.state.findings = findings
        path = self.state.save_json("findings.json", findings)

        return [path]

    def _run_stage_b(self) -> List[str]:
        """Stage B: Process - Systematic analysis with attack trees."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")

        # Check if we have any "not_disproven" findings that need Stage B
        not_disproven = [f for f in self.state.findings.get("findings", [])
                        if f.get("status") == "not_disproven"]

        if not not_disproven:
            logger.info("Stage B: No 'not_disproven' findings, skipping")
            return []

        # Initialize working documents
        attack_tree = {
            "root": "Exploit vulnerability",
            "updated_at": datetime.now().isoformat(),
            "nodes": []
        }
        attack_paths = []
        attack_surface = {"sources": [], "sinks": [], "trust_boundaries": []}
        hypotheses = []
        disproven = []

        # Save initial structures
        paths = [
            self.state.save_json("attack-tree.json", attack_tree),
            self.state.save_json("attack-paths.json", attack_paths),
            self.state.save_json("attack-surface.json", attack_surface),
            self.state.save_json("hypotheses.json", hypotheses),
            self.state.save_json("disproven.json", disproven),
        ]

        self.state.attack_tree = attack_tree
        self.state.attack_paths = attack_paths
        self.state.attack_surface = attack_surface
        self.state.hypotheses = hypotheses
        self.state.disproven = disproven

        # Update findings
        self.state.findings["stage"] = "B"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        paths.append(self.state.save_json("findings.json", self.state.findings))

        return paths

    def _run_stage_c(self) -> List[str]:
        """Stage C: Sanity - Verify findings against actual code."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")

        # Add sanity check instruction
        self.state.findings["_instruction"] = (
            "For each finding, verify against actual code: "
            "1. File exists at stated path "
            "2. Code matches VERBATIM at stated line "
            "3. Source->sink flow is real "
            "4. Code is reachable (function is called). "
            "Update sanity_check field for each finding."
        )

        self.state.findings["stage"] = "C"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        path = self.state.save_json("findings.json", self.state.findings)

        return [path]

    def _run_stage_d(self) -> List[str]:
        """Stage D: Ruling - Filter findings based on practical criteria."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")

        # Only process findings that passed sanity check
        for finding in self.state.findings.get("findings", []):
            sanity = finding.get("sanity_check") or {}
            if sanity.get("passed") is False:
                finding["status"] = "ruled_out"
                finding["ruling"] = {
                    "status": "RULED_OUT",
                    "disqualifier": "sanity_check_failed",
                    "reason": "Failed sanity check in Stage C"
                }
            elif sanity.get("passed") is True:
                finding["status"] = "confirmed"
                finding["ruling"] = {
                    "status": "CONFIRMED",
                    "reason": "Passed sanity check in Stage C"
                }
            else:
                # No sanity check performed - don't change status, but set ruling for Stage E
                finding["ruling"] = {
                    "status": "CONFIRMED",
                    "reason": "No sanity check performed - requires manual review"
                }

        self.state.findings["stage"] = "D"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        path = self.state.save_json("findings.json", self.state.findings)

        return [path]

    def _run_stage_e(self) -> List[str]:
        """Stage E: Feasibility - Binary constraint analysis for memory corruption."""
        if not self.state.findings:
            self.state.findings = self.state.load_json("findings.json")

        if self.config.skip_feasibility:
            logger.info("Stage E: Skipped (--skip-feasibility)")
            return []

        # Check if any findings need feasibility analysis
        confirmed = [f for f in self.state.findings.get("findings", [])
                    if (f.get("ruling") or {}).get("status") == "CONFIRMED"]

        memory_corruption_findings = [
            f for f in confirmed
            if f.get("vuln_type") in MEMORY_CORRUPTION_TYPES
        ]

        if not memory_corruption_findings:
            logger.info("Stage E: No memory corruption findings, skipping")
            # Mark all confirmed as final
            for f in confirmed:
                f["final_status"] = "CONFIRMED"
                f["feasibility"] = {"status": "not_applicable"}
            self.state.save_json("findings.json", self.state.findings)
            return [self.state.get_output_path("findings.json")]

        # Try to run exploit feasibility
        user_provided_binary = bool(self.config.binary_path)
        binary_path = self.config.binary_path

        # If user provided a binary path, check it exists
        if user_provided_binary and not Path(binary_path).exists():
            logger.warning(f"Stage E: Provided binary not found: {binary_path}")
            for f in memory_corruption_findings:
                f["final_status"] = "CONFIRMED_UNVERIFIED"
                f["feasibility"] = {
                    "status": "error",
                    "error": f"Provided binary not found: {binary_path}"
                }
            binary_path = None
        elif not user_provided_binary:
            # Try to auto-detect binary (no warning if not found)
            binary_path = self._find_binary()
            if not binary_path:
                logger.info("Stage E: No binary provided, skipping feasibility analysis")
                for f in memory_corruption_findings:
                    f["final_status"] = "CONFIRMED"
                    f["feasibility"] = {
                        "status": "skipped",
                        "reason": "No binary provided - use --binary to enable Stage E"
                    }

        if not binary_path:
            # Mark non-memory-corruption findings as CONFIRMED before returning
            for f in confirmed:
                if f.get("vuln_type") not in MEMORY_CORRUPTION_TYPES:
                    f["final_status"] = "CONFIRMED"
                    f["feasibility"] = {"status": "not_applicable"}
            self.state.findings["stage"] = "E"
            self.state.findings["timestamp"] = datetime.now().isoformat()
            self.state.save_json("findings.json", self.state.findings)
            return [self.state.get_output_path("findings.json")]
        else:
            # Import and run exploit feasibility
            try:
                from packages.exploit_feasibility import (
                    analyze_binary,
                    save_exploit_context
                )

                for finding in memory_corruption_findings:
                    result = analyze_binary(binary_path, vuln_type=finding.get("vuln_type"))
                    context_file = save_exploit_context(binary_path)

                    # Map raw enum values to human-readable verdicts
                    verdict_display = {
                        "exploitable": "Exploitable",
                        "likely_exploitable": "Likely exploitable",
                        "difficult": "Difficult",
                        "unlikely": "Unlikely",
                        "unknown": "Unknown",
                        "error": "Error"
                    }
                    raw_verdict = result.get("verdict", "unknown")
                    human_verdict = verdict_display.get(raw_verdict, raw_verdict)

                    finding["feasibility"] = {
                        "status": "analyzed",
                        "binary_path": binary_path,
                        "context_file": context_file,
                        "verdict": human_verdict,
                        "chain_breaks": result.get("blockers", []),
                        "what_would_help": result.get("suggestions", [])
                    }

                    # Set final status based on verdict
                    verdict_to_status = {
                        "exploitable": "EXPLOITABLE",
                        "likely_exploitable": "EXPLOITABLE",
                        "difficult": "CONFIRMED_CONSTRAINED",
                        "unlikely": "CONFIRMED_BLOCKED"
                    }
                    finding["final_status"] = verdict_to_status.get(
                        raw_verdict, "CONFIRMED_UNVERIFIED"
                    )

            except ImportError:
                logger.warning("exploit_feasibility package not available")
                for f in memory_corruption_findings:
                    f["final_status"] = "CONFIRMED_UNVERIFIED"
                    f["feasibility"] = {
                        "status": "error",
                        "error": "exploit_feasibility package not available"
                    }
            except Exception as e:
                logger.error(f"Feasibility analysis failed: {e}")
                for f in memory_corruption_findings:
                    f["final_status"] = "CONFIRMED_UNVERIFIED"
                    f["feasibility"] = {
                        "status": "error",
                        "error": str(e)
                    }

        # Mark non-memory-corruption as CONFIRMED
        for f in confirmed:
            if f.get("vuln_type") not in MEMORY_CORRUPTION_TYPES:
                f["final_status"] = "CONFIRMED"
                f["feasibility"] = {"status": "not_applicable"}

        self.state.findings["stage"] = "E"
        self.state.findings["timestamp"] = datetime.now().isoformat()
        path = self.state.save_json("findings.json", self.state.findings)

        return [path]

    def _find_binary(self) -> Optional[str]:
        """Attempt to find compiled binary."""
        target = Path(self.config.target_path)

        # Common build output locations
        search_paths = [
            target / "build",
            target / "bin",
            target / "out",
            target / "dist",
            target,
        ]

        for search_path in search_paths:
            if search_path.exists():
                # Look for executables
                for f in search_path.iterdir():
                    if f.is_file() and os.access(f, os.X_OK):
                        return str(f)

        return None

    def _validate_stage_outputs(self, stage: Stage) -> List[str]:
        """Validate stage outputs against schemas."""
        errors = []

        if stage == Stage.INVENTORY and self.state.checklist:
            valid, errs = validate_checklist(self.state.checklist)
            if not valid:
                errors.extend([f"checklist.json: {e}" for e in errs])

        if stage in (Stage.ONESHOT, Stage.PROCESS, Stage.SANITY, Stage.RULING, Stage.FEASIBILITY):
            if self.state.findings:
                valid, errs = validate_findings(self.state.findings)
                if not valid:
                    errors.extend([f"findings.json: {e}" for e in errs])

        if stage == Stage.PROCESS:
            if self.state.attack_tree:
                valid, errs = validate_attack_tree(self.state.attack_tree)
                if not valid:
                    errors.extend([f"attack-tree.json: {e}" for e in errs])

            if self.state.attack_paths:
                valid, errs = validate_attack_paths(self.state.attack_paths)
                if not valid:
                    errors.extend([f"attack-paths.json: {e}" for e in errs])

            if self.state.attack_surface:
                valid, errs = validate_attack_surface(self.state.attack_surface)
                if not valid:
                    errors.extend([f"attack-surface.json: {e}" for e in errs])

        return errors

    def _should_skip_remaining(self, stage: Stage, result: StageResult) -> bool:
        """Check if remaining stages should be skipped."""
        if stage == Stage.ONESHOT:
            # If all findings are disproven, skip remaining
            findings = self.state.findings.get("findings", []) if self.state.findings else []
            if findings and all(f.get("status") == "disproven" for f in findings):
                logger.info("All findings disproven in Stage A, pipeline complete")
                return True

        if stage == Stage.RULING:
            # If no confirmed findings, skip Stage E
            findings = self.state.findings.get("findings", []) if self.state.findings else []
            confirmed = [f for f in findings if (f.get("ruling") or {}).get("status") == "CONFIRMED"]
            if not confirmed:
                logger.info("No confirmed findings after Stage D, pipeline complete")
                return True

        return False

    def _attempt_recovery(self, stage: Stage, result: StageResult) -> bool:
        """Attempt to recover from stage failure."""
        if stage in self._recovery_handlers:
            try:
                self._recovery_handlers[stage](result)
                return True
            except Exception as e:
                logger.error(f"Recovery failed for stage {stage.name}: {e}")

        return False

    def _load_existing_findings(self):
        """Load pre-existing findings file (JSON or SARIF format)."""
        try:
            with open(self.config.findings_file, 'r') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in findings file: {e}")
            raise ValidationError(f"Failed to parse findings file: {e}")
        except FileNotFoundError:
            raise ValidationError(f"Findings file not found: {self.config.findings_file}")

        # Detect SARIF format and convert
        if self._is_sarif_format(data):
            self.state.findings = self._convert_sarif_to_findings(data)
            logger.info(f"Converted SARIF: {len(self.state.findings.get('findings', []))} findings")
        else:
            self.state.findings = data
            logger.info(f"Loaded JSON: {len(self.state.findings.get('findings', []))} findings")

        # Deduplicate findings
        self._deduplicate_findings()

        # Create minimal checklist from findings files
        self._create_minimal_checklist()

    def _is_sarif_format(self, data: Dict) -> bool:
        """Detect if data is SARIF format (supports 2.0 and 2.1)."""
        if not isinstance(data, dict):
            return False
        # SARIF 2.1.0 has $schema, SARIF 2.0 may not
        if 'runs' in data:
            schema = data.get('$schema', '')
            version = data.get('version', '')
            return ('sarif' in schema.lower() or
                    version.startswith('2.') or
                    isinstance(data.get('runs'), list))
        return False

    def _normalize_rule_id(self, rule_id: str, tool_name: str) -> str:
        """
        Normalize verbose rule IDs to clean vulnerability types.

        Examples:
            'engine.semgrep.rules.crypto.raptor.crypto.weak-hash.python' -> 'weak-hash'
            'java/sql-injection' -> 'sql-injection'
            'CWE-89' -> 'sql-injection'
        """
        if not rule_id:
            return 'unknown'

        # CWE mapping for common vulnerabilities (values must match schema enum)
        cwe_map = {
            'CWE-78': 'command_injection',
            'CWE-79': 'xss',
            'CWE-89': 'sql_injection',
            'CWE-90': 'other',  # LDAP injection
            'CWE-91': 'other',  # XML injection
            'CWE-94': 'command_injection',  # Code injection -> command_injection
            'CWE-119': 'buffer_overflow',
            'CWE-120': 'buffer_overflow',
            'CWE-121': 'stack_overflow',
            'CWE-122': 'heap_overflow',
            'CWE-125': 'out_of_bounds_read',
            'CWE-134': 'format_string',
            'CWE-190': 'integer_overflow',
            'CWE-200': 'other',  # Info disclosure
            'CWE-22': 'path_traversal',
            'CWE-327': 'weak_crypto',
            'CWE-328': 'weak_crypto',  # Weak hash -> weak_crypto
            'CWE-415': 'double_free',
            'CWE-416': 'use_after_free',
            'CWE-502': 'deserialization',
            'CWE-611': 'other',  # XXE
            'CWE-787': 'out_of_bounds_write',
            'CWE-918': 'ssrf',
        }

        # Check CWE mapping
        upper_id = rule_id.upper()
        for cwe, vuln_type in cwe_map.items():
            if cwe in upper_id:
                return vuln_type

        # Strip common prefixes
        prefixes_to_strip = [
            'engine.semgrep.rules.',
            'semgrep.',
            'codeql.',
            'rules.',
            'security.',
            'raptor.',
        ]

        clean = rule_id.lower()
        for prefix in prefixes_to_strip:
            if clean.startswith(prefix):
                clean = clean[len(prefix):]

        # Extract the meaningful part (usually the last segment)
        parts = clean.replace('/', '.').split('.')
        # Filter out language names and 'crypto' prefixes
        filter_out = {'python', 'java', 'javascript', 'c', 'cpp', 'go', 'ruby', 'php', 'crypto'}
        meaningful = [p for p in parts if p and p not in filter_out]

        if meaningful:
            # Normalize to underscores (codebase convention)
            return meaningful[-1].replace('-', '_')
        return rule_id.replace('-', '_')  # Fall back to original, normalized

    def _convert_sarif_to_findings(self, sarif: Dict) -> Dict:
        """Convert SARIF format to internal findings format.

        Handles:
        - SARIF 2.0 and 2.1.0 formats
        - Multiple runs from different tools
        - Logical locations for function names
        - Fingerprints for deduplication
        - Malformed entries (skipped with warning)
        """
        findings_list = []
        seen_fingerprints = set()
        skipped = 0
        finding_idx = 0

        for run_idx, run in enumerate(sarif.get('runs', [])):
            tool_name = run.get('tool', {}).get('driver', {}).get('name', 'unknown')
            rules = {r.get('id'): r for r in run.get('tool', {}).get('driver', {}).get('rules', [])}

            for result in run.get('results', []):
                try:
                    finding = self._convert_sarif_result(
                        result, finding_idx, tool_name, rules, seen_fingerprints
                    )
                    if finding:
                        findings_list.append(finding)
                        finding_idx += 1
                except Exception as e:
                    skipped += 1
                    logger.warning(f"Skipped malformed SARIF result: {e}")
                    continue

        if skipped > 0:
            logger.warning(f"Skipped {skipped} malformed SARIF results")

        return {
            'stage': 'A',
            'timestamp': datetime.now().isoformat(),
            'target_path': self.config.target_path,
            'source': 'sarif',
            'findings': findings_list
        }

    def _convert_sarif_result(self, result: Dict, idx: int, tool_name: str,
                              rules: Dict, seen_fingerprints: set) -> Optional[Dict]:
        """Convert a single SARIF result to internal finding format."""
        # Skip 'note' level findings (informational only)
        level = result.get('level', 'warning')
        if level == 'note':
            return None

        # Extract locations
        locations = result.get('locations', [])
        if not locations:
            return None

        loc = locations[0]
        phys_loc = loc.get('physicalLocation', {})
        artifact = phys_loc.get('artifactLocation', {})
        region = phys_loc.get('region', {})

        # Normalize file path
        file_path = artifact.get('uri', '')
        if file_path.startswith('file://'):
            file_path = file_path[7:]

        if not file_path:
            return None

        line = region.get('startLine', 0)
        if line == 0:
            return None

        # Get rule ID and normalize to clean vuln_type
        rule_id = result.get('ruleId', 'unknown')
        vuln_type = self._normalize_rule_id(rule_id, tool_name)

        # Check fingerprint for deduplication (use normalized vuln_type)
        fingerprint = result.get('fingerprints', {}).get('primaryLocationLineHash')
        if not fingerprint:
            # Create our own fingerprint using normalized type for cross-tool dedup
            fingerprint = f"{file_path}:{line}:{vuln_type}"

        if fingerprint in seen_fingerprints:
            return None
        seen_fingerprints.add(fingerprint)

        # Extract function name from logical locations
        function = 'unknown'
        for log_loc in loc.get('logicalLocations', []):
            if log_loc.get('kind') in ('function', 'method', 'member'):
                function = log_loc.get('name', log_loc.get('fullyQualifiedName', 'unknown'))
                break

        # Get rule metadata for severity
        rule = rules.get(rule_id, {})
        severity = rule.get('properties', {}).get('security-severity', level)

        # Extract snippet
        snippet = region.get('snippet', {}).get('text', '')
        if not snippet:
            context = phys_loc.get('contextRegion', {})
            snippet = context.get('snippet', {}).get('text', '')

        return {
            'id': f"SARIF-{idx:04d}",
            'file': file_path,
            'line': line,
            'function': function,
            'vuln_type': vuln_type,
            'status': 'pending',
            'message': result.get('message', {}).get('text', '')[:200],
            'proof': snippet[:500] if snippet else '',
            'tool': tool_name,
            'rule_id': rule_id,
            'severity': result.get('level', 'warning')
        }

    def _deduplicate_findings(self):
        """Deduplicate findings by file:line:type."""
        if not self.state.findings:
            return

        findings = self.state.findings.get('findings', [])
        if not findings:
            return

        seen = set()
        unique = []

        for finding in findings:
            key = (
                finding.get('file', ''),
                finding.get('line', 0),
                finding.get('vuln_type', '')
            )
            if key not in seen:
                seen.add(key)
                unique.append(finding)

        if len(unique) < len(findings):
            logger.info(f"Deduplicated: {len(findings)} -> {len(unique)} findings")
            self.state.findings['findings'] = unique

    def _create_minimal_checklist(self):
        """Create a minimal checklist from just the files in findings."""
        if not self.state.findings:
            return

        # Extract unique files from findings
        files = set()
        for finding in self.state.findings.get('findings', []):
            file_path = finding.get('file', '')
            if file_path:
                # Normalize path
                if file_path.startswith('file://'):
                    file_path = file_path[7:]
                files.add(file_path)

        # Create minimal checklist
        self.state.checklist = {
            'generated_at': datetime.now().isoformat(),
            'target_path': self.config.target_path,
            'total_files': len(files),
            'total_functions': len(self.state.findings.get('findings', [])),
            'scope': 'findings_only',
            'files': [{'path': f, 'functions': []} for f in sorted(files)]
        }

        # Save checklist
        path = self.state.save_json('checklist.json', self.state.checklist)
        logger.info(f"Created minimal checklist: {len(files)} files from findings")

    def _generate_report(self):
        """Generate final validation report."""
        report_lines = [
            "# Exploitability Validation Report",
            "",
            "## Summary",
            f"- Target: {self.config.target_path}",
            f"- Vulnerability Type: {self.config.vuln_type or 'all'}",
            f"- Started: {self.state.started_at}",
            f"- Completed: {self.state.completed_at}",
            "",
            "## Stage Results",
            ""
        ]

        for stage, result in self.state.stage_results.items():
            status_icon = {
                StageStatus.COMPLETED: "[OK]",
                StageStatus.FAILED: "[FAIL]",
                StageStatus.SKIPPED: "[SKIP]"
            }.get(result.status, "[?]")

            report_lines.append(f"- Stage {stage.value} ({stage.name}): {status_icon} ({result.duration_seconds:.1f}s)")
            if result.errors:
                for err in result.errors:
                    report_lines.append(f"  - Error: {err}")
            if result.warnings:
                for warn in result.warnings:
                    report_lines.append(f"  - Warning: {warn}")

        # Findings summary
        if self.state.findings:
            findings = self.state.findings.get("findings", [])
            report_lines.extend([
                "",
                "## Findings Summary",
                f"- Total: {len(findings)}",
            ])

            by_status = {}
            for f in findings:
                status = f.get("final_status") or f.get("status", "unknown")
                by_status[status] = by_status.get(status, 0) + 1

            for status, count in sorted(by_status.items()):
                display_status = STATUS_DISPLAY.get(status, status)
                report_lines.append(f"- {display_status}: {count}")

            # List confirmed findings
            confirmed = [f for f in findings if f.get("final_status") in
                        ("EXPLOITABLE", "CONFIRMED_CONSTRAINED", "CONFIRMED_BLOCKED", "CONFIRMED")]

            if confirmed:
                report_lines.extend(["", "## Confirmed Findings", ""])
                for f in confirmed:
                    report_lines.append(f"### {f['id']}: {f['vuln_type']} in {f['file']}:{f['line']}")
                    report_lines.append(f"- Function: {f['function']}")
                    final_status = f.get('final_status', 'N/A')
                    report_lines.append(f"- Final Status: {STATUS_DISPLAY.get(final_status, final_status)}")

                    if (f.get("feasibility") or {}).get("verdict"):
                        report_lines.append(f"- Feasibility: {f['feasibility']['verdict']}")
                        if f['feasibility'].get('chain_breaks'):
                            report_lines.append(f"- Chain Breaks: {', '.join(f['feasibility']['chain_breaks'][:3])}")

                    report_lines.append("")

        # Coverage
        if self.state.checklist:
            total = self.state.checklist.get("total_functions", 0)
            checked = sum(1 for f in self.state.checklist.get("files", [])
                         for fn in f.get("functions", []) if fn.get("checked"))
            report_lines.extend([
                "## Coverage",
                f"- Functions checked: {checked}/{total}",
                ""
            ])

        report_path = self.state.get_output_path("validation-report.md")
        with open(report_path, 'w') as f:
            f.write('\n'.join(report_lines))

        logger.info(f"Report written to {report_path}")


def run_validation(
    target_path: str,
    vuln_type: str = None,
    binary_path: str = None,
    findings_file: str = None,
    skip_feasibility: bool = False,
    workdir: str = None
) -> PipelineState:
    """
    Convenience function to run the validation pipeline.

    Args:
        target_path: Path to code to analyze
        vuln_type: Vulnerability type to focus on (optional)
        binary_path: Path to compiled binary for Stage E (optional)
        findings_file: Pre-existing findings to validate (optional)
        skip_feasibility: Skip Stage E even for memory corruption
        workdir: Output directory (auto-generated if not provided)

    Returns:
        PipelineState with all results
    """
    if not workdir:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        workdir = f".out/exploitability-validation-{timestamp}"

    config = PipelineConfig(
        target_path=target_path,
        workdir=workdir,
        vuln_type=vuln_type,
        binary_path=binary_path,
        findings_file=findings_file,
        skip_feasibility=skip_feasibility
    )

    orchestrator = ValidationOrchestrator(config)
    return orchestrator.run()
