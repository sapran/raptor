"""Tests for exploitability_validation package."""

import os
import json
import tempfile
import pytest
from pathlib import Path

from packages.exploitability_validation import (
    build_checklist,
    extract_functions,
    detect_language,
    update_checklist_coverage,
    get_coverage_stats,
    validate_checklist,
    validate_findings,
    create_empty_checklist,
    create_empty_findings,
    create_finding,
    run_validation,
    PipelineConfig,
    PipelineState,
    ValidationOrchestrator,
    Stage,
    StageStatus,
    StageResult,
    LANGUAGE_MAP,
    DEFAULT_EXCLUDES,
)
from packages.exploitability_validation.checklist_builder import (
    should_exclude,
    is_binary_file,
    is_generated_file,
    GENERATED_MARKERS,
)


class TestLanguageDetection:
    def test_python(self):
        assert detect_language("foo.py") == "python"

    def test_javascript(self):
        assert detect_language("bar.js") == "javascript"
        assert detect_language("bar.jsx") == "javascript"

    def test_typescript(self):
        assert detect_language("baz.ts") == "typescript"
        assert detect_language("baz.tsx") == "typescript"

    def test_c(self):
        assert detect_language("main.c") == "c"
        assert detect_language("header.h") == "c"

    def test_unknown(self):
        assert detect_language("unknown.xyz") is None


class TestFunctionExtraction:
    def test_python_functions(self):
        content = '''
def foo():
    pass

async def bar(x, y):
    return x + y

def _private():
    pass
'''
        functions = extract_functions("test.py", "python", content)
        names = [f.name for f in functions]
        assert "foo" in names
        assert "bar" in names
        assert "_private" in names
        assert len(functions) == 3

    def test_javascript_functions(self):
        content = '''
function foo() {}
const bar = () => {};
async function baz() {}
'''
        functions = extract_functions("test.js", "javascript", content)
        names = [f.name for f in functions]
        assert "foo" in names
        assert "bar" in names
        assert "baz" in names

    def test_c_functions(self):
        content = '''
int main(int argc, char *argv[]) {
    return 0;
}

void helper() {
    printf("hello");
}
'''
        functions = extract_functions("test.c", "c", content)
        names = [f.name for f in functions]
        assert "main" in names
        assert "helper" in names

    def test_java_functions(self):
        content = '''
public class MyClass {
    public void doSomething() {
        System.out.println("hello");
    }

    private static int calculate(int x) {
        return x * 2;
    }
}
'''
        functions = extract_functions("Test.java", "java", content)
        names = [f.name for f in functions]
        assert "doSomething" in names
        assert "calculate" in names

    def test_go_functions(self):
        content = '''
package main

func main() {
    fmt.Println("hello")
}

func (s *Server) handleRequest(w http.ResponseWriter, r *http.Request) {
    // method with receiver
}

func helper() int {
    return 42
}
'''
        functions = extract_functions("main.go", "go", content)
        names = [f.name for f in functions]
        assert "main" in names
        assert "handleRequest" in names
        assert "helper" in names

    def test_python_syntax_error_fallback(self):
        # Invalid Python syntax - should fall back to regex
        content = '''
def valid_func():
    pass

def another_func(x, y:
    # syntax error - missing closing paren
    pass
'''
        functions = extract_functions("broken.py", "python", content)
        names = [f.name for f in functions]
        # Regex fallback should still find functions
        assert "valid_func" in names
        assert "another_func" in names

    def test_generic_extractor(self):
        # Test with an unsupported language that falls back to generic
        content = '''
def some_func():
    pass

function another():
    return
'''
        functions = extract_functions("test.unknown", "unknown", content)
        names = [f.name for f in functions]
        assert len(names) >= 1  # Generic should find at least one


class TestShouldExclude:
    def test_directory_pattern(self):
        assert should_exclude("src/tests/test_foo.py", ["tests/"])
        assert should_exclude("node_modules/lodash/index.js", ["node_modules/"])
        assert not should_exclude("src/main.py", ["tests/"])

    def test_glob_pattern(self):
        assert should_exclude("test_foo.py", ["test_*"])
        assert should_exclude("foo_test.py", ["*_test.*"])
        assert should_exclude("bundle.min.js", ["*.min.js"])
        assert not should_exclude("main.py", ["test_*"])

    def test_exact_match(self):
        assert should_exclude("path/to/__pycache__/module.pyc", ["__pycache__"])
        assert not should_exclude("src/main.py", ["__pycache__"])

    def test_multiple_patterns(self):
        patterns = ["tests/", "test_*", "*.min.js"]
        assert should_exclude("tests/test_main.py", patterns)
        assert should_exclude("test_utils.py", patterns)
        assert should_exclude("app.min.js", patterns)
        assert not should_exclude("src/utils.py", patterns)


class TestChecklistBuilder:
    def test_build_from_directory(self, tmp_path):
        # Create test files
        src_dir = tmp_path / "src"
        src_dir.mkdir()
        (src_dir / "foo.py").write_text("def foo(): pass\ndef bar(): pass\n")
        (src_dir / "baz.js").write_text("function baz() {}\n")
        out_dir = tmp_path / "out"

        checklist = build_checklist(str(src_dir), str(out_dir), exclude_patterns=[])

        assert checklist["total_files"] == 2
        assert checklist["total_functions"] == 3
        assert "generated_at" in checklist
        assert (out_dir / "checklist.json").exists()

    def test_excludes_test_files(self, tmp_path):
        src_dir = tmp_path / "src"
        src_dir.mkdir()
        (src_dir / "main.py").write_text("def main(): pass\n")
        (src_dir / "test_main.py").write_text("def test_main(): pass\n")
        out_dir = tmp_path / "out"

        checklist = build_checklist(str(src_dir), str(out_dir))  # Uses DEFAULT_EXCLUDES

        assert checklist["total_files"] == 1
        assert checklist["total_functions"] == 1

    def test_single_file(self, tmp_path):
        test_file = tmp_path / "single.py"
        test_file.write_text("def one(): pass\ndef two(): pass\n")
        out_dir = tmp_path / "out"

        checklist = build_checklist(str(test_file), str(out_dir), exclude_patterns=[])

        assert checklist["total_files"] == 1
        assert checklist["total_functions"] == 2

    def test_multiple_languages(self, tmp_path):
        src_dir = tmp_path / "src"
        src_dir.mkdir()
        (src_dir / "app.py").write_text("def py_func(): pass\n")
        (src_dir / "app.js").write_text("function js_func() {}\n")
        (src_dir / "app.go").write_text("func go_func() {}\n")
        out_dir = tmp_path / "out"

        checklist = build_checklist(str(src_dir), str(out_dir), exclude_patterns=[])

        assert checklist["total_files"] == 3
        assert checklist["total_functions"] == 3


class TestCoverageTracking:
    def test_update_checklist_coverage(self):
        checklist = {
            "files": [
                {
                    "path": "app.py",
                    "functions": [
                        {"name": "foo", "checked": False},
                        {"name": "bar", "checked": False},
                    ]
                }
            ]
        }

        checked = [
            {"file": "app.py", "function": "foo"}
        ]

        updated = update_checklist_coverage(checklist, checked)

        assert updated["files"][0]["functions"][0]["checked"] is True
        assert updated["files"][0]["functions"][1]["checked"] is False

    def test_get_coverage_stats(self):
        checklist = {
            "files": [
                {
                    "path": "app.py",
                    "functions": [
                        {"name": "foo", "checked": True},
                        {"name": "bar", "checked": False},
                        {"name": "baz", "checked": True},
                    ]
                }
            ]
        }

        stats = get_coverage_stats(checklist)

        assert stats["total_functions"] == 3
        assert stats["checked_functions"] == 2
        assert stats["coverage_percent"] == pytest.approx(66.67, rel=0.1)

    def test_get_coverage_stats_empty(self):
        checklist = {"files": []}
        stats = get_coverage_stats(checklist)

        assert stats["total_functions"] == 0
        assert stats["checked_functions"] == 0
        assert stats["coverage_percent"] == 0


class TestSchemaValidation:
    def test_valid_checklist(self):
        checklist = create_empty_checklist("/tmp/test")
        valid, errors = validate_checklist(checklist)
        assert valid
        assert len(errors) == 0

    def test_invalid_checklist_missing_field(self):
        checklist = {"files": []}  # Missing required fields
        valid, errors = validate_checklist(checklist)
        assert not valid
        assert len(errors) > 0

    def test_valid_findings(self):
        findings = create_empty_findings("A", "/tmp/test", "sql_injection")
        valid, errors = validate_findings(findings)
        assert valid
        assert len(errors) == 0

    def test_invalid_findings_missing_stage(self):
        findings = {"findings": []}  # Missing 'stage'
        valid, errors = validate_findings(findings)
        assert not valid

    def test_finding_creation(self):
        finding = create_finding(
            finding_id="FIND-001",
            file="foo.py",
            function="vulnerable",
            line=42,
            vuln_type="command_injection",
            status="poc_success"
        )
        assert finding["id"] == "FIND-001"
        assert finding["file"] == "foo.py"
        assert finding["status"] == "poc_success"

    def test_finding_default_status(self):
        finding = create_finding(
            finding_id="FIND-002",
            file="bar.py",
            function="test",
            line=10,
            vuln_type="xss"
        )
        assert finding["status"] == "not_disproven"  # Default

    def test_validate_attack_tree(self):
        from packages.exploitability_validation import validate_attack_tree
        tree = {
            "root": "Exploit vulnerability",
            "updated_at": "2026-01-22T10:00:00",
            "nodes": []
        }
        valid, errors = validate_attack_tree(tree)
        assert valid

    def test_validate_attack_tree_invalid(self):
        from packages.exploitability_validation import validate_attack_tree
        tree = {"nodes": []}  # Missing 'root'
        valid, errors = validate_attack_tree(tree)
        assert not valid

    def test_validate_attack_paths(self):
        from packages.exploitability_validation import validate_attack_paths
        paths = [
            {
                "id": "PATH-001",
                "path": [
                    {"step": 1, "action": "inject payload", "result": "reflected"}
                ],
                "proximity": 3
            }
        ]
        valid, errors = validate_attack_paths(paths)
        assert valid

    def test_validate_attack_paths_empty(self):
        from packages.exploitability_validation import validate_attack_paths
        valid, errors = validate_attack_paths([])
        assert valid  # Empty is valid

    def test_validate_attack_surface(self):
        from packages.exploitability_validation import validate_attack_surface
        surface = {
            "sources": [{"type": "http_param", "location": "request.args.id"}],
            "sinks": [{"type": "command_exec", "location": "os.system()"}],
            "trust_boundaries": []
        }
        valid, errors = validate_attack_surface(surface)
        assert valid

    def test_validate_attack_surface_invalid(self):
        from packages.exploitability_validation import validate_attack_surface
        surface = {"sources": "not_a_list"}  # Wrong type
        valid, errors = validate_attack_surface(surface)
        assert not valid


class TestStageEnum:
    def test_stage_values(self):
        assert Stage.INVENTORY.value == "0"
        assert Stage.ONESHOT.value == "A"
        assert Stage.PROCESS.value == "B"
        assert Stage.SANITY.value == "C"
        assert Stage.RULING.value == "D"
        assert Stage.FEASIBILITY.value == "E"

    def test_stage_iteration(self):
        stages = list(Stage)
        assert len(stages) == 6


class TestStageStatus:
    def test_status_values(self):
        assert StageStatus.PENDING.value == "pending"
        assert StageStatus.RUNNING.value == "running"
        assert StageStatus.COMPLETED.value == "completed"
        assert StageStatus.FAILED.value == "failed"
        assert StageStatus.SKIPPED.value == "skipped"


class TestPipelineConfig:
    def test_defaults(self):
        config = PipelineConfig(
            target_path="/tmp/test",
            workdir="/tmp/out"
        )
        assert config.vuln_type is None
        assert config.binary_path is None
        assert config.skip_feasibility is False
        assert config.max_retries == 3

    def test_custom_values(self):
        config = PipelineConfig(
            target_path="/code",
            workdir="/out",
            vuln_type="sql_injection",
            binary_path="/bin/app",
            skip_feasibility=True,
            max_retries=5
        )
        assert config.vuln_type == "sql_injection"
        assert config.binary_path == "/bin/app"
        assert config.skip_feasibility is True
        assert config.max_retries == 5


class TestPipelineState:
    def test_get_output_path(self, tmp_path):
        config = PipelineConfig(target_path="/code", workdir=str(tmp_path))
        state = PipelineState(config=config)

        path = state.get_output_path("test.json")
        assert path == str(tmp_path / "test.json")

    def test_save_and_load_json(self, tmp_path):
        config = PipelineConfig(target_path="/code", workdir=str(tmp_path))
        state = PipelineState(config=config)

        data = {"key": "value", "number": 42}
        path = state.save_json("data.json", data)

        assert Path(path).exists()

        loaded = state.load_json("data.json")
        assert loaded == data

    def test_load_nonexistent_json(self, tmp_path):
        config = PipelineConfig(target_path="/code", workdir=str(tmp_path))
        state = PipelineState(config=config)

        result = state.load_json("nonexistent.json")
        assert result is None


class TestValidationOrchestrator:
    def test_stage_0_inventory(self, tmp_path):
        # Create test file
        (tmp_path / "app.py").write_text("def vulnerable(): pass\n")

        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(
            target_path=str(tmp_path),
            workdir=str(workdir)
        )

        orchestrator = ValidationOrchestrator(config)
        result = orchestrator._execute_stage(Stage.INVENTORY)

        assert result.status == StageStatus.COMPLETED
        assert orchestrator.state.checklist is not None
        assert orchestrator.state.checklist["total_functions"] == 1

        # Check file was saved
        checklist_file = workdir / "checklist.json"
        assert checklist_file.exists()

    def test_stage_a_oneshot(self, tmp_path):
        (tmp_path / "app.py").write_text("def vuln(): pass\n")
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        # Run stage 0 first
        orchestrator._execute_stage(Stage.INVENTORY)
        # Then stage A
        result = orchestrator._execute_stage(Stage.ONESHOT)

        assert result.status == StageStatus.COMPLETED
        assert orchestrator.state.findings is not None
        assert "findings" in orchestrator.state.findings

    def test_stage_b_process_skipped_no_findings(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        # Set up findings with no "not_disproven"
        orchestrator.state.findings = {"findings": []}

        result = orchestrator._execute_stage(Stage.PROCESS)
        assert result.status == StageStatus.COMPLETED
        assert result.output_files == []  # Skipped

    def test_stage_c_sanity(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        orchestrator.state.findings = {
            "stage": "A",
            "findings": [{"id": "F1", "status": "poc_success"}]
        }

        result = orchestrator._execute_stage(Stage.SANITY)
        assert result.status == StageStatus.COMPLETED
        assert "_instruction" in orchestrator.state.findings

    def test_stage_d_ruling(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        orchestrator.state.findings = {
            "stage": "C",
            "findings": [
                {"id": "F1", "sanity_check": {"passed": True}},
                {"id": "F2", "sanity_check": {"passed": False}},
            ]
        }

        result = orchestrator._execute_stage(Stage.RULING)
        assert result.status == StageStatus.COMPLETED

        # F2 should be ruled out
        f2 = next(f for f in orchestrator.state.findings["findings"] if f["id"] == "F2")
        assert f2["status"] == "ruled_out"

    def test_stage_e_skip_feasibility(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(
            target_path=str(tmp_path),
            workdir=str(workdir),
            skip_feasibility=True
        )
        orchestrator = ValidationOrchestrator(config)
        orchestrator.state.findings = {"findings": []}

        result = orchestrator._execute_stage(Stage.FEASIBILITY)
        assert result.status == StageStatus.COMPLETED
        assert result.output_files == []

    def test_stage_e_no_memory_corruption(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        # Web vuln - not memory corruption
        orchestrator.state.findings = {
            "findings": [{
                "id": "F1",
                "vuln_type": "sql_injection",
                "ruling": {"status": "CONFIRMED"}
            }]
        }

        result = orchestrator._execute_stage(Stage.FEASIBILITY)
        assert result.status == StageStatus.COMPLETED

        f1 = orchestrator.state.findings["findings"][0]
        assert f1["final_status"] == "CONFIRMED"
        assert f1["feasibility"]["status"] == "not_applicable"

    def test_should_skip_remaining_all_disproven(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        orchestrator.state.findings = {
            "findings": [
                {"status": "disproven"},
                {"status": "disproven"},
            ]
        }

        from packages.exploitability_validation.orchestrator import StageResult
        result = StageResult(stage=Stage.ONESHOT, status=StageStatus.COMPLETED)

        should_skip = orchestrator._should_skip_remaining(Stage.ONESHOT, result)
        assert should_skip is True

    def test_should_skip_remaining_has_findings(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        orchestrator.state.findings = {
            "findings": [
                {"status": "poc_success"},
                {"status": "disproven"},
            ]
        }

        from packages.exploitability_validation.orchestrator import StageResult
        result = StageResult(stage=Stage.ONESHOT, status=StageStatus.COMPLETED)

        should_skip = orchestrator._should_skip_remaining(Stage.ONESHOT, result)
        assert should_skip is False

    def test_generate_report(self, tmp_path):
        workdir = tmp_path / "out"
        workdir.mkdir()

        config = PipelineConfig(target_path=str(tmp_path), workdir=str(workdir))
        orchestrator = ValidationOrchestrator(config)

        from datetime import datetime
        orchestrator.state.started_at = datetime.now()
        orchestrator.state.completed_at = datetime.now()
        orchestrator.state.checklist = {"total_functions": 10, "files": []}
        orchestrator.state.findings = {
            "findings": [{"id": "F1", "final_status": "CONFIRMED", "vuln_type": "xss",
                         "file": "app.py", "line": 42, "function": "render"}]
        }

        orchestrator._generate_report()

        report_file = workdir / "validation-report.md"
        assert report_file.exists()
        content = report_file.read_text()
        assert "Exploitability Validation Report" in content
        assert "Confirmed" in content  # Human-readable status display


class TestRunValidation:
    def test_full_pipeline(self, tmp_path):
        # Create test file
        (tmp_path / "app.py").write_text('''
def execute_command(user_input):
    import os
    os.system(user_input)  # Command injection!
''')

        workdir = tmp_path / "validation"

        state = run_validation(
            target_path=str(tmp_path),
            vuln_type="command_injection",
            workdir=str(workdir),
            skip_feasibility=True
        )

        assert state.completed_at is not None
        assert state.checklist is not None
        assert state.findings is not None

        # Check report was generated
        report = workdir / "validation-report.md"
        assert report.exists()


class TestSarifConversion:
    """Test SARIF format handling."""

    def test_is_sarif_format_with_schema(self, tmp_path):
        """Test detection of SARIF 2.1.0 format."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        sarif_data = {
            "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
            "version": "2.1.0",
            "runs": []
        }
        assert orchestrator._is_sarif_format(sarif_data) is True

    def test_is_sarif_format_v20(self, tmp_path):
        """Test detection of SARIF 2.0 format (no schema)."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        sarif_data = {"version": "2.0", "runs": []}
        assert orchestrator._is_sarif_format(sarif_data) is True

    def test_is_sarif_format_not_sarif(self, tmp_path):
        """Test rejection of non-SARIF format."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        non_sarif = {"findings": [], "stage": "A"}
        assert orchestrator._is_sarif_format(non_sarif) is False

    def test_convert_sarif_basic(self, tmp_path):
        """Test basic SARIF to findings conversion."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        sarif_data = {
            "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
            "version": "2.1.0",
            "runs": [{
                "tool": {"driver": {"name": "semgrep"}},
                "results": [{
                    "ruleId": "sql-injection",
                    "message": {"text": "Possible SQL injection"},
                    "locations": [{
                        "physicalLocation": {
                            "artifactLocation": {"uri": "src/db.py"},
                            "region": {"startLine": 42, "snippet": {"text": "cursor.execute(query)"}}
                        }
                    }]
                }]
            }]
        }

        findings = orchestrator._convert_sarif_to_findings(sarif_data)

        assert findings["source"] == "sarif"
        assert len(findings["findings"]) == 1
        f = findings["findings"][0]
        assert f["file"] == "src/db.py"
        assert f["line"] == 42
        assert f["vuln_type"] == "sql_injection"  # Normalized to underscores
        assert "SQL injection" in f["message"]

    def test_convert_sarif_deduplication(self, tmp_path):
        """Test that SARIF conversion deduplicates by fingerprint."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        sarif_data = {
            "version": "2.1.0",
            "runs": [{
                "tool": {"driver": {"name": "test"}},
                "results": [
                    {
                        "ruleId": "vuln1",
                        "fingerprints": {"primaryLocationLineHash": "abc123"},
                        "message": {"text": "First"},
                        "locations": [{"physicalLocation": {
                            "artifactLocation": {"uri": "test.py"},
                            "region": {"startLine": 10}
                        }}]
                    },
                    {
                        "ruleId": "vuln1",
                        "fingerprints": {"primaryLocationLineHash": "abc123"},  # Duplicate
                        "message": {"text": "Duplicate"},
                        "locations": [{"physicalLocation": {
                            "artifactLocation": {"uri": "test.py"},
                            "region": {"startLine": 10}
                        }}]
                    }
                ]
            }]
        }

        findings = orchestrator._convert_sarif_to_findings(sarif_data)
        assert len(findings["findings"]) == 1

    def test_convert_sarif_malformed_result(self, tmp_path):
        """Test that malformed SARIF results are skipped gracefully."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        sarif_data = {
            "version": "2.1.0",
            "runs": [{
                "tool": {"driver": {"name": "test"}},
                "results": [
                    {},  # Malformed - no locations
                    {"locations": []},  # Malformed - empty locations
                    {  # Valid
                        "ruleId": "valid",
                        "message": {"text": "Valid finding"},
                        "locations": [{"physicalLocation": {
                            "artifactLocation": {"uri": "valid.py"},
                            "region": {"startLine": 5}
                        }}]
                    }
                ]
            }]
        }

        findings = orchestrator._convert_sarif_to_findings(sarif_data)
        assert len(findings["findings"]) == 1
        assert findings["findings"][0]["file"] == "valid.py"

    def test_load_findings_sarif_file(self, tmp_path):
        """Test loading findings from SARIF file."""
        sarif_file = tmp_path / "results.sarif"
        sarif_data = {
            "$schema": "https://json.schemastore.org/sarif-2.1.0.json",
            "version": "2.1.0",
            "runs": [{
                "tool": {"driver": {"name": "semgrep"}},
                "results": [{
                    "ruleId": "test-rule",
                    "message": {"text": "Test vuln"},
                    "locations": [{"physicalLocation": {
                        "artifactLocation": {"uri": "app.py"},
                        "region": {"startLine": 100}
                    }}]
                }]
            }]
        }
        sarif_file.write_text(json.dumps(sarif_data))

        workdir = tmp_path / "work"
        workdir.mkdir()

        config = PipelineConfig(
            target_path=str(tmp_path),
            workdir=str(workdir),
            findings_file=str(sarif_file)
        )
        orchestrator = ValidationOrchestrator(config)
        orchestrator._load_existing_findings()

        assert orchestrator.state.findings is not None
        assert len(orchestrator.state.findings["findings"]) == 1
        assert orchestrator.state.checklist is not None
        assert len(orchestrator.state.checklist["files"]) == 1

    def test_deduplicate_findings(self, tmp_path):
        """Test deduplication of findings by file:line:type."""
        config = PipelineConfig(target_path=str(tmp_path), workdir=str(tmp_path))
        orchestrator = ValidationOrchestrator(config)

        orchestrator.state.findings = {
            "findings": [
                {"file": "a.py", "line": 10, "vuln_type": "sqli"},
                {"file": "a.py", "line": 10, "vuln_type": "sqli"},  # Dup
                {"file": "a.py", "line": 10, "vuln_type": "xss"},   # Different type
                {"file": "a.py", "line": 20, "vuln_type": "sqli"},  # Different line
            ]
        }

        orchestrator._deduplicate_findings()

        assert len(orchestrator.state.findings["findings"]) == 3


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
