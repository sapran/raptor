"""
Checklist Builder - Language-aware function extraction for Stage 0

Extracts functions from source files to build the coverage checklist.

Optimized for:
- Speed: Parallel processing, single-pass directory scan
- Cleanliness: Generated file detection, comprehensive excludes
- Accuracy: AST parsing where possible, robust fallbacks
"""

import os
import re
import ast
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Set
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

# Maximum workers for parallel file processing
MAX_WORKERS = os.cpu_count() or 4


@dataclass
class FunctionInfo:
    """Information about an extracted function."""
    name: str
    line_start: int
    line_end: Optional[int] = None
    signature: Optional[str] = None
    checked: bool = False


@dataclass
class FileInfo:
    """Information about a source file."""
    path: str
    language: str
    lines: int
    functions: List[FunctionInfo]


# Language detection by extension
LANGUAGE_MAP = {
    '.py': 'python',
    '.js': 'javascript',
    '.jsx': 'javascript',
    '.ts': 'typescript',
    '.tsx': 'typescript',
    '.c': 'c',
    '.h': 'c',
    '.cpp': 'cpp',
    '.cc': 'cpp',
    '.cxx': 'cpp',
    '.hpp': 'cpp',
    '.java': 'java',
    '.go': 'go',
    '.rs': 'rust',
    '.rb': 'ruby',
    '.php': 'php',
    '.cs': 'csharp',
    '.swift': 'swift',
    '.kt': 'kotlin',
    '.scala': 'scala',
}

# Default exclude patterns - comprehensive list for clean inventory
DEFAULT_EXCLUDES = [
    # Test directories and files
    '*_test.*', 'test_*', '*_mock.*', 'mock_*', '*_spec.*',
    '__tests__/', 'tests/', 'test/', 'spec/', 'testing/',
    'fixtures/', '__fixtures__/', 'testdata/', 'test-data/',

    # Dependencies and vendor code
    'node_modules/', 'vendor/', 'third_party/', 'third-party/',
    'external/', 'deps/', 'dependencies/',

    # Python virtual environments and caches
    'venv/', '.venv/', 'env/', '.env/', 'virtualenv/',
    '__pycache__/', '.pytest_cache/', '.tox/', '.eggs/',
    '*.egg-info/', 'site-packages/',

    # Build outputs
    'dist/', 'build/', 'target/', 'out/', 'output/',
    'bin/', 'obj/', 'cmake-build-*/',

    # Version control
    '.git/', '.svn/', '.hg/', '.bzr/',

    # IDE and editor
    '.idea/', '.vscode/', '.vs/', '*.swp', '*.swo',

    # Generated/minified files
    '*.min.js', '*.min.css', '*.bundle.js', '*.bundle.css',
    '*.generated.*', '*.auto.*', '*_generated.*',
    '*_pb2.py', '*_pb2_grpc.py',  # Protobuf
    '*.pb.go', '*.pb.cc',  # Protobuf
    'generated/', 'gen/', 'autogen/',

    # Documentation
    'docs/', 'doc/', 'documentation/',

    # Examples and samples
    'examples/', 'example/', 'samples/', 'sample/', 'demo/',
]

# Markers that indicate a file is auto-generated (check first few lines)
GENERATED_MARKERS = [
    'auto-generated', 'autogenerated', 'automatically generated',
    'do not edit', 'do not modify', 'generated by', 'generated from',
    '@generated', '// code generated', '# generated', '/* generated',
    'this file was generated', 'machine generated',
]


def detect_language(filepath: str) -> Optional[str]:
    """Detect language from file extension."""
    ext = Path(filepath).suffix.lower()
    return LANGUAGE_MAP.get(ext)


def is_binary_file(filepath: Path, sample_size: int = 8192) -> bool:
    """Check if file is binary by looking for null bytes."""
    try:
        with open(filepath, 'rb') as f:
            chunk = f.read(sample_size)
            return b'\x00' in chunk
    except (IOError, OSError):
        return True  # Treat unreadable as binary


def is_generated_file(content: str, check_lines: int = 10) -> bool:
    """Check if file appears to be auto-generated."""
    # Check first N lines for generated markers
    lines = content.split('\n', check_lines)[:check_lines]
    header = '\n'.join(lines).lower()

    for marker in GENERATED_MARKERS:
        if marker in header:
            return True
    return False


def should_exclude(filepath: str, exclude_patterns: List[str]) -> bool:
    """Check if file should be excluded based on patterns."""
    filepath_lower = filepath.lower()
    path_parts = filepath.split(os.sep)

    for pattern in exclude_patterns:
        # Directory pattern (ends with /)
        if pattern.endswith('/'):
            dir_name = pattern[:-1]
            if dir_name in path_parts:
                return True
        # Glob pattern
        elif '*' in pattern:
            import fnmatch
            if fnmatch.fnmatch(os.path.basename(filepath_lower), pattern.lower()):
                return True
            if fnmatch.fnmatch(filepath_lower, pattern.lower()):
                return True
        # Exact match
        elif pattern in filepath:
            return True

    return False


class PythonExtractor:
    """Extract functions from Python files using AST."""

    def extract(self, filepath: str, content: str) -> List[FunctionInfo]:
        functions = []
        try:
            tree = ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    # Build signature
                    args = []
                    for arg in node.args.args:
                        args.append(arg.arg)

                    signature = f"def {node.name}({', '.join(args)})"
                    if isinstance(node, ast.AsyncFunctionDef):
                        signature = "async " + signature

                    functions.append(FunctionInfo(
                        name=node.name,
                        line_start=node.lineno,
                        line_end=node.end_lineno if hasattr(node, 'end_lineno') else None,
                        signature=signature
                    ))
        except SyntaxError as e:
            logger.warning(f"Failed to parse {filepath}: {e}")
            # Fall back to regex
            functions = self._regex_fallback(content)

        return functions

    def _regex_fallback(self, content: str) -> List[FunctionInfo]:
        """Regex fallback for unparseable Python."""
        functions = []
        pattern = r'^(?:async\s+)?def\s+(\w+)\s*\('
        for i, line in enumerate(content.split('\n'), 1):
            match = re.match(pattern, line.strip())
            if match:
                functions.append(FunctionInfo(
                    name=match.group(1),
                    line_start=i
                ))
        return functions


class JavaScriptExtractor:
    """Extract functions from JavaScript/TypeScript files using regex."""

    # Patterns for different function styles
    PATTERNS = [
        # function name() or async function name()
        r'(?:async\s+)?function\s+(\w+)\s*\(',
        # const/let/var name = function
        r'(?:const|let|var)\s+(\w+)\s*=\s*(?:async\s+)?function\s*\(',
        # const/let/var name = () => or async () =>
        r'(?:const|let|var)\s+(\w+)\s*=\s*(?:async\s+)?\([^)]*\)\s*=>',
        # class method: name() { or async name() {
        r'^\s+(?:async\s+)?(\w+)\s*\([^)]*\)\s*\{',
        # object method: name: function or name: () =>
        r'(\w+)\s*:\s*(?:async\s+)?(?:function\s*)?\([^)]*\)\s*(?:=>)?\s*\{',
    ]

    def extract(self, filepath: str, content: str) -> List[FunctionInfo]:
        functions = []
        seen = set()

        for i, line in enumerate(content.split('\n'), 1):
            for pattern in self.PATTERNS:
                match = re.search(pattern, line)
                if match:
                    name = match.group(1)
                    # Avoid duplicates and common non-function names
                    if name not in seen and name not in ('if', 'for', 'while', 'switch', 'catch'):
                        functions.append(FunctionInfo(
                            name=name,
                            line_start=i
                        ))
                        seen.add(name)
                    break

        return functions


class CExtractor:
    """Extract functions from C/C++ files using regex."""

    # Pattern for C function definitions
    # Matches: return_type function_name(params) {
    PATTERN = r'^(?:[\w\s\*]+)\s+(\w+)\s*\([^;]*\)\s*\{'

    def extract(self, filepath: str, content: str) -> List[FunctionInfo]:
        functions = []
        lines = content.split('\n')

        i = 0
        while i < len(lines):
            line = lines[i]

            # Skip preprocessor directives and comments
            stripped = line.strip()
            if stripped.startswith('#') or stripped.startswith('//'):
                i += 1
                continue

            # Look for function definition
            match = re.match(self.PATTERN, line)
            if match:
                name = match.group(1)
                # Skip common macros and keywords
                if name not in ('if', 'for', 'while', 'switch', 'return', 'sizeof', 'typeof'):
                    functions.append(FunctionInfo(
                        name=name,
                        line_start=i + 1
                    ))

            i += 1

        return functions


class JavaExtractor:
    """Extract methods from Java files using regex."""

    # Pattern for Java method definitions
    PATTERN = r'(?:public|private|protected|static|\s)+[\w<>\[\]]+\s+(\w+)\s*\([^)]*\)\s*(?:throws\s+[\w,\s]+)?\s*\{'

    def extract(self, filepath: str, content: str) -> List[FunctionInfo]:
        functions = []

        for i, line in enumerate(content.split('\n'), 1):
            match = re.search(self.PATTERN, line)
            if match:
                name = match.group(1)
                if name not in ('if', 'for', 'while', 'switch', 'try', 'catch'):
                    functions.append(FunctionInfo(
                        name=name,
                        line_start=i
                    ))

        return functions


class GoExtractor:
    """Extract functions from Go files using regex."""

    # Pattern for Go function definitions
    PATTERN = r'^func\s+(?:\([^)]+\)\s+)?(\w+)\s*\('

    def extract(self, filepath: str, content: str) -> List[FunctionInfo]:
        functions = []

        for i, line in enumerate(content.split('\n'), 1):
            match = re.match(self.PATTERN, line)
            if match:
                functions.append(FunctionInfo(
                    name=match.group(1),
                    line_start=i
                ))

        return functions


class GenericExtractor:
    """Generic fallback extractor using common patterns."""

    PATTERNS = [
        r'(?:function|def|func|fn|sub)\s+(\w+)\s*\(',
        r'(?:public|private|protected)?\s*(?:static)?\s*\w+\s+(\w+)\s*\([^)]*\)\s*\{',
    ]

    def extract(self, filepath: str, content: str) -> List[FunctionInfo]:
        functions = []
        seen = set()

        for i, line in enumerate(content.split('\n'), 1):
            for pattern in self.PATTERNS:
                match = re.search(pattern, line)
                if match:
                    name = match.group(1)
                    if name not in seen:
                        functions.append(FunctionInfo(
                            name=name,
                            line_start=i
                        ))
                        seen.add(name)
                    break

        return functions


# Extractor registry
EXTRACTORS = {
    'python': PythonExtractor(),
    'javascript': JavaScriptExtractor(),
    'typescript': JavaScriptExtractor(),
    'c': CExtractor(),
    'cpp': CExtractor(),
    'java': JavaExtractor(),
    'go': GoExtractor(),
}


def extract_functions(filepath: str, language: str, content: str) -> List[FunctionInfo]:
    """Extract functions from a file."""
    extractor = EXTRACTORS.get(language, GenericExtractor())
    return extractor.extract(filepath, content)


def _process_single_file(
    filepath: Path,
    target: Path,
    exclude_patterns: List[str],
    skip_generated: bool = True
) -> Optional[Dict]:
    """
    Process a single file for the checklist.

    Returns file info dict or None if file should be skipped.
    """
    rel_path = str(filepath.relative_to(target) if target.is_dir() else filepath.name)

    # Check exclusions
    if should_exclude(str(filepath), exclude_patterns):
        return None

    # Detect language
    language = detect_language(str(filepath))
    if not language:
        return None

    # Skip binary files early
    if is_binary_file(filepath):
        return None

    try:
        content = filepath.read_text(encoding='utf-8', errors='ignore')

        # Skip generated files
        if skip_generated and is_generated_file(content):
            logger.debug(f"Skipping generated: {rel_path}")
            return None

        line_count = content.count('\n') + 1

        # Extract functions
        functions = extract_functions(str(filepath), language, content)

        return {
            'path': rel_path,
            'language': language,
            'lines': line_count,
            'functions': [
                {
                    'name': f.name,
                    'line_start': f.line_start,
                    'line_end': f.line_end,
                    'signature': f.signature,
                    'checked': False
                }
                for f in functions
            ]
        }

    except Exception as e:
        logger.warning(f"Failed to process {filepath}: {e}")
        return None


def _collect_source_files(target: Path, extensions: Set[str]) -> List[Path]:
    """
    Collect all source files in a single pass.

    More efficient than multiple rglob() calls.
    """
    if target.is_file():
        return [target]

    file_list = []

    # Single-pass directory walk
    for root, dirs, files in os.walk(target):
        # Prune hidden directories early
        dirs[:] = [d for d in dirs if not d.startswith('.')]

        for filename in files:
            ext = Path(filename).suffix.lower()
            if ext in extensions:
                file_list.append(Path(root) / filename)

    return file_list


def build_checklist(
    target_path: str,
    output_dir: str,
    exclude_patterns: List[str] = None,
    extensions: Set[str] = None,
    skip_generated: bool = True,
    parallel: bool = True
) -> Dict:
    """
    Build a checklist of all functions in the target path.

    Args:
        target_path: Directory or file to analyze
        output_dir: Directory to save checklist.json (required)
        exclude_patterns: Patterns to exclude (defaults to DEFAULT_EXCLUDES)
        extensions: File extensions to include (defaults to LANGUAGE_MAP keys)
        skip_generated: Skip auto-generated files (default True)
        parallel: Use parallel processing (default True)

    Returns:
        Checklist dictionary (also saved to output_dir/checklist.json)
    """
    if exclude_patterns is None:
        exclude_patterns = DEFAULT_EXCLUDES

    if extensions is None:
        extensions = set(LANGUAGE_MAP.keys())

    target = Path(target_path)

    # Collect files in single pass
    file_list = _collect_source_files(target, extensions)
    logger.info(f"Found {len(file_list)} source files to process")

    files_info = []
    total_functions = 0
    skipped = 0

    if parallel and len(file_list) > 10:
        # Parallel processing for larger codebases
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = {
                executor.submit(
                    _process_single_file, fp, target, exclude_patterns, skip_generated
                ): fp
                for fp in file_list
            }

            for future in as_completed(futures):
                result = future.result()
                if result:
                    files_info.append(result)
                    total_functions += len(result['functions'])
                else:
                    skipped += 1
    else:
        # Sequential for small codebases
        for filepath in file_list:
            result = _process_single_file(filepath, target, exclude_patterns, skip_generated)
            if result:
                files_info.append(result)
                total_functions += len(result['functions'])
            else:
                skipped += 1

    # Sort files for consistent output
    files_info.sort(key=lambda x: x['path'])

    checklist = {
        'generated_at': datetime.now().isoformat(),
        'target_path': str(target_path),
        'total_files': len(files_info),
        'total_functions': total_functions,
        'skipped_files': skipped,
        'excluded_patterns': exclude_patterns,
        'files': files_info
    }

    # Save to output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    checklist_file = output_path / 'checklist.json'

    import json
    with open(checklist_file, 'w') as f:
        json.dump(checklist, f, indent=2)

    logger.info(f"Built checklist: {len(files_info)} files, {total_functions} functions ({skipped} skipped)")
    logger.info(f"Saved to: {checklist_file}")
    return checklist


def update_checklist_coverage(checklist: Dict, checked_functions: List[Dict]) -> Dict:
    """
    Update checklist with coverage information.

    Args:
        checklist: The checklist to update
        checked_functions: List of {"file": ..., "function": ...} that were checked

    Returns:
        Updated checklist
    """
    checked_set = {(f['file'], f['function']) for f in checked_functions}

    for file_info in checklist.get('files', []):
        for func in file_info.get('functions', []):
            key = (file_info['path'], func['name'])
            if key in checked_set:
                func['checked'] = True

    return checklist


def get_coverage_stats(checklist: Dict) -> Dict:
    """Get coverage statistics from checklist."""
    total = 0
    checked = 0

    for file_info in checklist.get('files', []):
        for func in file_info.get('functions', []):
            total += 1
            if func.get('checked'):
                checked += 1

    return {
        'total_functions': total,
        'checked_functions': checked,
        'coverage_percent': (checked / total * 100) if total > 0 else 0
    }
